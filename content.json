{"meta":{"title":"Frdqy的博客","subtitle":"记录默默到无闻的学习路","description":"","author":"Frdqy","url":"http://yoursite.com","root":"/"},"pages":[{"title":"关于","date":"2019-12-28T00:30:05.000Z","updated":"2020-01-12T11:57:29.430Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"性别：男 爱好：敲键盘 热衷于Linux和pwn 学习之路漫漫，只能砥砺前行。"},{"title":"分类","date":"2019-12-28T00:23:37.000Z","updated":"2019-12-28T00:26:11.438Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-12-28T00:25:13.000Z","updated":"2019-12-28T00:25:56.688Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis(1)-基本原理和安装配置","slug":"Redis-1-基本原理和安装配置","date":"2020-02-11T09:34:30.000Z","updated":"2020-02-11T09:35:38.115Z","comments":true,"path":"2020/02/11/Redis-1-基本原理和安装配置/","link":"","permalink":"http://yoursite.com/2020/02/11/Redis-1-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","excerpt":"基础概念Redis是一个KV型存储引擎，为了提高效率，它的所有工作都在内存中实现，但为了持久存储也会在磁盘上做冗余。它用作数据结构服务器，即存储例如String、list、Hash、Set、Bitmap等类型的数据。 Redis工作在单线程单进程单实例模式，它通过内核的epoll系统调用来处理多路并行请求。","text":"基础概念Redis是一个KV型存储引擎，为了提高效率，它的所有工作都在内存中实现，但为了持久存储也会在磁盘上做冗余。它用作数据结构服务器，即存储例如String、list、Hash、Set、Bitmap等类型的数据。 Redis工作在单线程单进程单实例模式，它通过内核的epoll系统调用来处理多路并行请求。 epoll原理早期的内核程序处理多路请求时使用read系统调用来处理，用户空间的进程如果没有读取到对应的文件描述符fd就会一直阻塞，从而妨碍其他进程处理请求。这就是初期的BIO阻塞模型。 随后为了解决阻塞问题，提出了同步非阻塞的NIO模型。它支持单进程在用户空间通过轮询的方式处理多个并发请求，这样就不会阻塞(多个进程会阻塞，这里就使用单进程轮询处理)。 NIO又引出新的问题，即如果请求量很大那么进程将频繁的在用户空间和内核空间进行切换(之所以不停切换是用户空间进程不知道哪些fd已经准备好需要被使用)，会消耗大量CPU资源。为了解决这个问题，内核进行了修改，出现了新的系统调用select。select实现了将多个可以使用的fd同时从内核发送给用户空间进程，由用户空间进程遍历选择依次进行read系统调用读取该连接，这样就大大减少了进程切换的开销。 上述select方法已经很大程度上减少了资源消耗，但是仍然需要将fd相关数据从内核态内存拷贝到用户空间进程的内存空间，以及select并不知道哪个fd是有数据状态，它自身也需要不断遍历来选择，有没有办法减少这种开销呢？这就引出了epoll机制。它实际上是使用mmap系统调用将用户空间的一块内存和内核空间的一块内存作为共享内存空间，其内维护着数据结构(红黑树和双向链表)，其中红黑树用于管理哪些fd需要被监视，双向链表实现队列。其中双向链表由内核维护，当进程在等待fd时，会创建了一个epoll对象(epoll对象本身也是文件系统资源，也拥有自己的等待队列)并且该epoll对象会被添加到fd等待队列中(如果是多个fd就将epoll放到每个fd等待队列中)。当某个进程调用epoll_wait等待时，内核将该进程添加到epoll对象的等待队列中，当某个fd收到数据时中断程序会修改epoll的双向链表(就绪队列)，添加fd引用并且唤醒阻塞的进程，从而该进程再次得到CPU调用且根据双向链表知道是哪个fd有数据。 epoll是三个系统调用： epoll_create：用户创建epoll对象，该对象的成员包括内核维护的双向链表 epoll_wait：用于epoll对象等待数据 epoll_cli：用于给epoll对象添加需要监控的fd，将fd添加到红黑树上 持久存储redis持久存储主要有两种方式：快照和AOF snapshotting：快照，数据异步从内存传输到磁盘 AOF：即将每次的写操作附加在一个文件后面写入磁盘，类似于mysql的事务日志 NoSql特性Redis属于NoSql存储，NoSql存储主要分为四种：KV键值型、Column列式存储、Documentation文档存储、Graph图表存储 与memcached区别memcached也是KV键值对的NoSql型数据库系统，他们都工作在内存中，一个重要的区别是memcached的value是没有数据类型的，而Redis的value是有数据类型的。memcached存储时将所有键值对都获取然后客户端通过程序解码(解析json格式数据)进行特定数据获取，而Redis由于有数据类型且提供了每种类型特定的获取方法(index、lpop等)，因此可以直接获取对应数据，不需要加载全部数据，换句话说所有的计算都是在server端实现不需要客户端额外的解码等消耗，因此大大提高了效率。 安装123456789101112131415161718#官网http://download.redis.io/releases/redis-5.0.7.tar.gz，此处使用编译安装wget http://download.redis.io/releases/redis-5.0.7.tar.gz#解压tar xf redis-5.0.7.tar.gz#编译make#安装，将可执行文件迁移make install#服务安装，切换至util目录下进行，全部默认即可./install_server.sh#启动，名字后面为端口号，根据不同端口进行修改systemctl start redis_6379#注意，如果make失败产生垃圾需要清除，具体命令以README.md为准make distclean#注意redis根据监听端口号不同区分不同的服务 配置文件redis配置文件根据不同的端口号命名不同，通常以xxxx.conf(其中xxxx为端口号) 123456789101112131415161718192021222324252627282930313233343536373839loadmoudle #加载自定义模块bind #redis服务监听地址port #redis服务运行端口timeout #客户端连接超时时长，即多久没有操作则关闭连接，0表示不设置时长tcp-keepalive #周期性检测客户端监控状态，同样0表示不检测protected-mode #是否开启保护模式，即是否允许客户端连接，默认为yestcp-backlog #tcp等待队列长度daemonize #redis是否运行为守护进程pidfile #配置PID文件路径loglevel #定义日志级别debug(开发测试)、verbose、notice(生产环境)、warning，默认为noticelogfile #配置log文件地址,默认打印在命令行终端的窗口上databases #设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select &lt;dbid&gt;命令选择一个不同的数据库，dbid是一个介于0到databases-1之间的数值。默认值是16，也就是说默认Redis有16个数据库。#持久存储相关save #这里是用来配置触发Redis的持久化条件，也就是什么时候将内存中的数据保存到硬盘，格式为save num1 num2表示num1秒内有num2个key发生变化则同步到磁盘rdbcompression #对于存储在磁盘的快照是否压缩存储，默认为yesrdbchecksum #对于存储的快照是否校验，默认yesdbfilename #设置快照名称，默认为dump.rdbdir #设置快照文件的存放路径，这个配置项一定是个目录，使用dbfilename作为文件名stop-writes-on-bgsave-error #当同步磁盘失败时是否停止接收数据，默认为yes#主从复制相关replica-serve-stale-data #主从复制时如何处理客户端请求，默认yes表示正常应答(会有过时数据)，no表示拒绝并返回错误提示replica-read-only #从节点是否处理请求，默认为yesrepl-diskless-sync #主从数据复制是否使用无硬盘复制功能。默认值为no。repl-diskless-sync-delay #当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段时间以期更多的从站到达。延迟时间以秒为单位，默认为5秒。要关掉这一功能只需将它设置为0秒，传送会立即启动。默认值为5。repl-disable-tcp-nodelay #默认值为no。yes表示redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。Linux内核默认配置情况下最多40毫秒的延时。如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。#AOF主从相关appendonly #使用AOF主从方式，默认为noappendfilename #文件名称appendfsync #持久策略，no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快；always表示每次写入都执行fsync，以保证数据同步到磁盘；everysec表示每秒执行一次fsync，可能会导致丢失这1s数据#集群相关cluster-enabled #是否开启集群，默认为nocluster-config-file #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息cluster-node-timeout#节点互连超时的阀值，集群节点超时毫秒数cluster-slave-validity-factor #可以配置值为10。在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period。如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移cluster-migration-barrier #master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2个可工作的从节点时，它的一个从节点会尝试迁移。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"epoll","slug":"epoll","permalink":"http://yoursite.com/tags/epoll/"},{"name":"多路复用","slug":"多路复用","permalink":"http://yoursite.com/tags/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"}],"author":"Frdqy"},{"title":"k8s(9)-helm程序包管理","slug":"k8s-9-helm程序包管理","date":"2020-02-10T06:05:12.000Z","updated":"2020-02-10T06:05:56.928Z","comments":true,"path":"2020/02/10/k8s-9-helm程序包管理/","link":"","permalink":"http://yoursite.com/2020/02/10/k8s-9-helm%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86/","excerpt":"概念为了解决各个服务安装pod时的依赖以及资源文件修改编写等问题从而提出helm。helm和yum类似，可以理解为包管理工具。","text":"概念为了解决各个服务安装pod时的依赖以及资源文件修改编写等问题从而提出helm。helm和yum类似，可以理解为包管理工具。 术语 chart：一个helm程序包，是创建一个应用的信息集合，包含各种Kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。可以将Chart比喻为yum中的软件安装包；char包括参数模板和值模板，因此可以自定义对其进行修改。 Repository：Charts仓库，本质是一个http服务器，用于集中存储和分发Charts； Config：应用程序实例化安装运行时所需要的配置信息；就是chart模板的值文件 Release：特定的Chart部署于目标集群上的一个实例，代表这一个正在运行的应用。当chart被安装到Kubernetes集群，就会生成一个release，chart可以多次安装到同一个集群，每次安装都是一个release。 架构 helm：客户端，实现管理本地的Chart仓库，可管理Chart，与Tiller服务进行交互，用于发送Chart，实例安装、查询、卸载等操作。 Tiller：服务端，通常运行在K8S集群之上。用于接收helm发来的Charts和Conifg，合并生成release，完成部署。 Helm把Kubernetes资源(比如deployments、services或 ingress等) 打包到一个chart中，而chart被保存到chart仓库，通过chart仓库可用来存储和分享chart。在k8s集群上想要创建pod必须通过APIServer，因此helm客户端将创建请求以及需要的文件发往Tiller服务端，由其向APIServer交互实现pod的创建。 配置部署helm12345678#下载https://github.com/helm/helm/releases编译好的版本，此处使用2.11版本wget https://get.helm.sh/helm-v2.11.0-linux-amd64.tar.gz#解压出linux-amd64文件tar xf helm-v2.11.0-linux-amd64.tar.gz#将二进制文件复制到/usr/bin下直接命令行运行cd mv helm /usr/binmv tiller /usr/bin 部署Tiller3.0之后的helm部署时就没有这一步了，此处使用2.11部署。 部署Tiller就是执行helm的init指令。helm第一次init时，需要APIServer进行创建部署pod，因此需要链接api-server并进行认证，所以在运行helm时，会去读取kube-config文件，所以必须确认当前用户存在kube-config文件。 Tiller运行在K8s集群之上，也必须拥有集群的管理权限，也就是需要一个serviceaccount，进行一个clusterrolebinding到cluster-admin。 12345678910111213141516171819202122232425#创建rbacapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system#初始化，使用阿里云镜像，初始化之后会在kube-system中创建podhelm init --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.11.0 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts#检查是否安装完成，正确的话可以看到helm和tiller的版本helm version 命令1234567891011121314151617181920212223242526272829303132333435363738helm常用命令： search: #搜索charts fetch: #下载charts到本地目录 install: #安装charts list: #列出charts的所有版本 repo list: #列出仓库 repo add: #添加仓库用法: helm [command]命令可用选项: completion #为指定的shell生成自动补全脚本（bash或zsh） create #创建一个新的charts delete #删除指定版本的release dependency #管理charts的依赖 fetch #下载charts并解压到本地目录 get #下载一个release history #release历史信息 home #显示helm的家目录 init #在客户端和服务端初始化helm inspect #查看charts的详细信息 install #安装charts lint #检测包的存在问题 list #列出release package #将chart目录进行打包 plugin #add(增加), list（列出）, or remove（移除） Helm 插件 repo #add(增加), list（列出）, remove（移除）, update（更新）, and index（索引） chart仓库 reset #卸载tiller rollback #release版本回滚 search #关键字搜索chart serve #启动一个本地的http server status #查看release状态信息 template #本地模板 test #release测试 upgrade #release更新 verify #验证chart的签名和有效期 version #打印客户端和服务端的版本信息 chart目录结构下载下来的chart放在/root/.helm/cache/archive下，为压缩文件。其内部由多个yaml文件组成 12345678910111213141516171819202122232425262728#查看jenkins打包目录[root@localhost archive]@ tree jenkinsjenkins├── Chart.yaml├── OWNERS├── README.md├── templates│ ├── config.yaml│ ├── _helpers.tpl│ ├── home-pvc.yaml│ ├── jenkins-agent-svc.yaml│ ├── jenkins-master-deployment.yaml│ ├── jenkins-master-ingress.yaml│ ├── jenkins-master-networkpolicy.yaml│ ├── jenkins-master-svc.yaml│ ├── jenkins-test.yaml│ ├── jobs.yaml│ ├── NOTES.txt│ ├── rbac.yaml│ ├── secret.yaml│ ├── service-account.yaml│ └── test-config.yaml└── values.yaml1 directory, 19 files#注意template中放的yaml文件和平时定义的差不多，但是都是以模板定义，通过values.yaml进行默认赋值。我们可以自定义该文件进行赋值 定义格式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#以jenkins为例apiVersion: v1kind: Podmetadata: name: \"&#123;&#123; .Release.Name &#125;&#125;-ui-test-&#123;&#123; randAlphaNum 5 | lower &#125;&#125;\" annotations: \"helm.sh/hook\": test-successspec: &#123;&#123;- if .Values.Master.NodeSelector &#125;&#125; nodeSelector:&#123;&#123; toYaml .Values.Master.NodeSelector | indent 4 &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123;- if .Values.Master.Tolerations &#125;&#125; tolerations:&#123;&#123; toYaml .Values.Master.Tolerations | indent 4 &#125;&#125; &#123;&#123;- end &#125;&#125; initContainers: - name: \"test-framework\" image: \"dduportal/bats:0.4.0\" command: - \"bash\" - \"-c\" - | set -ex # copy bats to tools dir cp -R /usr/local/libexec/ /tools/bats/ volumeMounts: - mountPath: /tools name: tools containers: - name: &#123;&#123; .Release.Name &#125;&#125;-ui-test image: &#123;&#123; .Values.Master.Image &#125;&#125;:&#123;&#123; .Values.Master.ImageTag &#125;&#125; command: [\"/tools/bats/bats\", \"-t\", \"/tests/run.sh\"] volumeMounts: - mountPath: /tests name: tests readOnly: true - mountPath: /tools name: tools volumes: - name: tests configMap: name: &#123;&#123; template \"jenkins.fullname\" . &#125;&#125;-tests - name: tools emptyDir: &#123;&#125; restartPolicy: Never #解释.Release.Name：是Chart内置变量，表示创建的release的名称，其他类似.Chart.Name：也是内置变量，表示chart名称.Values.Master.NodeSelector：.Values表示的是Value.yaml文件，Master是一级字段(顶格写)，依次如此template \"jenkins.fullname\"：表示引用template目录下的其他模板的某个属性字段randAlphaNum 5 | lower：前者是Go模板的函数，通过|传递结果 自定义chart12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#创建chart基本目录结构helm create myapp#目录结构为myapp/├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── ingress.yaml│ ├── NOTES.txt│ └── service.yaml└── values.yaml#修改Chart.yaml文件，里面是基本描述信息apiVersion: v1appVersion: \"1.0\"description: A Helm chart for Kubernetesname: myappversion: 0.1.0maintainer:- name: Dqy email: 1259178786@qq.com url: http://www.frdqy.top #template/deployment文件apiVersion: apps/v1beta2kind: Deploymentmetadata: name: &#123;&#123; include \"myapp.fullname\" . &#125;&#125; labels: app.kubernetes.io/name: &#123;&#123; include \"myapp.name\" . &#125;&#125; helm.sh/chart: &#123;&#123; include \"myapp.chart\" . &#125;&#125; app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125; app.kubernetes.io/managed-by: &#123;&#123; .Release.Service &#125;&#125;spec: replicas: &#123;&#123; .Values.replicaCount &#125;&#125; selector: matchLabels: app.kubernetes.io/name: &#123;&#123; include \"myapp.name\" . &#125;&#125; app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125; template: metadata: labels: app.kubernetes.io/name: &#123;&#123; include \"myapp.name\" . &#125;&#125; app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125; spec: containers: - name: &#123;&#123; .Chart.Name &#125;&#125; image: \"&#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125;\" imagePullPolicy: &#123;&#123; .Values.image.pullPolicy &#125;&#125; ports: - name: http containerPort: 80 protocol: TCP livenessProbe: httpGet: path: / port: http readinessProbe: httpGet: path: / port: http resources:&#123;&#123; toYaml .Values.resources | indent 12 &#125;&#125; &#123;&#123;- with .Values.nodeSelector &#125;&#125; nodeSelector:&#123;&#123; toYaml . | indent 8 &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123;- with .Values.affinity &#125;&#125; affinity:&#123;&#123; toYaml . | indent 8 &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123;- with .Values.tolerations &#125;&#125; tolerations:&#123;&#123; toYaml . | indent 8 &#125;&#125; &#123;&#123;- end &#125;&#125;#注意myapp.fullname：是当前chart的完整名称，其他类似。myapp就是当前chart的名字#编辑完后，需要检查语法，需要在myapp目录外面使用helm lint ./myapp#打包，默认放在本地的仓库local中helm package myapp/#开启仓库，监听本地8879端口helm serve#安装，可以通过目录安装，压缩包安装，仓库安装以及URL安装helm install --name myapp local/myapphelm install --name myapp ./myapphelm install --name myapp ./myapp-0.1.0.tgz#删除，使用purge删除占用的名字helm delete --purge myapp 自定义仓库1234567891011#在node1上运行httpd，存储卷绑定于/var/www目录docker run -d -p 8080:80 -v /var/www/:/usr/local/apache2/htdocs/ httpd#执行index命令生成页面。myrepo是目录，目录内放打包好的压缩文件helm repo index myrepo/ --url http://192.168.163.135:8080/charts#将mychart-0.1.0.tgz和index.yaml上传到k8s-node1的/var/www/charts目录。scp ./* root@node01:/var/www/charts/#添加仓库源helm repo add newrepo http://192.168.163.135:8080/charts","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"helm","slug":"helm","permalink":"http://yoursite.com/tags/helm/"}],"author":"Frdqy"},{"title":"k8s(8)-资源指标和监控","slug":"k8s-8-资源指标和监控","date":"2020-02-09T04:24:08.000Z","updated":"2020-02-09T04:28:23.156Z","comments":true,"path":"2020/02/09/k8s-8-资源指标和监控/","link":"","permalink":"http://yoursite.com/2020/02/09/k8s-8-%E8%B5%84%E6%BA%90%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7/","excerpt":"常见指标request：需求，pod内容器运行时的资源最低保障 limits：限制，pod内容器可占用的最大资源阈值 CPU：一个物理CPU可分成多个逻辑CPU(根据核心数划分)，每个逻辑CPU又可以分为1000个微核心(millicores) 内存：以E、P、T、G、M、K为计量单位，特别的当以Ei、Pi等作为计量单位时表示使用1024作为单位 QoS：作资源限制后每个pod会自动分配QoS类别，主要分三种：","text":"常见指标request：需求，pod内容器运行时的资源最低保障 limits：限制，pod内容器可占用的最大资源阈值 CPU：一个物理CPU可分成多个逻辑CPU(根据核心数划分)，每个逻辑CPU又可以分为1000个微核心(millicores) 内存：以E、P、T、G、M、K为计量单位，特别的当以Ei、Pi等作为计量单位时表示使用1024作为单位 QoS：作资源限制后每个pod会自动分配QoS类别，主要分三种： Guaranteed：pod内每个容器同时设置CPU和内存的requests和limits且值相等，这类pod具有最高优先级 Burstable：pod内至少一个容器定义了CPU或者内存的requests属性，具有中等优先级 BestEffort：pod内容器没有定义资源限制，具有最低优先级 1234567891011121314151617181920#定义在pod.containers.spec.resourcesapiVersion: v1kind: Podmetadata: name: pod-demo labels: app: nginx tier: frontendspec: contaniers: - name: nginx image: nginx imagePullPolicy: IfNotPresent resources: requests: cpu: \"200m\" memory: \"256Mi\" limits: cpu: \"500m\" memory: \"512Mi\" HeapSterk8s集群上可以使用top命令查看各pod和node的资源使用情况，但是默认情况下无法使用，因为该命令实际上需要HeapSter来收集监控数据从而显示出来，因此需要先安装HeapSter。 我们知道每个node节点上都有一个kubelet程序，该程序用于管理node以及其上pod资源，它靠其插件cAdvisor来收集当前node节点上各pod内容器资源以及node资源的占用量。但是由于cAdvisor只能收集单个node节点的资源使用情况，因此使用HeapSter来收集cAdvisor收集的数据，即HeapSter是统一的多个指标的收集工具。另外，为了使得HeapSter能够存储收集的数据以便查看长久的趋势数据，它使用influxDB时序数据库系统来持久存储。最后可以使用Grafana作为前端显示监控工具，它可以连接influxDB数据库。 部署influxDB123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#资源文件https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/influxdb.yaml，需要修改为如下样式apiVersion: apps/v1 kind: Deploymentmetadata: name: monitoring-influxdb namespace: kube-systemspec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: influxdb template: metadata: labels: task: monitoring k8s-app: influxdb spec: containers: - name: influxdb image: k8s.gcr.io/heapster-influxdb-amd64:v1.5.2 volumeMounts: - mountPath: /data name: influxdb-storage volumes: - name: influxdb-storage emptyDir: &#123;&#125;---apiVersion: v1kind: Servicemetadata: labels: task: monitoring # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons) # If you are NOT using this as an addon, you should comment out this line. kubernetes.io/cluster-service: 'true' kubernetes.io/name: monitoring-influxdb name: monitoring-influxdb namespace: kube-systemspec: ports: - port: 8086 targetPort: 8086 selector: k8s-app: influxdb #应用kubectl apply -f influxdb.yaml 部署RBAC12345678910111213141516#资源文件，https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml，不需要修改kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: heapsterroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:heapstersubjects:- kind: ServiceAccount name: heapster namespace: kube-system #应用kubectl apply -f heapster-rbac.yaml 部署heapster12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#资源文件https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/heapster.yaml，需要修改为如下样式apiVersion: v1kind: ServiceAccountmetadata: name: heapster namespace: kube-system---apiVersion: apps/v1 kind: Deploymentmetadata: name: heapster namespace: kube-systemspec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: heapster template: metadata: labels: task: monitoring k8s-app: heapster spec: serviceAccountName: heapster containers: - name: heapster image: k8s.gcr.io/heapster-amd64:v1.5.4 imagePullPolicy: IfNotPresent command: - /heapster - --source=kubernetes:https://kubernetes.default - --sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086---apiVersion: v1kind: Servicemetadata: labels: task: monitoring # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons) # If you are NOT using this as an addon, you should comment out this line. kubernetes.io/cluster-service: 'true' kubernetes.io/name: Heapster name: heapster namespace: kube-systemspec: ports: - port: 80 targetPort: 8082 type: NodePort selector: k8s-app: heapster #应用kubectl apply -f heapster.yaml 部署grafana123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#资源文件，https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/grafana.yaml，需要修改为如下样式apiVersion: apps/v1 kind: Deploymentmetadata: name: monitoring-grafana namespace: kube-systemspec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: grafana template: metadata: labels: task: monitoring k8s-app: grafana spec: containers: - name: grafana image: k8s.gcr.io/heapster-grafana-amd64:v5.0.4 ports: - containerPort: 3000 protocol: TCP volumeMounts: - mountPath: /etc/ssl/certs name: ca-certificates readOnly: true - mountPath: /var name: grafana-storage env: - name: INFLUXDB_HOST value: monitoring-influxdb - name: GF_SERVER_HTTP_PORT value: \"3000\" # The following env variables are required to make Grafana accessible via # the kubernetes api-server proxy. On production clusters, we recommend # removing these env variables, setup auth for grafana, and expose the grafana # service using a LoadBalancer or a public IP. - name: GF_AUTH_BASIC_ENABLED value: \"false\" - name: GF_AUTH_ANONYMOUS_ENABLED value: \"true\" - name: GF_AUTH_ANONYMOUS_ORG_ROLE value: Admin - name: GF_SERVER_ROOT_URL # If you're only using the API Server proxy, set this value instead: # value: /api/v1/namespaces/kube-system/services/monitoring-grafana/proxy value: / volumes: - name: ca-certificates hostPath: path: /etc/ssl/certs - name: grafana-storage emptyDir: &#123;&#125;---apiVersion: v1kind: Servicemetadata: labels: # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons) # If you are NOT using this as an addon, you should comment out this line. kubernetes.io/cluster-service: 'true' kubernetes.io/name: monitoring-grafana name: monitoring-grafana namespace: kube-systemspec: # In a production setup, we recommend accessing Grafana through an external Loadbalancer # or through a public IP. # type: LoadBalancer # You could also use NodePort to expose the service at a randomly-generated port # type: NodePort ports: - port: 80 targetPort: 3000 selector: k8s-app: grafana type: NodePort #应用kubectl apply -f grafana.yaml 新监控体系上面讲的HeapSter监控体系在k8s1.11时已经被废弃，现在是普遍使用的是metrics-server来代替HeapSter进行资源指标的获取。另外，现在还使用prometheus进行自定义资源指标的获取(需要k8s-prometheus-adapter将自定义的监控数据转换成指标格式)，并且它本身还是一个监控系统，用于监控例如CPU、内存、报文收发、进程切换等指标。 整体监控体系主要分两部分： 核心指标流水线：由kubelet、metrics-server以及由APIServer提供的api组成，主要有：CPU累计使用率、内存实时使用率、Pod资源占用率及容器的磁盘占用率等。这些资源需要被系统其他进程所使用，例如top。 监控流水线：用于从系统收集各种指标数据并提供中断用户、存储系统及HPA，它包含核心指标和非核心指标。但是非核心指标本身不能被k8s所解析，需要转换成固定指标格式才可以。 metrics-server由于k8s不支持heapSter，为了获取系统核心指标而提出了metrics-server。它作为一个server工作，类似于APIServer，它拓展了k8s本身所没有的群组，从而实现资源监控功能。在多个server模型下，需要一个kube-aggregator聚合器来实现对外统一，以后用户访问时都通过这个聚合器进行访问，这样就可以即访问k8s原生的k8s群组，也可以使用拓展的metrics-server群组。 123456789101112131415#部署https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/metrics-serverfor i in auth-delegator.yaml auth-reader.yaml metrics-apiservice.yaml metrics-server-deployment.yaml metrics-server-service.yaml resource-reader.yaml ;do wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/metrics-server/$i; donekubectl apply -f .#注意下载下来的yaml文件不能直接使用，需要修改两个文件#修改resource-reader.yaml，在resources字段下增加node/stats，这是节点数据获取的资源路径resources: - node/stats#修改metrics-server-deployment.yaml，在deployment的command字段修改端口为10250，为kubeletcommand:- --kubelet-port=10250#使用top命令不出错说明配置成功kubectl top Prometheus架构 它本身是一个监控工具，分为server端和agent端，server端从被监控主机获取数据，而agent端需要部署一个node_exporter，主要用于数据采集和暴露node节点的数据，对于获取Pod级别或者是mysql等多种应用的数据时，需要部署相关的exporter来暴露。Prometheus部署过后会自动通过metricURL向各个pod采集数据，可以通过PromQL的方式对数据进行查询，但是由于本身prometheus属于第三方的解决方案，原生的k8s系统并不能对Prometheus的自定义指标进行解析，需要使用kube-state-metrics来转换，然后借助于k8s-prometheus-adapter将其配置为APIServer聚合到一起，从而能被访问。 Prometheus通过pull metrics向每个exporter获取指标数据。也可以被动的接收，各个组件可以将数据推送至Push Gateway，由Prometheus从push gateway获取数据。获取到数据后，将这些数据存储到自己内建的时序存储数据库中。Prometheus通过Service Discovery来发现服务，从而知道需要监控哪些服务。对于获取的数据来说它支持API client、web UI、grafana来显示数据(将prometheus当作数据源)。当Prometheus发生异常时会将信息发送给一个外部独立组件Alertmanager，它负责发送报警信息。 部署1234567891011121314151617181920212223242526272829303132333435#https://github.com/iKubernetes/k8s-promgit clone https://github.com/iKubernetes/k8s-prom.git#创建名称空间promkubectl apply -f namespace.yaml#部署exporter，在prom名称空间中创建DaemonSetcd node_exporter/kubectl apply -f .#部署Prometheus，需要删除deploy的资源限制cd prometheus/kubectl apply -f .#部署kube-state-metrics，用于转换指标cd kube-state-metrics/kubectl apply -f .#部署k8s-prometheus-adapter，本身是http协议，需要k8s签署一个证书给他#制作证书cd /etc/kubernetes/pki/(umask 077; openssl genrsa -out serving.key 2048)openssl req -new -key serving.key -out serving.csr -subj \"/CN=serving\"openssl x509 -req -in serving.csr -CA ./ca.crt -CAkey ./ca.key -CAcreateserial -out serving.crt -days 3650#创建secretkubectl create secret generic cm-adapter-serving-certs --from-file=serving.crt=./serving.crt --from-file=serving.key -n prom#部署k8s-prometheus-adapter，注意自带的custom-metrics-apiserver-deployment.yaml和custom-metrics-config-map.yaml有问题，需要重新下载，并且修改名称空间为promwget https://raw.githubusercontent.com/DirectXMan12/k8s-prometheus-adapter/master/deploy/manifests/custom-metrics-apiserver-deployment.yamlwget https://raw.githubusercontent.com/DirectXMan12/k8s-prometheus-adapter/master/deploy/manifests/custom-metrics-config-map.yaml#注意部署后可以使用grafana进行数据绑定需要注意grafana和Prometheus通信属于pod通信，配置时的url写为http://prometheus.prom.svc:9090表示prom名称空间内的service，注意端口是9090，不是NodePort暴露出集群的端口 HPAHorizontal Pod Autoscaling，简称HPA，用于实现Pod的动态增减功能。HPA会从Heapster或者用户自定义的RESTclient端获取每个Pod利用率或原始值的平均值，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值并进行相应的操作。HPA也是k8s集群的资源对象。 实例12345678#创建podkubectl run nginx --image=nginx --replicas=1 --requests='cpu=50m,memory=256Mi' --limits='cpu=50m,memory=256Mi' --labels='app=nginx' --expose --port=80#设置autoscalekubectl autoscale deployment nginx --min=1 --max=8 --cpu-percent=60#暴露service端口进行压测kubectl patch svc nginx -p '&#123;\"spec\":&#123;\"type\":\"NodePort\"&#125;&#125;'#压测ab -c 1000 -n 500000 http://192.168.163.135:32126 资源定义123456789101112131415161718192021apiVersion: autoscaling/v2beta1kind: HorizontalPodAutoscalermetadata: name: ngixn-hpaspec: minReplicas: 10 #最大pod数量 maxReplicas: 1 #最小pod数量 scaleTargetRef: #针对扩容deployment apiVersion: apps/v1 kind: Deployment #需要扩容的类型 name: nginx #需要扩容的deployment名称 targetCPUUtilizationPercentage: 90 #CPU使用率，平均数 metrics: #对哪些指标进行评估 - type: Resource resource: name: cpu targetAverageUtilization: 55 - type: Resource resource: name: memory targetAverageValue: 50Mi","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"metrics","slug":"metrics","permalink":"http://yoursite.com/tags/metrics/"},{"name":"prometheus","slug":"prometheus","permalink":"http://yoursite.com/tags/prometheus/"}],"author":"Frdqy"},{"title":"k8s(7)-调度","slug":"k8s-7-调度","date":"2020-02-07T06:00:34.000Z","updated":"2020-02-07T06:01:50.961Z","comments":true,"path":"2020/02/07/k8s-7-调度/","link":"","permalink":"http://yoursite.com/2020/02/07/k8s-7-%E8%B0%83%E5%BA%A6/","excerpt":"概念当APIServer收到新的pod创建请求时会根据请求的资源清单使用schedule进行node节点调度。调度分为三个阶段：节点预选(Predicate)-&gt;节点优选(Priority)-&gt;节点选定(Select) 节点预选：基于一系列的预选规则对每个节点进行检查，将那些不符合条件的节点过滤(如端口冲突、资源不足等)，从而完成节点的预选 节点优选：对预选出的节点进行优先级排序，以便选出最合适运行Pod对象的节点 节点选定：从优先级排序结果中挑选出优先级最高的节点运行Pod，当这类节点多于1个时，则进行随机选择","text":"概念当APIServer收到新的pod创建请求时会根据请求的资源清单使用schedule进行node节点调度。调度分为三个阶段：节点预选(Predicate)-&gt;节点优选(Priority)-&gt;节点选定(Select) 节点预选：基于一系列的预选规则对每个节点进行检查，将那些不符合条件的节点过滤(如端口冲突、资源不足等)，从而完成节点的预选 节点优选：对预选出的节点进行优先级排序，以便选出最合适运行Pod对象的节点 节点选定：从优先级排序结果中挑选出优先级最高的节点运行Pod，当这类节点多于1个时，则进行随机选择 节点预选若定义多个预选策略，必须全部满足才可以通过预选。下面是常见的一些预算策略： CheckNodeCondition：检查节点是否工作正常 HostName：如果Pod对象拥有pod.spec.hostname属性，则检查节点名称字符串是否和该属性值匹配。 PodFitsHostPorts：如果Pod对象定义了pod.spec.container.ports.hostPort属性，则检查Pod指定的端口是否已经被节点上的其他容器或服务占用。 MatchNodeSelector：如果Pod对象定义了pod.spec.nodeSelector属性，则检查节点标签是否和该属性匹配。 NoDiskConflict：检查Pod对象请求的存储卷在该节点上可用。 PodFitsResources：检查节点上的资源（CPU、内存）可用性是否满足Pod对象的运行需求。 PodToleratesNodeTaints：如果Pod对象中定义了pod.spec.tolerations属性，则需要检查该属性值是否可以接纳节点定义的污点（taints），且node污点改变后默认仍接收。 PodToleratesNodeNoExecuteTaints：如果Pod对象定义了pod.spec.tolerations属性，检查该属性是否接纳节点的NoExecute类型的污点，node污点改变后如果不容忍则不接受。 CheckNodeLabelPresence：仅检查节点上指定的所有标签的存在性，要检查的标签以及其可否存在取决于用户的定义。 CheckServiceAffinity：将同一Service下的pod节点优先放在一个node上。 MaxEBSVolumeCount：检查节点上是否已挂载EBS存储卷数量是否超过了设置的最大值，默认值：39 MaxGCEPDVolumeCount：检查节点上已挂载的GCE PD存储卷是否超过了设置的最大值，默认值：16 MaxAzureDiskVolumeCount：检查节点上已挂载的Azure Disk存储卷数量是否超过了设置的最大值，默认值：16 CheckVolumeBinding：检查节点上已绑定和未绑定的PVC是否满足Pod对象的存储卷需求。 NoVolumeZoneConflct：在给定了区域限制的前提下，检查在该节点上部署Pod对象是否存在存储卷冲突。 CheckNodeMemoryPressure：在给定了节点已经上报了存在内存资源压力过大的状态，则需要检查该Pod是否可以调度到该节点上。 CheckNodePIDPressure：如果给定的节点已经报告了存在PID资源压力过大的状态，则需要检查该Pod是否可以调度到该节点上。 CheckNodeDiskPressure：如果给定的节点存在磁盘资源压力过大，则检查该Pod对象是否可以调度到该节点上。 MatchInterPodAffinity：检查给定的节点能否可以满足Pod对象的亲和性和反亲和性条件，用来实现Pod亲和性调度或反亲和性调度。 节点优选预选后的一些列节点列表会进入优选阶段，在这个过程schedule会向每个通过预选的节点传递一系列的优选函数来计算其优先级分值，优先级分值介于0-10之间，其中0表示不适用，10表示最适合托管该Pod对象。另外，调度器还支持给每个优选函数指定一个简单的值，表示权重，进行节点优先级分值计算时，它首先将每个优选函数的计算得分乘以权重，然后再将所有优选函数的得分相加，从而得出节点的最终优先级分值。权重可以让管理员定义优选函数倾向性的能力，其计算优先级的得分公式如下： 1234finalScoreNode = (weight1 * priorityFunc1) + (weight2 * priorityFunc2) + ......#注意weight表示该优选函数的权重priorityFunc表示该优选函数的优先级 least_requested：选择消耗最小的节点（根据空闲比率评估 cpu((总容量-已使用)*10/总容量) ） most_requested：选择消耗最大的节点上（尽量将一个节点上的资源用完） balanced_resource_allocation：从节点列表中选出各项资源使用率最均衡的节点（CPU和内存） node_prefer_avoid_pods：节点倾向。判断节点是否有注解”scheduler.alpha.kubernetes.io/preferAvoidPods”，如果有就权重为0，没有则权重为10000。 taint_toleration：将pod对象的spec.toleration与节点的taints列表项进行匹配度检查，匹配的条目越多，得分越低。 selector_spreading：与services上其他pod尽量不在同一个节点上，节点上通一个service的pod越少得分越高。 interpod_affinity：遍历node上的亲和性条目，与pod亲和性匹配项越多的得分越高 node_label：根据节点标签得分，存在标签既得分，没有标签没得分。标签越多得分越高。 image_locality：节点上有所需要的镜像既得分，所需镜像越多得分越高。（根据已有镜像体积大小之和） 节点亲和性节点亲和性指的是pod定义的pod.spec.affinity.nodeAffinity字段定义的标签列表和node节点的标签的匹配程度。 定义节点亲和性规则有2种： 硬亲和性（require）：实现的是强制性规则，是Pod调度时必须满足的规则，否则Pod对象的状态会一直是Pending 软亲和性（preferred）：实现的是一种柔性调度限制，在Pod调度时可以尽量满足其规则，在无法满足规则时，可以调度到一个不匹配规则的节点之上。 硬亲和性实例1234567891011121314151617181920#定义pod-nodeaffinity-demo.yamlapiVersion: v1kind: Podmetadata: name: with-require-nodeaffinityspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: zone operator: In values: - foo - bar containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent 软亲和性实例123456789101112131415161718192021#定义pod-nodeaffinity-demo.yamlapiVersion: v1kind: Podmetadata: name: with-prefered-nodeaffinityspec: affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: zone operator: In values: - foo - bar weight: 60 containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent Pod亲和性pod之间也需要亲和性调度。比如NMP架构，NMP三种服务的pod放在一个物理主机或者同一个机柜的物理主机上，那么他们的通信效率肯定是很高的。 调度器把第一个Pod放到任意位置，然后和该Pod有亲和或反亲和关系的Pod根据该动态完成位置编排，这就是Pod亲和性和反亲和性调度的作用。Pod的亲和性定义也存在硬亲和性和软亲和性的区别，其约束的意义和节点亲和性类似。 另外，对于同一位置的理解是根据不同的。例如可以根据主机名来作为同一位置的标准，那么具有亲和性的pod都会被调度到同一主机上；再比如将同一机架上的主机打上标签标明是同一组主机，亲和性以该标签为标准，那么pod调度时就会被调度到一组主机的一个上面。 硬亲和实例1234567891011121314151617181920212223242526272829303132333435363738394041#apiVersion: v1kind: Podmetadata: name: pod-first labels: myapp: nginx tier: frontendspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent---apiVersion: v1kind: Podmetadata: name: pod-second labels: myapp: nginx-back tier: frontend-backspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent affinity: podAffninity: requiredDuringSchedulingIngnoreDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - nginx topologyKey: kubernetes.io/hostname#注意labelSelector &lt;Object&gt;：指明与哪些pod亲和namespace &lt;[]string&gt;：指明labelSelector选中的pod匹配哪个名称空间的pod，不指默认该pod当前名称空间topologyKey &lt;string&gt;：用于定义位置标准，kubernetes.io/hostname表示以node节点的主机名作为位置判断 软亲和实例1234567891011121314151617181920212223242526272829303132333435363738#大体上与节点亲和一样apiVersion: v1kind: Podmetadata: name: pod-first-prefer labels: myapp: nginx tier: frontendspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent---apiVersion: v1kind: Podmetadata: name: pod-second-prefer labels: myapp: nginx-back tier: frontend-backspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent affinity: podAffninity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 80 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - nginx topologyKey: kubernetes.io/hostname 反亲和实例12345678910111213141516171819202122232425262728293031323334353637383940#给node节点打标，使得第一个pod配到一个node后由于反亲和，另一个pod必然处于pending状态kubectl label nodes node1.day.com zone=fookubectl label nodes node2.day.com zone=foo#定义资源apiVersion: v1kind: Podmetadata: name: pod-first labels: myapp: nginx tier: frontendspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent---apiVersion: v1kind: Podmetadata: name: pod-second labels: myapp: nginx-back tier: frontend-backspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent affinity: podAntiAffninity: requiredDuringSchedulingIngnoreDuringExecution: - labelSelector: matchExpressions: - key: app operator: in values: - nginx topologyKey: zone 污点调度污点是定义在node上的一组键值型数据，用来让node拒绝将Pod调度到该节点上，除非该Pod对象具有容纳节点污点的容忍度。而容忍度是定义在Pod对象上的键值型数据，用来配置让Pod对象可以容忍节点的污点。 前面的节点选择器和节点亲和性的调度方式都是通过在Pod对象上添加标签选择器来完成对特定类型node标签的匹配，实现的是Pod选择节点的方式。而污点和容忍度则是通过对node添加污点信息来控制Pod对象的调度结果，让node拥有了控制哪种Pod对象可以调度到该节点上的 一种方式。 Kubernetes使用PodToleratesNodeTaints预选策略和TaintTolerationPriority优选函数来完成这种调度方式。 定义污点1234567891011#node.spec.taints.effect定义node对pod的排斥效果NoSchedule：只影响调度过程，对已有的pod不产生影响NoExecute：既影响调度过程也影响现存的pod对象，不容忍的pod会被驱逐PreferNoSchedule：程度比第一个轻，无其他可调度的node时可以调度到该node#定义taint格式key=value:effect表示对于该键值的污点如果pod不能容忍，那么执行effect相对应的排斥效果#命令kubectl taint node node1.dqy.com node-type=production:NoSchedule 定义容忍度1234567891011121314151617181920212223#Equaltolerations:- key: \"node-type\" operator: \"Equal\" value: \"production\" effect: \"Noexecute\" tolerationSeconds: 10#Existstolerations: - key: \"node-type\" operator: \"Exists\" value:\"\" effect: \"Noexecute\" tolerationSeconds: 3600#operator字段选项Equal：等值比较，表示容忍度和污点必须在key、value、effect三者之上完全匹配。Exists：存在性判断，表示二者的key和effect必须完全匹配，而容忍度中的value字段使用空值。#注意第一个使用Equal操作模式，表示node上的node-type字段的值为production，且Noexecute的污点可以容忍第二个使用Exists操作模式，表示node上只要存在node-type字段且Noexecute的污点，可以容忍","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"污点","slug":"污点","permalink":"http://yoursite.com/tags/%E6%B1%A1%E7%82%B9/"},{"name":"容忍度","slug":"容忍度","permalink":"http://yoursite.com/tags/%E5%AE%B9%E5%BF%8D%E5%BA%A6/"}],"author":"Frdqy"},{"title":"k8s(6)-网络配置","slug":"k8s-6-网络配置","date":"2020-02-06T06:36:03.000Z","updated":"2020-02-06T06:41:22.596Z","comments":true,"path":"2020/02/06/k8s-6-网络配置/","link":"","permalink":"http://yoursite.com/2020/02/06/k8s-6-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/","excerpt":"基础通信方式 容器间通信：同一个pod内的多个容器间的通信，使用lo接口 pod间通信：overlay叠加网络实现。直达，不要经过NAT转换 pod与service通信：由iptables规则或者lvs规则实现。直达，不要经过NAT转换 service与集群外部通信：配置nodePort或者ingress","text":"基础通信方式 容器间通信：同一个pod内的多个容器间的通信，使用lo接口 pod间通信：overlay叠加网络实现。直达，不要经过NAT转换 pod与service通信：由iptables规则或者lvs规则实现。直达，不要经过NAT转换 service与集群外部通信：配置nodePort或者ingress 实现格式 k8s集群自身不提供网络解决方案，它支持CNI接口的插件来解决。CNI的主要核心是：在创建容器时，先创建好网络名称空间（netns），然后调用CNI插件为这个netns配置网络，最后在启动容器内的进程。每次Pod被初始化或删除，kubelet都会调用默认的CNI插件去创建一个虚拟设备接口附加到相关的底层网络，为Pod去配置IP地址、路由信息并映射到Pod对象的网络名称空间。网络插件存放在/etc/cni/net.d目录下，由kubelet加载该目录下的网络插件，根据其type属性到/opt/cni/bin中查找相关的插件二进制文件，由这些二进制文件和配置文件代为分配网络地址、创建等信息。常见的插件有：flannel、calico、canel等。 Flannel：为Kubernetes提供叠加网络的网络插件，基于TUN/TAP隧道技术，使用UDP封装IP报文进行创建叠 加网络，借助etcd维护网络的分配情况，缺点：无法支持网络策略访问控制。 Calico：基于BGP的三层网络插件，也支持网络策略进而实现网络的访问控制；它在每台主机上都运行一个虚拟路由，利用Linux内核转发网络数据包，并借助iptables实现防火墙功能。实际上Calico最后的实现就是将每台主机都变成了一台路由器，将各个网络进行连接起来，实现跨主机通信的功能。 Canal：由Flannel和Calico联合发布的一个统一网络插件，提供CNI网络插件，并支持网络策略实现。 其他的还包括Weave Net、Contiv、OpenContrail、Romana、NSX-T、kube-router等等。而Flannel和Calico是目前最流行的选择方案。 Flannelflannel使用叠加式网络进行pod间通信，通过节点上的flannel.1网卡实现隧道来通信。当前节点有pod时会创建一个eni接口的网卡，它的地址是与flannel.1网卡同网络，用于隧道通信。flannel作为pod以daemonset的方式工作在各个具有kubelet的node节点上，用于kubelet调用flannel进行网络部署。因此，有多少node节点(拥有kubelet)就有多少个flannel pod。 创建flannel的过程在第一章讲过，此处不再赘述。 配置参数12345678910#查看配置信息kubectl get configmap kube-flannel-cfg -o yaml -n kube-system#常见参数Network：flannel使用的CIDR格式的网络地址，用于为Pod配置网络功能例如Network：10.244.0.0/16，代表master：10.244.0.0/24、node1：10.244.1.0/24以此类推Subnetlen：把network切分子网供个节点使用时，使用多长的掩码进行切分，默认为24位，表示每个node可以创建256个podSubnetMin：子网起始SubnetMax：子网最大Backend：指明pod间通信方式vxlan、host-gw、udp 通信流程123456789101112131415161718192021222324#查看master网卡，会发现几个特殊的，有flannel、cni和一些veth开头的网卡ifconfig#查看master路由信息ip route showdefault via 192.168.163.2 dev ens33 proto dhcp metric 100 10.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.1 10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink 10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 192.168.163.0/24 dev ens33 proto kernel scope link src 192.168.163.132 metric 100#查看cni0网卡的虚拟网桥信息brctl show cni0bridge name bridge id STP enabled interfacescni0 8000.eae2fc220dba no veth2bdcb591 veth3648ee64 veth6cca7eb2 veth899cf515#注意cni为flannel创建的虚拟网桥，用于pod本地通信使用flannel为每个Pod创建一对veth虚拟设备，一端放在容器接口上，一端放在cni0桥上(和docker一样)上面这些路由信息可以看出，发送到主机10.244.2.0/24及10.244.1.0/24网段的报文都通过flannel.1网卡接口进行隧道封装(VxLAN协议) VxLAN默认情况下使用VxLAN协议实现隧道方式进行不通过主机间pod通信，其报文格式如下图： 它支持两种方式： 第一种是当运行pod的node节点处于 同一网段中时使用Directrouting方式进行通信，即将该pod的物理主机网卡当作网关，发往其他主机的报文通过网卡查路由表进行转发；这种方式传输效率很高，类似host-gw模式 第二种是当pod处于不同网段时，使用隧道进行叠加式网络通信，其中隧道是以太网帧的二层隧道。 123456789101112131415#默认为VxLAN隧道模式，此处演示修改为Directrouting模式#修改configmap&#123; \"Network\": \"10.244.0.0/16\", #默认网段 \"Backend\": &#123; \"Type\": \"vxlan\", \"Directrouting\": true #增加 &#125;&#125;#重新应用kubectl apply -f kube-flannel.yml#注意修改flannel时使用edit不能生效，需要重新部署 host-gw该方式类似于VxLAN的Directrouting模式，即不同node节点处于同一网段中时，其上的pod直接使用node物理网卡进行通信，网卡上维护路由表用于路由转发，因此必须处于同一网段，否则可能会被路由转发到其他主机。 具体配置只需要改Backend字段的type字段即可 1234567#修改配置文件&#123; \"Network\": \"10.244.0.0/16\", #默认网段 \"Backend\": &#123; \"Type\": \"host-gw\" &#125;&#125; Canal上文提到的Flannel只是一款网络地址分配的插件，它不具备网络策略功能。即在Flannel插件工作下，整个网络各个pod之间都可以通信，它不具备隔离某些pod间通信的功能。因此为了实现网络策略功能，通常使用Calico实现网络策略功能，而flannel实现地址分配功能，二者结合就变成了Canal。 部署12345678#部署RBACkubectl apply -f https://docs.projectcalico.org/v3.2/getting-started/kubernetes/installation/hosted/canal/rbac.yaml#部署canalkubectl apply -f https://docs.projectcalico.org/v3.2/getting-started/kubernetes/installation/hosted/canal/canal.yaml#注意Canal作为DaemonSet部署到每个节点，属于kube-system这个名称空间 配置策略 在Kubernetes系统中，报文的流入和流出的核心组件是Pod资源，它们也是网络策略功能的主要应用对象。NetworkPolicy对象通过podSelector选择 一组Pod资源作为控制对象。NetworkPolicy是定义在一组Pod资源之上用于管理入站(ingress)流量，或出站(egress)流量的一组规则，有可以是出入站规则一起生效，规则的生效模式通常由spec.policyTypes进行定义。 默认情况下，Pod对象的流量控制是为空的，报文可以自由出入。在附加网络策略之后，Pod对象会因为NetworkPolicy而被隔离，一旦名称空间中有任何NetworkPolicy对象匹配了某特定的Pod对象，则该Pod将拒绝NetworkPolicy规则中不允许的所有连接请求，但是那些未被匹配到的Pod对象依旧可以接受所有流量。 就特定的Pod集合来说，入站和出站流量默认是放行状态，除非有规则可以进行匹配。还有一点需要注意的是，在networkpolicy.spec.policyTypes中指定了生效的规则类型，但是在networkpolicy.spec字段中嵌套定义了没有任何规则的Ingress或Egress时，则表示拒绝入站或出站的一切流量。即默认的ingress和egress规则都是拒绝一切。 资源定义networkpolicy自身就是k8s集群的资源对象。 123456789101112131415#spec属性egress &lt;[]Object&gt; #定义出站规则 ports &lt;[]Object&gt; #定义目标端口 port &lt;string&gt; #端口 protocol &lt;string&gt; #协议 to &lt;[]Object&gt; #定义目标地址 ipBlock &lt;Object&gt; #目标为ip地址范围或主机的pod namespaceSelector #目标为名称空间内所有pod podSelector &lt;Object&gt;#目标为一组pod ingress &lt;[]Object&gt; #定义入站规则，与egress相似 from &lt;[]Object&gt; ports &lt;[]Object&gt;podSelector &lt;Object&gt; #定义管理的podpolicyTypes &lt;[]string&gt; #定义选择的策略类型 实例设置两个名称空间，一个为dev，一个为prod。下面进行不同名称空间访问的控制 创建名称空间 12kubectl create namespace devkubectl create namespace prod 定义networkpolicy规则 123456789101112131415161718apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-ingressspec: podSelector: &#123;&#125; policyTypes: - Ingress#应用于dev名称空间kubectl apply -f ingress-def.yaml -n dev #注意podSelector为空表示选择所有名称空间中的podpolicyTypes选择了ingress而没定义ingress表示使用ingress默认规则，即拒绝所有请求如果明确定义ingress但内容为空，则表示允许全部，如下所示 ingree: - &#123;&#125; 在dev名称空间下创建pod 12345678910111213141516apiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent #应用kubectl apply -f pod-a.yaml -n devkubectl apply -f pod-a.yaml -n prod#注意上述创建好后可以使用master访问prod名称空间的prod，但无法访问dev名称空间的pod 修改dev名称空间下的ingress规则，允许外部访问 12345678910111213141516171819202122232425#将pod1打标签，用于被ingress的podSelector控制kubectl label pods pod1 app=nginx -n dev#apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-nginx-ingressspec: podSelector: matchLabels: app: nginx ingress: - from: - ipBlock: cidr: 10.244.0.0/16 except: - 10.244.1.2/32 ports: - protocol: TCP port: 80 - protocol: TCP port: 443#注意上述ingress规则表示允许10.244.0.0/16网段的主机且标签app为nginx访问，但不允许10.244.1.2/32访问，对外开放端口为tcp/80，tcp/443","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"VxLAN","slug":"VxLAN","permalink":"http://yoursite.com/tags/VxLAN/"},{"name":"flannel","slug":"flannel","permalink":"http://yoursite.com/tags/flannel/"},{"name":"canal","slug":"canal","permalink":"http://yoursite.com/tags/canal/"}],"author":"Frdqy"},{"title":"k8s(5)-认证","slug":"k8s-5-认证","date":"2020-02-05T03:35:24.000Z","updated":"2020-02-05T03:39:49.231Z","comments":true,"path":"2020/02/05/k8s-5-认证/","link":"","permalink":"http://yoursite.com/2020/02/05/k8s-5-%E8%AE%A4%E8%AF%81/","excerpt":"基础在与APIServer交互时需要做认证、权限检查、准入控制来确保集群资源安全。与APIServer交互的对象有两种，一种是工作在集群外部的用户使用kubectl来访问APIServer对外端口，另一种是集群内部pod节点通过service访问。","text":"基础在与APIServer交互时需要做认证、权限检查、准入控制来确保集群资源安全。与APIServer交互的对象有两种，一种是工作在集群外部的用户使用kubectl来访问APIServer对外端口，另一种是集群内部pod节点通过service访问。 12345#该service就是集群内pod节点访问APIServer的servicekubectl get service kubernetes#查看详细信息，可以看到master的地址是该service的Endpoints地址kubectl describe service kubernetes 每个pod或多或少都需要和APIServer进行通信，因此在其创建时都会默认设置一个存储卷，该卷是一个token信息，它以存储卷的形式挂载到pod的容器内，使得该容器能够使用该token来与APIServer通信时进行认证。 资源请求在整个k8s集群的资源请求中，kubectl命令对资源的操作实际是对http的访问路径，可以通过本地代理kubectl访问集群来实现http的资源请求 1234567891011#资源请求格式/apis/&lt;GROUP&gt;/&lt;VERSION&gt;/namespaces/&lt;NAMESPACE_NAME&gt;/&lt;KIND&gt;[/OBJECT_ID]#代理，使用curl命令访问本地8080端口实现对集群资源的访问kubectl proxy --port=8080#访问路径http://ip:port/apis/apps/namespaces/default/deployments/nginx-deployapis整个资源的访问入口apps是apis的一个组因此，之前使用kubectl命令对各种资源的操作实际就是对资源路径的操作 请求动作http请求需要转换为对API对象的请求来进行访问 http：get、post、put、delete API request：get、list、create、update、patch、watch、proxy、redirect、delete、deletecollection 访问用户整个k8s集群中访问APIServer的用户有两类，一类为Useraccount，另一类为Serviceaccount，区别如下： User account是为人设计的，而service account则是为Pod中的进程调用Kubernetes API而设计； User account是跨namespace的，而service account则是仅局限它所在的namespace； 每个namespace都会自动创建一个default service account； Token controller检测service account的创建，并为它们创建secret 总结APIServer是整个访问请求进入的网关接口，请求过程中认证用于实现身份识别，授权用于实现权限检查，准入控制用于补充权限检查功能，一般在创建、修改、删除、代理等情况下做补充。 ServiceAccount它是一个k8s对象资源。当集群内pod节点与APIServer交互时，需要pod提供认证信息，该信息定义在pod上的serviceaccount字段中。serviceaccount是仅局限它所在的namespace中有意义的，且每个namespace都会自动创建一个default service account，当创建 pod 的时候，如果没有指定一个 service account，系统会自动在与该pod 相同的 namespace 下为其指派一个default service account。而pod和APIserver之间进行通信的账号，称为serviceAccountName。 12#查看默认sa，其名称为defaultkubectl get sa 默认的service account 仅仅只能获取当前Pod自身的相关属性，无法观察到其他名称空间Pod的相关属性信息。如果想要扩展Pod，假设有一个Pod需要用于管理其他Pod或者是其他资源对象，是无法通过自身的名称空间的serviceaccount进行获取其他Pod的相关属性信息的，此时就需要进行手动创建一个serviceaccount，并在创建Pod时进行定义。 自定义serviceaccount 1234kubectl create serviceacount admin#注意创建后会在sa里新建一个admin名称的sa；在secret中也会创建一个admin名称的token做认证使用 创建pod并设置其serviceAccountName 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: pod-sa-demo namespace: default labels: app: nginxspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 serviceAccountName: admin#注意serviceAccountName用于与已创建的sa绑定 认证配置文件各个APIServer客户端与APIServer通信时不仅可以使用上述的Serviceaccount来进行认证，还可以使用配置文件进行认证 1234567891011121314151617181920212223242526272829#查看配置文件kubectl config view#详细信息apiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://192.168.163.132:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: &#123;&#125;users:- name: kubernetes-admin user: client-certificate-data: REDACTED client-key-data: REDACTED #注意clusters表示集群列表，可以定义多个集群从而控制多个集群users表示用户列表contexts表示上下文列表，用于指明用哪个user访问哪个clustercurrent-context：表示当前使用哪个user访问哪个cluster 在/etc/kubernetes/pki文件中都是整个k8s集群的ca证书和密钥，其中有ca.crt证书用于签署哪些用户可以连入APIServer中。下面演示自建账户并使用APIServer的ca签署流程 123456789101112131415161718192021222324#生成私钥(umask 077;openssl genrsa -out dqy.key 2048)#生成证书，且由ca.crt签署#生成证书申请请求openssl req -new -key dqy.key -out dqy.csr -subj \"/CN=dqy\"#用ca.crt签署openssl x509 -req -in dqy.csr -CA ./ca.crt -CAkey ./ca.key -CAcreateserial -out dqy.crt -days 365#查看证书内容openssl x509 -in dqy.crt -text -noout#创建集群用户kubectl config set-credentials dqy --client-certificate=./dqy.crt --client-key=./dqy.key --embed-certs=true#设置上下文kubectl config set-context dqy@kubernetes --cluster=kubernetes --user=dqy#设置当前上下文kubectl config use-context dqy@kubernetes#新增集群，使用新增集群的ca证书来进行认证kubectl config set-cluster e2e --server=\"https://192.168.163.132:6443\" --certificate-authority=~/.kube/e2e/kubernetes.ca.crt#注意CN的值就是你的需要访问APIServer的用户账号名CAcreateserial表示自建序列号text表示以文本格式不适用base64编码certificate-authority指明需要的集群ca上述创建的用户没有管理员权限，可以使用RBAC进行授权 RBACRole-based AC，即基于角色的访问控制。让一个用户(user)扮演一个角色(Role)，这个用户就拥有了该角色的权限，并且后续的权限授予都只针对角色而不是用户来进行。主要用于为上文中创建出用户的权限进行授予。 在集群中的所有操作都是在某个对象上施加的某种行为，一个对象上许可的行为组合起来就叫做许可权限，可以在role上授予该role具有某些许可权限。首先定义role，role中需要定义operations和object。之后使用rolebinding将role绑定到user(user account、service account)上实现名称空间级别的授权。 在k8s中有两类资源，一类是名称空间级资源，一类是集群级资源。 在名称空间A中定义一个角色role，将User1和role进行rolebinding绑定，这样user1就获得了role上定义的在该名称空间内的资源的访问权限。 在集群定义角色clusterRole，通过clusterRoleBinding将其和User1进行绑定，那么它就拥有整个集群内的资源的访问权限。 注意，绑定可以跨界。换句话说，可以将user1通过RoleBinding绑定到ClusterRole中，注意虽然此时ClusterRole定义的是整个集群上的权限，但是由于使用NamespaceA中的RoleBinding进行绑定，那么此时User1只拥有该名称空间中的访问权限。(用谁绑定就拥有哪个级别的权限)。该操作适用于为每个名称空间设置一个管理员，如果使用rolebinding绑定role和user，那么需要定义多个role；而此处可以定义一个ClusterRole再使用对应名称空间的RoleBinding来绑定，也可以达到同样的效果。 上文提到的role、clusterRole、roleBinding、clusterRoleBinding都是k8s资源 定义role创建role 123456789#干跑模式，可以查看yaml格式kubectl create role pods-reader --verb=get,list,watch --resource=pods --dry-run -o yaml#查看创建的rolekubectl get role#注意verb：指明资源请求动作resource：指明资源对象resource names：具体资源的名称 创建roleBinding并绑定 12345678#干跑模式，可以查看yaml格式kubectl create rolebinding dqy-read-pods --role=pods-reader --user=dqy --dry-run -o yaml#查看绑定信息kubectl describe rolebinding dqy-read-pods#注意role：指明roleuser：要绑定的用户 定义clusterrole创建clusterRole 1kubectl create clusterrole cluster-read --verb=get,list,watch --resource=pods -o yaml 创建clusterRoleBinding并绑定 12#干跑一下看看kubectl create clusterrolebinding dqy-read-all-pods --clusterrole=cluster-read --user=dqy --dry-run -o yaml 跨界绑定使用roleBinding绑定clusterRole，将clusterRole降级为普通role 12#干跑看一下kubectl create rolebinding dqy-read-pods --clusterrole=cluster-read --user=dqy --dry-run -o yaml dashboard部署12345678910111213141516171819kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc3/aio/deploy/recommended.yaml#会创建如下资源namespace/kubernetes-dashboard createdserviceaccount/kubernetes-dashboard createdservice/kubernetes-dashboard createdsecret/kubernetes-dashboard-certs createdsecret/kubernetes-dashboard-csrf createdsecret/kubernetes-dashboard-key-holder createdconfigmap/kubernetes-dashboard-settings createdrole.rbac.authorization.k8s.io/kubernetes-dashboard createdclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard createdrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard createdclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard createddeployment.apps/kubernetes-dashboard createdservice/dashboard-metrics-scraper createddeployment.apps/dashboard-metrics-scraper created#将service/kubernetes-dashboard改为nodeport进行集群外访问kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p '&#123;\"spec\":&#123;\"type\":\"NodePort\"&#125;&#125;' 认证部署成功并且暴露service端口后既有如下页面： 认证方式有两种，一种是token认证，一种是Kubeconfig认证 token认证dashboard安装在自建的名称空间kubernetes-dashboard中，如果想要dashboard的pod能够管理整个集群，就需要创建serviceaccount并将其绑定到clusterrole上，其中serviceaccount需要的token认证文件就是这里需要填入的token信息 123456789#将dashboard自带的serviceaccount和clusterrole进行绑定kubectl create clusterrolebinding dash-role-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:kubernetes-dashboard#获取该sa的token信息kubectl describe sa -n kubernetes-dashboard kubernetes-dashboard#从token信息中提取出tokenkubectl describe secret kubernetes-dashboard-token-wh87j -n kubernetes-dashboardeyJhbGciOiJSUzI1NiIsImtpZCI6Ik9FeEZPa0pTcnF6Yl9tMzVkQUZRS3lISTdVZjhvTGNGZ0lDdjJtQjRSQzAifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi13aDg3aiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjA1MDg4YjFhLTExMGEtNGFkNS04ZmQwLWZiYWFhNWM1NmM3OSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.7joqmYOT3AQKtJs8sQVx8mlYcb5Vy4R8NhZDSYGXzOA259DpIvbHeBZBJBi_SBnVsQ_XNZTinC33j8zSwlb5jdlTKBGLoWTdWxbaFgH3GjSXigSS5yq4h-7A-aVj_bjmycejnWDfzOG-vpqlXtmLabUWYCUa2Bihw_TnxTaWqNnNqqVHQ7Gaq8O84fe61W0gMUAWoZ2iQol2raohoEEzMURQceozSa_CaBxZd2X2gztWnBrqsmsG3PorVR-E7wt1bqYkW8OnTXat-T9FNChp3iDP70k-Le1CD7MzvyPE4L2U7MN_vHndRTbw9a9tFHbboO2Rx6qoJokA0hE7BbjdZA Kubeconfig认证kubeconfig配置文件也可以使用token来认证，将其添加到kubeconfig文件即可 1234567891011121314151617#创建serviceaccount并绑定role或者clusterrole，和上面一样，此处略#添加集群kubectl config set-cluster kubernetes --certificate-authority=/etc/kubernetes/pki/ca.crt --server=\"https://192.168.163.132:6443\" --embed-certs=true --kubeconfig=/root/def-ns-admin.conf#添加tokenKUBE_ADMIN_TOKEN=`kubectl get secret kubernetes-dashboard-token-wh87j -n kubernetes-dashboard -o jsonpath=&#123;.data.token&#125; | base64 -d`kubectl config set-credentials def-ns-admin --token=$KUBE_ADMIN_TOKEN --kubeconfig=/root/def-ns-admin.conf#添加上下文kubectl config set-context def-ns-admin@kubernetes --cluster=kubernetes --user=def-ns-admin --kubeconfig=/root/def-ns-admin.conf#设置当前上下文kubectl config use-context def-ns-admin@kubernetes --kubeconfig=/root/def-ns-admin.conf#查看完整配置文件kubectl config view --kubeconfig=/root/def-ns-admin.conf","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"认证","slug":"认证","permalink":"http://yoursite.com/tags/%E8%AE%A4%E8%AF%81/"},{"name":"dashboard","slug":"dashboard","permalink":"http://yoursite.com/tags/dashboard/"}],"author":"Frdqy"},{"title":"k8s(4)-存储卷","slug":"k8s-4-存储卷","date":"2020-02-03T04:18:18.000Z","updated":"2020-02-09T11:25:23.306Z","comments":true,"path":"2020/02/03/k8s-4-存储卷/","link":"","permalink":"http://yoursite.com/2020/02/03/k8s-4-%E5%AD%98%E5%82%A8%E5%8D%B7/","excerpt":"概念基础在docker中就引入了存储卷的概念，它在docker内和物理机做映射使得即使docker容器挂掉数据也保存在其他地方，下次启动docker时数据依然存在。但是在k8s集群体系中，pod作为最小的调度单位(因此存储卷概念是建立在pod之上)，如果pod挂掉还是要被调度器进行调度，那么就有可能调度到其他的node节点上，这样使得docker存储卷的处理方案行不通(因为docker挂掉不会被调度，一直在一个主机上)。上述情况只是pod挂掉就可能会导致pod调度到其他node，那么如果node挂掉情况会更加严重。 鉴于上述需求，k8s提出了脱离节点存在的存储概念。在此之前，考虑一个问题，为什么pod本身具有存储卷和网络名称空间？这取决于pod基础容器pause，这个容器是执行k8s初始化时拉取的一个容量很小的容器，它不启动，可以理解为它是pod的根，所有pod的网络名称空间等资源分配实际上是分配给pause镜像，在pod中运行的主容器是共享pause的网络名称空间，同理容器挂载存储卷也是挂载pause的存储卷而已。","text":"概念基础在docker中就引入了存储卷的概念，它在docker内和物理机做映射使得即使docker容器挂掉数据也保存在其他地方，下次启动docker时数据依然存在。但是在k8s集群体系中，pod作为最小的调度单位(因此存储卷概念是建立在pod之上)，如果pod挂掉还是要被调度器进行调度，那么就有可能调度到其他的node节点上，这样使得docker存储卷的处理方案行不通(因为docker挂掉不会被调度，一直在一个主机上)。上述情况只是pod挂掉就可能会导致pod调度到其他node，那么如果node挂掉情况会更加严重。 鉴于上述需求，k8s提出了脱离节点存在的存储概念。在此之前，考虑一个问题，为什么pod本身具有存储卷和网络名称空间？这取决于pod基础容器pause，这个容器是执行k8s初始化时拉取的一个容量很小的容器，它不启动，可以理解为它是pod的根，所有pod的网络名称空间等资源分配实际上是分配给pause镜像，在pod中运行的主容器是共享pause的网络名称空间，同理容器挂载存储卷也是挂载pause的存储卷而已。 k8s作为一个集群需要管理多个主机，各个主机的存储系统接口可能不一样，面对这么多的差异性提出了PVC和PV的概念。PVC全称为PersistentVolumeClaim，即持久卷申请，是对多个存储接口的抽象申请。PV全称为PersistentVolume，是分配的真实的存储管理空间。PVC的申请就是对PV进行操作。这里仍然存在一个问题：PV大小如何指定？即如何根据具体需求定制PV大小，虽然可以管理员定义，但是考虑云计算环境的不同用户的不同需求使用管理员手动创建显然不合实际，因此引入StorageClass概念，又叫存储类，它是对PV的抽象。当用户通过PVC申请存储空间时，通过StorageClass分配指定的PV给用户。 pv和pvc是kubernetes抽象出来的一种存储资源，定义方法与pod等类似。 PVPersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 PVCPersistentVolumeClaim（PVC）是用户存储的请求。PVC的使用逻辑：在pod中定义一个存储卷（该存储卷类型为PVC），定义的时候直接指定大小，pvc必须与对应的pv建立关系，pvc会根据定义去pv申请，而pv是由存储空间创建出来的。 StorageClass存储类，是对多个存储设备的封装(设备必须支持Restful格式的请求)，也是一个标准k8s的资源。定义存储类后，pvc申请对象不是pv而是存储类，由存储类动态创建出pv来满足申请。主要使用在多个应用场景下，不同的应用对存储性能要求的不同，因此将不同性能的存储设备分组对外提供可以很好的解决这个问题。 configMap它是一个k8s资源，作用相当于配置中心的作用。它可以通过挂载到pod上的某个容器内作为该容器进程的配置文件；也可以类似docker的entrypoint脚本一样对容器内的环境变量进行注入从而修改配置文件。总之，configMap实现的就是同一配置多个pod配置文件的功能。 secret它是一个类似configMap的k8s资源，功能实现和configMap一样，不过他是configMap的加密版。configMap采用明文传输，而secret采用base64编码传输(也比较容易反解)。一般密钥使用secret来定义，其它仍然使用configMap。 常见的secret类型有三种：docker-registry、tls、generic。 docker-registry：用于创建docker私有仓库的认证 tls：用于证书私钥等 generic：其他如mysql认证等 分类emptyDir只在节点本地使用，一旦pod被删除该存储卷也被删除，通常用于做临时目录、缓存(将物理机的内存空间作为存储空间)等 1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: nginx tier: frontendspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 volumeMounts: #在容器内定义挂载存储名称和挂载路径 - name: html mountPath: /usr/share/nginx/html/ - name: busybox image: busybox:latest imagePullPolicy: IfNotPresent volumeMounts: - name: html mountPath: /data/ #在容器内定义挂载存储名称和挂载路径 command: ['/bin/sh','-c','while true;do echo $(date) &gt;&gt; /data/index.html;sleep 2;done'] volumes: #定义存储卷 - name: html #定义存储卷名称 emptyDir: &#123;&#125; #定义存储卷类型 hostPath与docker存储卷一样，在物理机找一个目录作为pod的挂载目录，且该目录不能是pod名称空间中的目录，可以实现pod删除时存储卷仍然存在。该存储为node节点级存储，若node挂掉或者pod被调度到其他node上也会丢失数据。 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: pod-vol-hostpath namespace: defaultspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent volumeMounts: - name: html mountPath: /usr/share/nginx/html/ volumes: - name: html hostPath: path: /data/pod/volume1 type: DirectoryOrCreate#注意type类型可以参考https://kubernetes.io/docs/concepts/storage/volumes#hostpathDirectoryOrCreate：如果目录不存在就创建(物理主机被挂载的目录)FileOrCreate：如果文件不存在就就创建(物理主机被挂载的文件) 网络存储主要解决hostPath存储遇到node节点不同时数据丢失的问题，此处以NFS为例，NFS主机IP为192.168.163.137 12345678910111213141516171819#在NFS主机安装nfs，其他主机也要安装否则无法挂载yum install -y nfs-utils#启动nfs和rpcbind服务，rpcbind必须在nfs之前启动systemctl start rpcbindsystemctl start nfs#创建共享目录mkdir /data/volumes -pv#编辑/etc/exports文件，或者编辑/etc/exports.d/下的文件/data/volumes 192.168.163.0/24(rw,no_root_squash)#在node1/2主机(192.168.163.135)上挂载，需要提前在/etc/hosts做域名解析mount -t nfs node3:/data/volumes /mnt#导出exportexportfs -arvshowmount -e 编写nfs.yaml文件 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: pod-vol-nfs namespace: defaultspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent volumeMounts: - name: html mountPath: /usr/share/nginx/html/ volumes: - name: html nfs: path: /data/volumes server: node3.dqy.io 实例定义PVC/PV在网络存储基础上构建PV。 配置nfs存储 12345#在nfs上创建多个目录mkdir /data/volumes/v&#123;1,2,3,4,5&#125;#导出exportfs -arvshoumount -e 定义pv 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#pv-demo.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv001 labels: name: pv001spec: nfs: path: /data/volumes/v1 server: node3.day.io accessModes: [\"ReadWriteMany\"] capacity: storage: 1Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv002 labels: name: pv002spec: nfs: path: /data/volumes/v2 server: node3.day.io accessModes: [\"ReadWriteMany\"] capacity: storage: 2Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv003 labels: name: pv003spec: nfs: path: /data/volumes/v3 server: node3.day.io accessModes: [\"ReadWriteMany\"] capacity: storage: 3Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv004 labels: name: pv004spec: nfs: path: /data/volumes/v4 server: node3.day.io accessModes: [\"ReadWriteMany\"] capacity: storage: 4Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv005 labels: name: pv005spec: nfs: path: /data/volumes/v5 server: node3.day.io accessModes: [\"ReadWriteMany\"] capacity: storage: 5Gi#注意pv属于集群级资源，被名称空间共享，不需要指明名称空间pvc属于名称空间级资源，需要指明名称空间更多accessModes见文档https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes 定义PVC和pod 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mypvc namespace: defaultspec: accessModes: [\"ReadWriteMany\"] resources: requests: storage: 3Gi---apiVersion: v1kind: Podmetadata: name: pod-vol-pvc namespace: defaultspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent volumeMounts: - name: html mountPath: /usr/share/nginx/html #在容器内定义挂载存储名称和挂载路径 volumes: - name: html persistentVolumeClaim: #绑定哪个pvc claimName: mypvc#注意pvc属于名称空间级资源，需要指明名称空间，其名称空间和pod一致pvc定义的accessModes必须是pv的子集，否则无法分配到pvresources定义资源数 定义configMap创建configMap资源 1234567891011121314#直接在命令行给出键值对kubectl create configmap nginx-config --from-literal=nginx_port=80 --from-literal=server_name=nginx.dqy.com#以文件方式创建www.confserver &#123; server_name nginx.dqy.com; listen 80; root /data/web/html;&#125;#将使用文件名作为键，内容作为值kubectl create configmap nginx-www --from-file=./www.conf#查看定义的configMapkubectl get configmap -o yaml 以环境变量方式注入nginx容器 12345678910111213141516171819202122232425262728293031apiVersion: v1kind: Podmetadata: name: pod-cm-1 namespace: default labels: app: nginx tier: frontendspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 env: - name: NGINX_SERVER_PORT valueFrom: configMapKeyRef: name: nginx-config key: nginx_port - name: NGINX_SERVER_NAME valueFrom: configMapKeyRef: name: nginx-config key: server_name #注意configMapKeyRef中name即为存在的已定义的configMap的名称，key即为其内的键名称当镜像运行时即使改变configmap的值镜像内的环境变量也不会改变，因此只在镜像启动时有效 以存储卷方式挂载configmap 123456789101112131415161718192021222324252627apiVersion: v1kind: Podmetadata: name: pod-cm-2 namespace: default labels: app: nginx tier: frontendspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 volumeMounts: - name: nginxconf mountPath: /etc/nginx/config.d/ volumes: - name: nginxconf configMap: name: nginx-config #注意在volumes中定义挂载类型为configMap，name指明已创建的configMap资源修改configMap的值后容器内的值也会改变，需要等待一个随机时间(同步需要时间)，可以理解为链接文件 定义StorageClassStorageClass的定义主要包括名称、后端存储的提供者(Provisioner)和后端存储的相关参数配置。StorageClass一旦被创建出来，将无法修改。如需修改，则只能删除原StorageClass的定义重建。 123456789101112131415161718192021222324252627282930313233343536#创建nfs-client的自动配置程序，根据已经创建好的nfs服务器进行自动创建PVkind: DeploymentapiVersion: apps/v1metadata: name: nfs-client-provisionerspec: replicas: 1 selector: matchLabels: app: nfs-client-provisioner strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs - name: NFS_SERVER value: 192.168.163.137 #nfs server 地址 - name: NFS_PATH value: /data/k8s-volume #nfs共享目录 volumes: - name: nfs-client-root nfs: server: 192.168.163.137 path: /data/k8s-volume 定义serviceaccount 12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: v1kind: ServiceAccountmetadata: name: nfs-client-provisioner---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nfs-client-provisioner-runnerrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"list\", \"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"create\", \"delete\", \"get\", \"list\", \"watch\", \"patch\", \"update\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: defaultroleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io 创建storageclass 12345apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: managed-nfs-storageprovisioner: fuseim.pri/ifs # or choose another name, must match deployment's env PROVISIONER_NAME' 创建pvc 1234567891011121314kind: PersistentVolumeClaimapiVersion: v1metadata: name: test-claim annotations: volume.beta.kubernetes.io/storage-class: \"managed-nfs-storage\" #storageclass 名称spec: accessModes: #访问模式 - ReadWriteMany resources: requests: storage: 1024Mi #请求数据大小 #成功后可以看到自动创建了一个pv给pvc","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"存储卷","slug":"存储卷","permalink":"http://yoursite.com/tags/%E5%AD%98%E5%82%A8%E5%8D%B7/"}],"author":"Frdqy"},{"title":"nfs各种问题解决","slug":"nfs各种问题解决","date":"2020-02-02T10:25:38.000Z","updated":"2020-02-02T10:29:36.940Z","comments":true,"path":"2020/02/02/nfs各种问题解决/","link":"","permalink":"http://yoursite.com/2020/02/02/nfs%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","excerpt":"转载：https://www.xuebuyuan.com/2158147.html 在配置kubenetes存储卷时遇到nfs配置问题，在网上找到如下解决方案","text":"转载：https://www.xuebuyuan.com/2158147.html 在配置kubenetes存储卷时遇到nfs配置问题，在网上找到如下解决方案 Permission deniedmount: 192.168.81.32:/opt failed, reason given by server: Permission denied 查看配置文件exports,是否为允许挂载的客户。 error = No route to hostmount: RPC: Unable to receive; errno = No route to host 首先看是否在同一网段 再者输入： [root@localhost etc]# service iptables status 看防火墙是否开启，有则将其关闭 [root@localhost etc]# service iptables stop 注意：但是这样子有时候其实还是有一些问题, 因此我们干脆直接将防火墙关闭掉, 同时关闭selinux error = Connection refusedmount: RPC: Unable to receive; errno = Connection refused ① 首先看nfs服务是否开启， ② 其次看rpcbind是否开启， 如果rpcbind没有运行，那在重新开启rpcbind后，要再restart nfs服务， 因为重启rpcbind已对nfs的一些配置造成影响，需要restart. 没错，看到这时候，你已经找到问题了， not responding,still trying..有时候传输大文件会出错, NFS: server 192.168.81.32 not responding,still trying.. 这个可能是NFS有问题,与RING或buffer的大小有关, 问题的原因分析： 1、NFS 的默认传输协议是 UDP，而PC机与嵌入式系统通过UPD交互时就会出现严重的网卡丢包现象； 2、server机和目标机网卡传输速率冲突，使得目标机需要大量时间复制大量数据包，其实如果目标机的网卡速率够大，则不用分那么多包，也不会冲突。 问题的解决方案： 方法一： 在客户端改用TCP协议，使用下面的命令，在mount命令中加上参数tcp mount -o tcp ,nolock 192.168.14.223:/nfs_root /mnt 也可这样干： 跟踪了fs/nfs/nfsroot.c的代码，发现在nfs作为根文件系统时，参数可以直接写在“nfsroot=”后面，每个参数用逗号隔开，如： nfsroot=192.168.10.1:/rootfs,proto=tcp,nfsvers=3,nolock 这样就可以指定nfs使用tcp协议 方法二： 指定传输速率（限定传输时一次读写的数据大小） #mount -t nfs -o intr,nolock,rsize=1024,wsize=1024 192.168.14.223:/nfs_root /mnt","categories":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"http://yoursite.com/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}],"tags":[{"name":"nfs","slug":"nfs","permalink":"http://yoursite.com/tags/nfs/"}],"author":"Frdqy"},{"title":"k8s(3)-ingress详解","slug":"k8s-3-ingress详解","date":"2020-02-01T09:40:41.000Z","updated":"2020-02-02T10:27:17.166Z","comments":true,"path":"2020/02/01/k8s-3-ingress详解/","link":"","permalink":"http://yoursite.com/2020/02/01/k8s-3-ingress%E8%AF%A6%E8%A7%A3/","excerpt":"概念当nginx实现七层负载均衡时通过upstream反向代理多个后端主机。但在k8s集群中，使用nginx反代时如果后端新增加pod组就需要通过修改nginx配置文件来新增upstream，但在k8s种修改nginx不方便，不能直接修改配置文件，由此引入ingress。ingress包括如下组件：","text":"概念当nginx实现七层负载均衡时通过upstream反向代理多个后端主机。但在k8s集群中，使用nginx反代时如果后端新增加pod组就需要通过修改nginx配置文件来新增upstream，但在k8s种修改nginx不方便，不能直接修改配置文件，由此引入ingress。ingress包括如下组件： ingress对象：使用yaml格式定义不同的nginx配置文件。 ingress controller：用于管理ingress对象，当ingress对象变化时自动读取并生成对应的nginx配置并重新加载nginx服务。 流程 用户请求经由外部负载均衡器调度到集群内部的service然后访问IngressController，它根据ingress定义的规则从而访问后端的pod。注意后端的pod也是根据ingress定义来分组，它通过一个Service来分组，该Service只用于标记哪些pod属于同一组，不起到调度作用。 其实，IngressController可以不定义于某个Service后，可以采用共享主机网络名称空间的方式(定义hostnetwork)，定义成DaemonSet运行于指定几个主机上(用污点实现)，这样也可以实现七层负载均衡调度。 配置流程安装ingress-controller 12345#创建名称空间kubectl create namespace ingress-nginx#部署ingressControllerkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.28.0/deploy/static/mandatory.yaml 配置ingress-nginx 1234567891011121314151617181920212223242526272829303132333435#编辑配置文件apiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: type: NodePort ports: - name: http port: 80 targetPort: 80 protocol: TCP - name: https port: 443 targetPort: 443 protocol: TCP selector: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx #创建kubectl apply -f service-nodeport.yaml#查看开放端口,80和443端口都有相应的映射kubectl describe service ingress-nginx -n ingress-nginx#注意此处需要使用nodeport来暴露端口，或者将ingress-controller配置为DaemonSet，并共享物理主机网络配置也可以实现类似功能注意名称空间是ingress-nginxtargetPort是容器端口port是service端口 定义service，该service负责标记两个后端web服务器 12345678910111213141516171819202122232425262728293031323334353637383940414243#此处直接expose暴露kubectl expose deployment nginx-deploy --name=nginx --port=80 --target-port=80 --protocol=TCP#注意这里可以使用上面这种直接暴露的方法，也可以在pod控制器的yaml中同时定义一个service，如下：apiVersion: v1kind: Servicemetadata: name: nginx namespace: defaultspec: selector: app: nginx release: canary ports: - name: http targetPort: 80 port: 80---apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploy namespace: defaultspec: replicas: 3 selector: matchLabels: app: nginx release: canary template: metadata: labels: app: nginx release: canary spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - name: https containerPort: 80 定义ingress文件规则 12345678910111213141516171819202122apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress namespace: default annotations: kubenetes.io/ingress.class: \"nginx\"spec: rules: - host: nginx.dqy.com http: paths: - path: backend: serviceName: nginx servicePort: 80#注意该ingress的namespace必须与要发布的service(上面那个)处在同一namespace中annotations的作用是表示此处使用nginx作为反代，必须要设置rules下的host指定为域名时必须能解析到之前定义的NodePort上，即ingress-nginx上backend用来定义后端相关信息，serviceName就是代理后端2个web主机的service的名称path默认不写代表/ 至此，整个nginx七层代理就搭好了，不出意外的话在物理主机上可以使用nginx.dqy.com来进行访问，注意要指定Nodeport暴露的端口号，以及定义好hosts文件进行域名解析。另外此处定义虚拟主机的host为nginx.dqy.com就必须使用该域名来访问，不能使用其ip地址访问。 拓展上述只能实现http访问，这里拓展一下https的实现。 为了方便就本地自签证书，先生成密钥 1openssl genrsa -out tls.key 2048 生成自签证书 1234openssl req -new -x509 -key tls.key -out tls.crt -subj /C=CN/ST=Huaian/L=Huaian/O=Linux/CN=nginx.dqy.com#注意CN一定要设置为要访问的域名 将crt证书转换成secret对象 12345kubectl create secret tls nginx-ingress-secret --cert=tls.crt --key=tls.key#注意nginx-ingress-secret是一个名称可以随意指明证书和密钥 编写ingress-tls.yaml 123456789101112131415161718192021222324252627apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-tls namespace: default annotations: kubenetes.io/ingress.class: \"nginx\"spec: tls: - hosts: - nginx.dqy.com secretName: nginx-ingress-secret rules: - host: nginx.dqy.com http: paths: - path: backend: serviceName: nginx servicePort: 80#创建kubectl apply -f ingress-tls.yaml #注意定义tls字段时host主机可以有多个secretName就是创建的secret 至此就可以使用https端口访问了，注意要在地址前手动添加https协议。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"ingress","slug":"ingress","permalink":"http://yoursite.com/tags/ingress/"}],"author":"Frdqy"},{"title":"k8s(2)-pod和service","slug":"k8s-2-pod和service","date":"2020-02-01T09:37:24.000Z","updated":"2020-02-03T04:23:01.427Z","comments":true,"path":"2020/02/01/k8s-2-pod和service/","link":"","permalink":"http://yoursite.com/2020/02/01/k8s-2-pod%E5%92%8Cservice/","excerpt":"资源清单kubernetes使用REST格式的API将各种操作对象当作资源来管理。常见资源对象如下： workload：工作负载型资源对象，主要运行应用程序对外提供服务；如pod、deployment、statefileset等 服务发现和负载均衡有关：service、ingress等 配置与存储相关：volume、CSI第三方存储卷、configmap、secret等 集群级资源：名称空间、node、role、cluster role等 元数据型资源：HPA、podtemplate、limitrange","text":"资源清单kubernetes使用REST格式的API将各种操作对象当作资源来管理。常见资源对象如下： workload：工作负载型资源对象，主要运行应用程序对外提供服务；如pod、deployment、statefileset等 服务发现和负载均衡有关：service、ingress等 配置与存储相关：volume、CSI第三方存储卷、configmap、secret等 集群级资源：名称空间、node、role、cluster role等 元数据型资源：HPA、podtemplate、limitrange 1234567891011121314151617#pod资源清单查看，以yaml格式查看指定pod的资源配置文件kubectl get pod nginx-xxxx -o yaml#配置文件apiVersion：api群组和版本，一般为group/version，group省略则为core组；使用如下命令可以获取 kubectl api-versionkind：资源类别，就是上文指定的资源类别metadata：元数据 name：pod名称 namespace：名称空间 labels：标签 annotations：资源注解spec：规格，定义对象满足哪些特性，是用户定义的目标状态；容器、容忍度等stats：当前资源的当前状态，当前状态与目标状态不同时，当前状态需要向期望状态转变#查看某个资源如何定义，可以逐级查看kubectl explain pod.metadata 资源清单文件实例 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: myapp tier: frontendspec:#containers内容为列表，因此需要使用- name这种格式来定义；可以多次定义 containers: - name: myapp image: busybox:latest imagePullPolocy: IfNotPresent #替换busybox容器默认启动执行命令 command: - \"/bin/sh\" - \"-c\" - \"date &gt;&gt; /usr/share/nginx/html/index.html\" Pod分类 自主创建的Pod：通过手动指定yaml文件进行创建的pod，它不受pod控制器的管理，即使容器失效后也不会自动给重启 控制器管理的Pod：使用run指令创建的pod，它受到控制器管理，可以根据指定条件维持pod内容器数量 生命周期首先需要初始化容器进行初始化，可以理解为docker中的ENTRYPOINT脚本执行效果。在初始化结束后存在类似awk的begin和end的post start和pre stop。 另外，在主容器进程执行时会有两个健康探测一直执行，探测方式主要有ExecActino(自定义命令)、TCPSocketAction(向套接字发请求)、HTTPGetAction(向http发送get请求)。常见的pod状态如下： Pending：挂起，请求pod后调度没有完成，如标签不符合 Running：运行态 Failed：失败态 Succeeded：成功态 Unknown：未知态，可能是kubelet自身出问题 创建过程首先，创建请求提交给API server，之后API server将其保存在etcd数据库中，之后请求schedule进行调度并将其调度结果保存到etcd的pod状态中；对于node节点来说，node节点上的kubelet会收到API server变动事件，然后该kubelet会得到创建的pod的资源清单，根据清单在当前node上进行pod创建。如果创建失败，其结果会反馈给API server并保存在etcd中 删除过程先发送terminal信号，使得内部容器执行stop命令(给时间保存数据)；达到pod设定缓冲时间后再执行kill信号杀死pod。 资源定义1234567891011121314151617181920212223242526272829#speccontainers &lt;[]object&gt; - name &lt;string&gt; #pod名称 image &lt;string&gt; #镜像名称 imagePullPolicy &lt;string&gt; #拖取镜像方式，有三种方式 Always #总是向仓库拖取，即使本地存在 Never #从不向仓库拖取 IfNotPresent #如果本地不存在就下载 ports &lt;[]object&gt; #定义暴露端口，但是这里不指定pod也会将容器内的服务监听端口暴露，这里主要是信息式的显示，方便查看 - name &lt;string&gt; #端口名称，如http等 containerPort &lt;string&gt; #容器端口，如80等 command &lt;[]string&gt; #用于替换docker中的cmd和entrypoint args &lt;[]string&gt; #用于替换docker中的cmd(cmd做参数时)，此时当作command参数 livenessProbe #容器存活状态检测，在post start后检测 exec #command &lt;[]string&gt;，通过命令来直接探测 httpGet #http探测，需要指明port和path；port也可以是上面ports暴露的名称，path是相对路径，相对于容器内服务定义的doc_root路径 tcpSocket #tcp探测 failureThreshold #探测失败次数，默认3次 periodSeconds #每次间隔时间，默认10秒 timeoutSeconds #超时时间，默认1秒 initialDelaySeconds #容器启动后多久开始探测 readinessProbe #服务就绪状态检测，在post start后检测 lifecycle #生命周期 poststart #类似于awk的begin，与检测逻辑相似，都包含三种方式；其执行在command后 prestop #类似于awk的end，与检测逻辑相似，都包含三种方式；其执行在command后nodeSelector &lt;map[string]string&gt; #节点标签选择器，可以根据label限定Pod运行的节点 label=valuenodeName #直接运行pod于指定节点上，不通过nodeSelector选择restartPolicy #重启策略，Always，OnFailure，Never，默认Always 健康检测实例ReadinessProbe，使用httpGet做就绪性探测 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: readiness-httpget-pod namespace: defaultspec: containers: - name: readiness-httpget-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 readinessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3 LivenessProbe，使用command做存活性探测 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: liveness-exec-pod namespace: defaultspec: containers: - name: liveness-exec-container image: busybox:latest imagePullPolicy: IfNotPresent command: - \"/bin/sh\" - \"-c\" - \"touch /tmp/health; sleep 30; rm -f /tmp/health; sleep 3600;\" livenessProbe: exec: command: - \"test\" - \"-e\" - \"/tmp/healthy\" Pod控制器ReplicaSet主要由三个主要部件组成，用于管理无状态pod。 部件：用户期望的pod副本数、标签选择器、pod模板。 123456789101112131415161718192021222324252627282930apiVersion: apps/v1kind: ReplicaSetmetadata: name: myapp namespace: defaultspec: replicas: 2 selector: matchLabels: app: myapp release: canary templates: metadata: name: myapp-pod labels: app: myapp release: canary environment: qa spec: containers: - name: myapp-container image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80#注意spec中需要定义三个字段：replicas、selector、templatesmatchLabels用于匹配pod的labels字段，因此在templates中的labels字段中必须包含matchlabels的字段templates中定义的pod名称并没有意义，控制器会自动为各个pod添加自身名称后加随机字符串修改可以使用patch或edit编辑 Deployment工作在ReplicaSet之上，不直接控制pod而是控制ReplicaSet，一般都使用Deployment作为pod控制器。另外，在使用Deployment进行版本更新时，它会创建一个新的RepicaSet然后在旧的RepicaSet上删除一个pod，在新的RepicaSet上新建一个pod，从而实现动态更新。当然，如果考虑到删除一个pod时会不会导致业务瓶颈导致服务中断，Deployment还支持临时允许多添加或减少pod，即可以暂时超过RepicaSet设置的replicas数，从而实现先创建一个新的，再删除旧的，这样更稳定。 123456789101112131415161718192021222324252627apiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deploy namespace: defaultspec: replicas: 2 selector: matchLabels: app: myapp release: canary template: metadata: labels: app: myapp release: canary spec: containers: - name: myapp-container image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 #注意Deployment会自动创建ReplicaSet进行管理修改可以使用patch或edit编辑 DaemonSet用于确保指定的node节点只运行一个pod副本，通常用来实现系统级后台任务，且pod必须是无状态的。它也支持滚动更新。可以用于工作在指定pod上做七层负载均衡调度(打污点)。 1234567891011121314151617181920212223242526apiVersion: apps/v1kind: DaemonSetmetadata: name: myapp-daemon namespace: defaultspec: selector: matchLabels: app: filebeat release: stable template: metadata: labels: app: filebeat release: stable spec: containers: - name: filebeat image: ikubernetes/filebeat:v1 env: - name: REDIS_HOST value: redis.default.cluster.svc.cluster.local #注意定义env一般是设置服务工作，手动指定filebeat将日志传给redis，从而实现pod之间的通信由于一个node上运行一个DaemonSet，因此可以使用spec字段的hostNetwork共享该pod和node的网络地址空间，这样就不用service暴露ip端口也可以直接通过node的IP进行访问 Job用于执行一次性pod，如果正常执行结束则不会被重启，如果未结束时被异常终止那么会重启该pod。 Cronjob周期性job StatefulSet用于管理有状态的pod，且每一个pod都被单独管理。如redis、mysql等。该控制器主要管理有以下特性的控制程序： 稳定且唯一的网络标识符 稳定且持久的存储 有序平滑的部署扩展和终止删除 有序的滚动更新 它需要三个组件： headless service：用于确保pod删除后再重建它的名称等信息必须和原来一样，因为pod名称是唯一标识符。因此使用headless service，它确保解析直达后端pod而不是代理的service。 statefulSet：pod管理器 volumeClaimTemplate：有状态的pod不能使用同一个存储卷，因此不能使用deployment中template定义pod来定义。这里使用volumeClaimTemplate实现动态创建pvc，并且绑定各自的pv，从而实现各自挂载各自的存储卷(分布式存储) 资源定义12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152apiVersion: v1kind: Servicemeatadata: name: nginx-svc labels: app: nginx-svcspec: clusterIP: None ports: - port: 80 name: web selector: app: nginx-pod---apiVersion: apps/v1kind: StatefulSetmetadata: name: nginxspec: serviceName: nginx-svc replicas: 2 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod sepc: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: web volumeMounts: - name: nginxdata mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: nginxdata spec: accessModes: [\"ReadWriteOnce\"] storageClassName: \"gluster-dynamic\" resources: requests: storage: 2Gi #注意删除pod是有顺序依次删除，且不会删除对应的pvc，可以保证数据不丢失；删除后重新绑定仍然是之前对应的pvc每个pod名称都需要被解析，这里解析需要额外指明service_name，如：pod_name.service_name.ns_name.svc.cluster.local 修改命令123456#扩容，顺序增序kubectl scale sts nginx --replicas=5#镜像升级这里升级支持定义updateStrategy升级策略，其rollingUpdate属性下有一个属性为partition，它指明更新边界。我们知道statefulSet创建的pod有编号，从0-n，如果partition为n，表示编号大于等于n的都会更新，可以模拟出灰度更新的效果kubectl set image sts/nginx nginx=nginx:v2 Service用于解决pod更新时地址等资源改变的问题而提出的新概念，是对多个pod的封装，pod客户端访问其他pod时是通过service访问，其本质是iptables规则或者是ipvs规则。这些规则由node节点上的kube-proxy组件实现，它一直使用watch方法监视apiserver，service资源有变动时对应kube-proxy会将其定义为规则。 实现方式userspace 请求由ClientPod发给ServiceIP，ServiceIP将其转发给本地的kube-proxy，再由kube-proxy经由ServiceIP发送给目的地的kube-proxy，最后发送给对应的ServerPod。这种模式的通信kube-proxy是工作在用户空间的进程，这种通信方式效率很低(内核和用户空间的切换)。 iptables/ipvs 请求经过ServiceIP后不再转发到本地kube-proxy，而是直接由ServiceIP的规则转发，大大减少了时间开销。根据转发的规则是iptables还是ipvs来划分。 默认使用iptables规则，如果要使用ipvs规则则需要在初始化之前在/etc/sysconfig/kubelete文件中设置 1KUBE_PROXY_MODE=ipvs 类型ClusterIP：默认类型，分配一个集群内地址给service，由于是私网地址因此只用于集群内通信 NodePort：用于集群外部访问集群内部pod，并需要定义nodeport字段的端口，该模式工作于ClusterIP之上，客户端请求先经由NodeIP:NODEPORT到ClusterIP:PORT最后到pod。 LoadBalance：工作在LAAS创建负载均衡时使用 ExternalName：集群内部节点访问外部服务时定义的service，该服务必须要被DNS解析 定义清单12345678910111213141516apiVersion: v1kind: Servicemetadata: name: redis namespace: defaultspec: selector: app: redis role: logstor type: ClusterIP ports: - port: 6379 targetPort: 6379 #注意端口有三种，port是service端口；targetPort是pod端口；nodePort是使用NodePort类型service时对外通信的端口","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"pod","slug":"pod","permalink":"http://yoursite.com/tags/pod/"}],"author":"Frdqy"},{"title":"k8s(1)-基本架构及部署","slug":"k8s-1-基本架构及部署","date":"2020-01-30T09:54:20.000Z","updated":"2020-02-05T04:10:04.322Z","comments":true,"path":"2020/01/30/k8s-1-基本架构及部署/","link":"","permalink":"http://yoursite.com/2020/01/30/k8s-1-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8F%8A%E9%83%A8%E7%BD%B2/","excerpt":"基础kubernetes是一个容器编排工具，其本质是集群，即组合多台主机的资源对外提供统一服务。在每台主机上安装相关程序，并使得这些程序实现通信，从而实现多个主机的协调。","text":"基础kubernetes是一个容器编排工具，其本质是集群，即组合多台主机的资源对外提供统一服务。在每台主机上安装相关程序，并使得这些程序实现通信，从而实现多个主机的协调。 通信k8s的集群内部主要分为三种网络模式，分别为节点网络、集群网络、pod网络。外部请求经由节点网络代理至集群网络，集群网络再代理至pod网络实现通信。 同一pod内：直接使用lo网卡即可通信 各pod之间通信：使用overlay Network方式实现叠加网络通信。overlay构建一个虚拟网段，实现各节点的主机内的pod处于同一个虚拟网段，这样就可以直接进行通信，不需要各种NAT转换。原理是利用隧道技术进行二层封装，主机网卡收到pod虚拟地址的报文时封装一层ip地址发送给另一台主机，另一台主机再解封装发现里面仍然是ip报文，根据ip判断是发送给自身虚拟pod的地址，从而实现各pod之间在同一虚拟网段中通信。 pod与service通信：通过iptables规则或者lvs规则进行通信。其规则由proxy生成。 存储由上文可以知道，想要与pod通信需要先与service通信，而pod更新或者挂掉换新都会导致service规则的更新，这个过程需要通知master的API server进行事务处理。这里就有问题了，因为pod更新通知master那么master必然存储了大量的不必要的通知信息，这很占空间因此不可能存储在master本地，因此这里使用共享存储etcd。 etcd是键值存储的数据库系统，需要做成高可用集群，etcd通信一般使用https通信。etcd内部使用一个端口进行通信，外部使用另一个端口与master通信，这个过程都是https协议通信。 名称空间在一个k8s集群中，将多个pod划分成不同的空间实现隔离效果，这个隔离是管理的隔离比如分成生成环境、开发环境等等，各个pod仍然可以正常通信不受影响。 网络策略用于实现在网络层面上隔离各个名称空间，定义iptables规则来限制pod之间的访问。k8s虽然本身网络很复杂(三种网络)但是它自身不提供网络配置以及策略的解决方案，因此需要使用第三方插件如canel来实现网络配置和网络策略的设置。 架构kubernetes是一个有中心节点的集群，其架构为master/nodes模型。用户请求(启动容器等)通过API server发往master，master根据调度器(scheduler)分析各node节点资源，判断哪个适合完成用户请求的操作，接着将请求发给调度过的node上，node通过容器引擎(一般为docker)运行相关容器。 scheduler：工作在master的调度器。负责观测各node节点可供使用的CPU、RAM等资源，并根据用户申请所需要的资源量来判断将请求交给哪个node相应。调度时一般分成两步，第一步选出所有符合资源需求的node；第二步根据优选算法再挑选最符合的node进行调度。 controllers：控制器管理器。用于管理各控制器的健康状态。管理器自身基于master做冗余从而保证自身的健康。 pod：它是逻辑组件，是kubernetes的最小调度单位，有前端pod与后端pod等根据不同功用分配的类型。它是容器的封装，可以理解为docker中的多个容器共享一个网络名称空间实现的效果。pod内的多个容器除了共享网络名称空间外还共享存储卷。另外，虽然它可以组合多个容器，但是一般关联不大的容器不封装为一个pod，只有像日志记录容器和主服务容器可以建议封装在一个pod中。pod使用标签来实现不同pod的身份识别，从而可以统一控制一类pod，一般使用label selector来实现过滤。 replication controller：副本控制器，用于管理pod，可以实现pod调度。它也可以实现pod的版本滚动更新。常见的pod控制器有：Deployment(无状态)、StatefulSet(有状态)、Job(用于实现小功能，如删除数据)等。一般情况下不直接对pod进行调用而调用其控制器。 service：它是定义一系列pod的逻辑抽象，本质就是iptables规则或者lvs规则。它工作在一组pod之前，根据lvs实现负载均衡式的对pod的调度。考虑一种情况，当某个pod节点坏掉后需要新的pod替换，那么新的pod的ip地址、主机名等关键资源都将变动，那么如何才能让master无视这种变得来调用pod呢？service就是为解决此问题而提出的抽象概念，它通过label来识别不同的pod。service本身具有名称，可以根据集群内部的DNS pod实现解析，并且一旦service地址改变DNS会自动修改对应条目，使得pod客户端在下次申请资源时依旧正确连接service从而与后端pod进行交互。 node：物理机，通常成为Minion，主要运行多个pod。 kubelet：node的集群代理。工作在node节点，用于与master通信并接收执行各种任务的组件。它调用容器引擎如docker来管理容器。 proxy：node代理。负责随时与master的API server通信。因为每次node节点上的pod有变动时会主动通知API server生成一个事件，该事件会通知proxy创建新的service规则。 安装安装一般有两种方式： 第一种方式是手动将k8s的master以及node节点的各个功能以守护进程的方式运行在主机上，这种方式需要全程手动参与，且要解决大量证书问题，很繁琐。 第二种方式是使用kubeadm部署，它将k8s本身也部署为pod，且各个master以及node只需要安装配置docker以及kubelet即可。前者是容器运行的必备引擎，后者是运行pod化容器的核心组件，这些pod都是静态pod。最后部署好flanner即可通信。 环境节点网络：192.168.163.0/24 service网络：10.96.0.0/12 Pod网络：10.244.0.0/16，该网络为flannel默认网段 配置master123456789101112131415161718192021222324252627282930313233343536373839#配置yum源，编辑/etc/yum.repos.d/kubernetes.repo[kubernetes]name=kubernetes repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=0#配置docker-ce源，此处省略#安装yum install -y docker-ce kubelet kubeadm kubectl#设置开机启动systemctl enable kubeletsystemctl enable dockerecho 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables#修改配置文件/etc/sysconfig/kubelet，使得开启swap时不会出错KUBELET_EXTRA_ARGS=\"--fail-swap-on=false\"#初始化initkubeadm init --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap#注意拖镜像需要科学上网上述命令会pull镜像到本地，可以先使用kubeadm config images pull预先拖取镜像安装成功后会提示建议执行的一系列指令，按照要求执行即可成功后最后一行会有一串命令用来使得别的node加入该k8s集群中，包括密钥认证等，需要保存好该指令，如下kubeadm join 192.168.163.132:6443 --token m01is4.mhh9mcgn4nz4b0c3 \\ --discovery-token-ca-cert-hash sha256:3089b2a13f124b82b87a33f04ab1f2c4eb3a5286576783b34aea7964f635d50a --ignore-preflight-errors=Swap#后续指令mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config#下载fanner镜像，从github上手册下载kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml#注意执行上述命令后很快会显示create，但是并没有好，需要等待docker image有flannel镜像拉取成功并且名称空间中有对应节点才说明安装好#查看kube-system名称空间节点kubectl get pods -n kube-system 配置node1234567891011121314151617#将master的docker-ce.repo和kubernetes.repo复制过来#安装yum install -y docker-ce kubelet kubeadm#将master的/etc/sysconfig/kubelet配置文件复制过来#设置开机启动systemctl enable kubeletsystemctl enable docker#使用之前保存的join命令加入k8s集群，需要指明--ignore-preflight-error=Swap#下载fanner镜像，从github上手册下载kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml#注意执行上述命令后很快会显示create，但是并没有好，需要等待docker image有flannel镜像拉取成功并且名称空间中有对应节点才说明安装好#查看kube-system名称空间节点kubectl get pods -n kube-system 命令get1234567891011121314151617181920212223#查看状态，包括scheduler、controller、etcdkubectl get cs#获取节点信息，显示详细信息kubectl get nodes -o wide#获取名称空间kubectl get ns#查看pod信息，默认节点是default名称空间内的podkubectl get pods#列举所有servicekubectl get services#查看指定控制器kubectl get deployment#查看指定标签kubectl get pods -l \"release in (canary,beta,alpha)\"kubectl get pods -l \"release notin (canary,beta,alpha)\"kubectl get pods -l release,appkubectl get pods -l release=stable,appkubectl get pods -l release!=stable,app--all-namespaces：显示所有名称空间-o wide：显示详细信息-l label1,laebl2：查看指定label的pod-w：监控方式查看 run创建并运行一个镜像，且创建指定pod控制器(deployment或者job) 12345--image=nginx #使用指定镜像创建资源--replicas=5 #指定启动多少个pod资源--restart=Never #容器结束不自动启动--port=80 #暴露哪个端口--dry-run=true #是否只执行命令不创建 exec12#交互式连入指定podkubelet exec -it pod_name -- /bin/sh delete123-n ns #指明删除哪个名称空间下的资源-l name=label #删除指定label的pod-f name.yaml #删除指定资源清单定义的资源 scale调整指定deployment的pod个数，既可以增大也可以减小 1kubectl scale --replicas=5 deployment nginx-deploy set1234567#动态升级kubectl set image deployment nginx-deploy nginx-deploy=docker_name/name:v2#注意第一个nginx-deploy表示控制器名称，即实例里第一命令创建的名称，第二个nginx-deploy表示容器名称#查找指定容器对应详细信息，包括属于哪个deployment和镜像名称kubectl describe pods pods_name rollout回滚操作 12345678#默认回滚上一个，若指定回滚的版本需要指定--to-revision=VERSIONkuberctl rollout undo deployment nginx-deploy#进行canary发布即更新一个后暂停更新，通常使用&amp;&amp;结合set image使用kubectl rollout pause deployment nginx-deploy#动态查看状态kubectl rollout deployment nginx-deploy#继续进行更新操作kubectl rollout resume deployment nginx-deploy explain查看资源定义文档 12#查看某个资源如何定义，可以逐级查看kubectl explain pod.metadata create从yaml文件或标准输入来加载资源对象 12#根据自定义的pod-demo.yaml来创建podkubectl create -f pod-demo.yaml apply类似于create，但是可以执行多次。执行后会通知APISERVER修改etcd相关内容，从而更改期望状态，从而使得pod从现有状态转向期望状态 1kubectl apply -f pod-demo.yaml describe显示一个或者多个资源对象的详细信息。 1kubectl describe 资源类型 资源名称 log查看容器的日志 123kubectl logs &lt;pod-name&gt;#实时查看日志kubectl logs -f &lt;pod-name&gt; label为资源打标签 123kubectl label &lt;type_name&gt; &lt;name&gt; KEY_1=VAL_1 KEY_2=VAL_2...#举例kubectl label pods pod-demo release=canary patch动态修改yaml配置文件，以json格式修改 123kubectl patch deployment myapp-deploy -p '&#123;\"spec\":&#123;\"replicas\":5&#125;&#125;'#注意外层用单引号，内层每个字段使用双引号 实例在master上创建一个pod镜像 1234kubectl run nginx-deploy --image=nginx --replicas=1#注意默认使用deployment调度 在master上创建一个service，需要指明是为哪个pod创建 12345678910kubectl expose deployment nginx-deploy --name=nginx --port=80 --target-port=80 --protocol=TCP#注意nginx-deploy就是上面创建的pod镜像--port指的是服务端口，即service_port；--target-port指的是容器端口，即pod_port创建好后其他pod即可访问该service名nginx来访问该service下的pod镜像注意直接以域名访问时需要用到CoreDNS来解析，必须创建一个pod客户端来访问，否则DNS检索时后缀补充会出问题#查看该service的详细信息，包括监听的标签，即关联的pod的标签名；还有关联pod的ipkubectl describe service nginx 创建一个pod客户端来访问nginx 12#创建名为client的pod镜像kubectl run client --image=busybox --replicas=1 -it --restart=Never 删除nginx的pod后，会自动创建新的pod，自此简单的k8s已搭好。 123kubectl delete nginx-xxx#删除后查看发现已经重新创建pod，且名称后缀已经改变kubectl get pods","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"kubectl","slug":"kubectl","permalink":"http://yoursite.com/tags/kubectl/"}],"author":"Frdqy"},{"title":"docker详解","slug":"docker详解","date":"2020-01-28T10:02:04.000Z","updated":"2020-01-28T10:03:04.307Z","comments":true,"path":"2020/01/28/docker详解/","link":"","permalink":"http://yoursite.com/2020/01/28/docker%E8%AF%A6%E8%A7%A3/","excerpt":"虚拟化虚拟化技术可以实现将多台物理主机虚拟为一个逻辑主机或者将一台物理主机虚拟为多台逻辑主机，其中后者现在被广泛运用。虚拟化技术可以分为完全虚拟化和半虚拟化，其中完全虚拟化又分为硬件辅助虚拟化和软件辅助虚拟化。","text":"虚拟化虚拟化技术可以实现将多台物理主机虚拟为一个逻辑主机或者将一台物理主机虚拟为多台逻辑主机，其中后者现在被广泛运用。虚拟化技术可以分为完全虚拟化和半虚拟化，其中完全虚拟化又分为硬件辅助虚拟化和软件辅助虚拟化。 软件辅助全虚拟化该虚拟化方式是将虚拟化管理器(VMM)运行在用户态中。当虚拟机里的程序需要执行系统调用时，CPU并不知道它是虚拟机的指令还是真正物理机的指令，因此需要VMM来实现对每条虚拟机指令的捕获和翻译，此时VMM充当一个中间人的角色，虚拟机通过VMM来调用真正的物理资源，而实际上是VMM来向物理机的内核申请使用物理资源。对于物理机内核来说，VMM只是一个用户空间的普通进程；对于虚拟机内核来说，它认为自己就是真正内核，这就是软件辅助虚拟化。这个过程由于需要VMM参与，导致其效率不高，现在逐渐被硬件辅助全虚拟化取代。 硬件辅助全虚拟化该虚拟化是在CPU硬件层面支持虚拟化技术后实现的新技术。对于虚拟内核来说，只需要将标志位设置为虚拟状态，那么就可以直接在CPU上执行大部分指令，不需要VMM作转述。因为开启了虚拟化技术的CPU有两个新的执行状态，他们是Non-Root和Root。VMM运行在Root模式(装载在物理内核中，相当于本身就是物理内核)，虚拟机运行在Non-Root模式的Ring0状态，这就意味这它可以直接执行特权指令，不需要VMM转述，从而大大提高虚拟机的执行效率。 容器容器是虚拟化的一种方案，但它不是主机级别的虚拟化，而是应用级别的虚拟化。它将操作系统虚拟化，把物理上的操作系统虚拟为逻辑上的多个操作系统，不同的操作系统有自己的用户空间，用户空间相互隔离，彼此意识不到对方的存在，整个容器中只运行它本身一个进程。 Namespaces是内核实现的修改进程视图的机制，它实现了容器间资源的隔离。Namespaces包含种资源，分别是：Mount、UTS、IPC、PID、Network和User。每次创建并启动一个容器时，就指定了Namespaces的参数(通过clone()系统调用实现)，每个容器只能看到当前分配给他们的Namespaces内的内容。 namespace 系统调用参数 隔离内容 UTS CLONE_NEWUTS 主机名和域名 IPC CLONE_NEWIPC 信号量、共享内存、消息队列等 PID CLONE_NEWPID 进程编号 Network CLONE_NEWNET 网络设备、端口、网络栈等 Mount CLONE_NEWNS 文件系统挂载点 User CLONE_NEWUSER 用户和组 Cgroupcgroup，即Control group。该机制实现的是将系统资源分配到指定的内存中进程组上。和Namespaces类似，但是实现的目的是为了对各组进程进行统一的资源监控和限制(Namespces是为了实现隔离)。它将进程分组，将有限的资源对这些组进行分配。每个进程组可以再细分组，分配给该组的系统资源在组内共享。 docker安装123456789101112#extra仓库版本较老，使用镜像安装#首先下载repo仓库进行本地制作，放在本地/etc/yum.repo.d/目录下wget https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo#仓库中指向的仍然是docker官方，速度很慢，此处在vim中修改为清华镜像(全局替换)%s@https://download.docker.com/@https://mirrors.tuna.tsinghua.edu.cn/docker-ce/@#更新本地repo缓存yum repolist#指向安装yum install -y docker-ce#若之前安装过extra仓库的docker，需要卸载如下包，否则会冲突导致docker-ce无法安装yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine 配置docker配置文件为：/etc/docker/daemon.json，该文件初始并未创建，需要手动创建 12345678mkdir /etc/dockervim /etc/docker/daemon.json#编辑该文件，添加阿里云镜像加速，该链接在阿里云容器云上获取&#123; \"registry-mirrors\": [\"https://pjfb83d0.mirror.aliyuncs.com\"]&#125;#如果docker已运行需要重载配置文件systemctl daemon-reload 常用命令image123456789101112131415docker image COMMANDS build：根据Dockerfile创建一个镜像 history：显示image使用历史 import： inspect：显示image的详细信息 load：从标准输入或者归档文件创建一个image -i：指明输入文件 ls：显示所有image prune：删除没有使用的image pull：从docker hub上拉去指定image push：将image推送到docker hub上，或指定的docker镜像服务器 rm：删除指定镜像 save：保存指定image到归档文件中 -o：指明保存文件 tag：创建一个image的tag标签 container12345678910111213141516171819202122232425262728docker container COMMANDS attach commit：将最上层的可写层创建为image的一层，相当于基于容器制作镜像 cp：在本地文件系统和容器内的文件系统中复制文件 create：根据image创建一个容器 diff exec：在容器中运行命令 export inspect：显示容器的详细信息 kill：杀死一个运行的容器，相当于kill -9 logs：获取容器运行进程的日志 ls：显示容器 pause：暂停所有容器 port prune：删除所有停止状态的容器 rename：重命名容器 restart：重启容器 rm：删除容器 run：在容器中运行命令，需要指明image -i：保持交互式连接 -t：启动终端 start：启动容器 stats stop：停止运行的容器，相当于kill -15 top：基于资源消耗比率显示容器 unpause：继续暂停的容器 update wait 镜像组织结构Docker镜像含有启动容器所需要的文件系统及其内容。因此，其用于创建并启动docker容器。 Docker镜像采用分层构建机制，最底层为bootfs，上层为rootfs bootfs：用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以节约资源 rootfs：位于bootfs之上，表现为docker容器的根文件系统。在传统模式中系统启动时内核挂载rootfs时会首先将其挂载为只读模式，完成一系列自检操作后将其重新挂载为读写模式。而在docker中，rootfs由内核挂载为只读模式，而后通过联合挂载技术额外挂载一个可写层。因此由镜像创建容器时，实际就是在基础镜像层上添加一个可写的image层，所有的写操作都在此层。因此在删除容器时实际也是删除该可写image层，源镜像保持不变。 一个完整的镜像是由多个镜像分层联合挂载而来。bootfs作为最底层在引导出用户空间的根文件系统后就自动卸载。之后有Base image基本镜像层，该层主要是封装各种操作系统；其次是各种应用程序层，比如vim编辑器层、nginx服务层等。这些多个镜像一层一层叠加形成完整的镜像。 12345#从指定镜像仓库中拉取镜像docker pull &lt;registry&gt;[:&lt;port&gt;]/[&lt;namespace&gt;/]&lt;name&gt;:&lt;tag&gt; &lt;registry&gt;[:&lt;port&gt;]：指明仓库服务器和端口(默认443https)，如果是docker hub则可省略(一般都省略) &lt;namespace&gt;：指明用户空间(可以是用户名、组织名等)，如果是顶层仓库可以省略 &lt;name&gt;:&lt;tag&gt;：仓库名和标签名 制作镜像镜像的制作有三种途径： 基于容器的制作，即在运行的容器中使用commit命令将镜像最上层的可写层合并到原始镜像中变成新镜像； 12345678910111213#创建镜像docker commit [options] CONTAINER [REPOSITORY[:TAG]] [REPOSITORY[:TAG]]：指定仓库名和标签名，不指明则为none -p：在制作镜像时暂停容器#打标签docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]#登录docker仓库，阿里云比较快docker login#push镜像，如果不是dockerhub需要指明服务器地址、仓库名等docker push IMAGE_NAME[:TAG] 基于Dockerfile的build命令制作； 基于Docker Hub的automated build制作，它本质也是基于Dockerfile来制作，它需要监视联合github，每次用户对Dockerfile的修改先推送到github上，然后Docker Hub会不断监视Github是否发生改动，如果有改动就拉取过来基于Dockerfile进行镜像制作。 推送镜像1234567891011#先登录Registry，默认不指定SERVER为docker hubdocker login [OPTIONS] [SERVER] -p password：指明密码 -u username：指明用户名 SERVER：指定Registry地址#给指定镜像打标签，注意username必须是顶层仓库名，如果不是顶层仓库还需要依次指明仓库名docker tag image username/repository:tag#推送，按照打标签的格式推上去即可docker push username/repository:tag 网络docker网络通信主要有四种方式：bridge、host、none、container 模式 解释 Bridge 使用虚拟网卡和虚拟交换机实现 Host namespace不分配网络资源，公用物理主机网络资源 None 没有网卡，不能进行网络通信 Container 和已存在的运行的容器共享网络资源 Bridge该模式是docker的默认模式，它使用模拟网卡和模拟交换机实现。可以理解为将网卡分成两半即每个网卡都是成对出现的，一半在docker上，一半在软件模拟的交换机上(网卡名称一样)。 12345678910111213141516171819#模拟的虚拟交换机(有ip时也当作模拟网卡)，在物理机使用如下命令查看#可以看出编号为3的docker0的设备即为虚拟交换机，编号为9的vethcf37621@if8的网卡设备为虚拟网卡，且该设备连接在docker0上ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:b1:56:1d brd ff:ff:ff:ff:ff:ff3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:6c:8a:31:24 brd ff:ff:ff:ff:ff:ff9: vethcf37621@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether 66:17:df:67:22:31 brd ff:ff:ff:ff:ff:ff link-netnsid 0 #查看docker容器的虚拟网卡#其中eth0@if9表示的就是上述vethcf37621@if8的另一半虚拟网卡，相当于连接到docker0上(类似于一根网线)ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:008: eth0@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 另外，在bridge模式下，不仅容器间可以正常通信(处于同一个虚拟交换机上)，容器也可以同外部主机进行通信。实现方法是通过iptables的nat规则实现SNAT，使用如下命令查看 12345678iptables -t NAT -vnL...Chain POSTROUTING (policy ACCEPT 567 packets, 44852 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0...#上述条目标明从本机发出报文时，如果不是发往docker0网卡的且源地址为172.17网段的，都要做源地址转换，转换后与外界通信时使用的是物理机的网卡信息 最后，既然本机的docker容器可以访问外网地址，那么外网地址是否可以访问本机呢，答案是肯定的。当本机启动一个进程后(监听在某个端口上)，这是会添加一条新的iptables规则，如下 123456789101112#运行nginx的docker映射到本地80端口，前者为主机端口，后者为容器内端口，-d表示后台运行dockerdocker run -p 80:80 -d nginx#iptables -t nat -vnLChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.2:80 #可以看出，任何以目标端口为80的请求都会做DNAT，将其地址改为172.17.0.2，因此可以实现通信#也可以使用如下命令查看端口映射docker port c6849e28cea7 Host该模式下，docker和物理主机共用网络资源，换句话说没有对docker容器进行namespace的网络资源隔离。通信的话就直接使用物理网卡进行通信即可。 None不具有网络功能，主要用于实现一些计算等不用网络的docker容器。 Container其实和host很像。但是该模式并不是没有隔离网络资源，而是仅设置为该模式的两个共享网络资源，即共享的是分配的namespace的网络资源，而host是共享的物理主机的资源，根本不存在namespace概念(单指网络，其他资源依旧隔离)。可以理解为一台主机上的两各进程间通信，但是有一定隔离。 12#表示nginx容器和infracon容器使用Container模式网络docker run --name nginx --network container:infracon -it busybox 自定义12345678#创建虚拟交换机mybr1docker network create -d bridge --subnet \"192.163.10.0/24\" --gateway \"192.168.10.1\" mybr1#运行docker时加入自定义的mybr1docker run -it --network mybr1 nginx#若想要不同虚拟交换机之间的docker能够通信，只需要开启物理机的核心转发即可#注意，iptables会添加很多规则，若想实验可以先保存规则再删掉echo 1 &gt; /proc/sys/net/ipv4/ip_forward 配置实例此处使用ip netns命令模拟网络名称空间的设定。此处只是将Net的namespace隔离开，其他五个namespace资源全部共享。 1234567891011121314151617181920212223#添加网络名称空间ns1和ns2ip netns add ns1ip netns add ns2#查看网络空间ip netns list#查看ns1和ns2内部的网卡，只能看到一个lo回环设备，无网卡ip netns exec ns1 ifconfig -a#创建虚拟网卡对ip link add name veth1.1 type veth peer name veth1.2#查看创建的虚拟网卡对，可以从名字看出是成对的网卡ip link show24: veth1.2@veth1.1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 4e:20:59:46:17:81 brd ff:ff:ff:ff:ff:ff25: veth1.1@veth1.2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether a2:a8:b7:cb:4d:8d brd ff:ff:ff:ff:ff:ff#将成对的两个网卡分别移动到不同的netns中ip link set dev veth1.2 netns ns1ip link set dev veth1.1 netns ns2#激活物理机网卡veth1ip netns exec ns2 ifconfig veth1.1 192.168.163.120/24 upip netns exec ns1 ifconfig veth1.2 192.168.163.121/24 up 其他配置修改默认docker0桥地址 1234#修改/etc/docker/daemon.json，只需要添加bip即可，其他会自动添加，多个项之间使用\",\"隔开&#123; \"bip\": \"192.168.163.2/24\"&#125; 修改docker服务器监听地址，默认是基于本机/var/run/docker.sock通信 1234567#编辑/etc/docker/daemon.json&#123; \"hosts\": [\"tcp://0.0.0.0:2375\",\"unix:///var/run/docker.sock\"]&#125;#另一台主机使用-H选项指明docker服务器地址docker -H IP_ADDR COMMANDS 存储卷概念docker镜像由多个只读层叠加而成，启动容器时docker会加载只读镜像层并在镜像层顶部添加一个读写层，用户所有的对镜像的写操作都在此层中生效。如果运行中的容器修改了一个已存在的文件，那该文件将会从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在，只是已经被读写层中该文件的副本所隐藏，这就是所谓的写时复制机制。另外，用户在读写层对文件进行删除操作时，只是相当于在该文件上做了删除标记，此后在读写层该文件对用户不可见，在只读层该文件依然存在。 由上可知，docker容器在关闭后全部更改都会丢失，因此会存在容器间数据共享不便、删除容器数据丢失、不利于分布式容器集群管理等问题。因此，为解决以上问题提出了卷的概念。实际上卷是容器上的一个或多个目录，此目录与物理机上的某个目录存在绑定关系，这样即使容器删除后，其数据依然存在本地，下次再启动容器时该数据依然存在。 类型docker中有两种类型的卷，每种类型都在容器中存在一个挂载点，但其物理主机上的位置有所不同 Bind mount volume：容器和物理机的目录都需要手动指定 Docker-managed volume：容器内的目录手动指定，物理机的目录由docker管理 12345678#docker管理卷，指明容器内目录为/datadocker run -it -v /data --name bbox1 busybox#Bind挂载，指明物理机目录和容器内目录docker run -it -v HOSTDIR:VOLUMEDIR --name bbox2 busybox#查看挂载属性docker inspect -f &#123;&#123;.Mounts&#125;&#125; bbox1docker inspect -f &#123;&#123;.Mounts&#125;&#125; bbox2 另外，可以实现用一个容器单独作为卷，其他容器绑定在该容器上。在实际使用中，使用一个专门做基础容器镜像的容器来代替此处自建的infracon，它只需要实现被其他容器关联即可，不需要启动。 1docker run --name nginx --network container:infracon --volumes-from infracon -it busybox Dockerfile前文创建镜像时提到过dockerfile，它是一个文本描述文件，其内包含了一条条指令来描述如何构建一个镜像文件。编写dockerfile时，需要创建一个目录将dockerfile文件放入该目录中，之后dockerfile内指令需要的所有文件都放到该目录或者该目录的子目录中。.dockerignore文件可以指定哪些文件不需要被build进镜像中。 不同的关键字定义不同的指令功能，dockerfile本身对字符大小写不敏感，但是一般关键字默认使用全大写。 FROMFROM指令是dockerfile文件第一个非注释行，用于指明镜像文件的构建过程的基准镜像，后续的指令都运行于此基准镜像所提供的运行环境之上。默认情况下docker build时会在docker主机上查找指定的镜像文件，在其不存在时默认从docker hub上拉取镜像文件，也可以从指定的仓库拉取镜像文件。 1234567#语法FROM &lt;repository&gt;[:&lt;tag&gt;] &lt;repository&gt;：基准镜像名称 &lt;tag&gt;：基准镜像的标签，默认为latest#另外一种语法FROM &lt;repository&gt;@&lt;digest&gt; &lt;digest&gt;：指明基准镜像的hash值 LABEL用来取代MAINTAINER关键字。它是用来为镜像添加元数据，如镜像名称、制作时间、作者等信息。 12#语法LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;... COPY用于将dockerfile目录下的文件复制到镜像文件中。 123456789101112#语法COPY &lt;src&gt;... &lt;dest&gt; &lt;src&gt;：要复制的源文件或目录，支持使用通配符 &lt;dest&gt;：目标路径，即正在创建的镜像文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则使用关键字WORKDIR指明的路径#另一种语法，用于路径中有空白字符COPY [\"&lt;src&gt;\"...\"&lt;dest&gt;\"]#注意&lt;src&gt;必须是build上下文中的路径(即dockerfile文件所在的目录中的文件)，不能是其父目录中的文件如果&lt;src&gt;是目录，则其内部文件或子目录会被递归复制，但&lt;src&gt;目录自身不会被复制如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用通配符，则&lt;dest&gt;必须是一个目录且必须以/结尾指明是目录如果&lt;dest&gt;不存在，会自动创建(包括其父目录) ADD与COPY类似，但是ADD支持tar文件打包和url文件联网下载 123456789#语法ADD &lt;src&gt;... &lt;dest&gt;#另一种语法，用于路径中有空白字符ADD [\"&lt;src&gt;\"...\"&lt;dest&gt;\"]#注意COPY有的特性ADD都有如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并创建为&lt;dest&gt;；如果&lt;dest&gt;以/结尾，则保存至其目录下如果&lt;src&gt;是一个本地系统上的压缩格式的tar文件，其将会被展开成目录放在&lt;dest&gt;下；如果是网上下载的tar文件则不会展开 WORKDIR用于为dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY、ADD指明工作目录，可以多次指定且只对该关键字后的指令有效 123456#语法WORKDIR &lt;dirpath&gt;#注意WORKDIR可以出现多次，若其为相对路径则是相对上一个WORKDIR的相对路径WORKDIR可以调用由ENV指定定义的变量 VOLUME用于在镜像中创建挂载卷，用来挂载物理主机或者其他容器的卷。 1234567#语法VOLUME &lt;mountpoint&gt;#另一种语法，用于路径中有空白字符VOLUME [\"&lt;mountpoint&gt;\"]#注意此处只能指定docker容器中的路径，不能手动指定物理主机的挂载路径，使用的是docker管理的挂载方式 EXPOSE用于为容器打开指定要监听的端口以实现与外部通信 123456#语法EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [port][/&lt;protocol&gt;]... &lt;protocol&gt;：指定传输层协议，默认为tcp协议 #注意镜像并不会直接暴露出可暴露的端口，而是当run时使用-P选项才暴露所有设定的端口 ENV用于为镜像定义所需要的环境变量，并可被dockerfile文件中定义于其后的其他指令(如ENV、ADD、COPY等)调用 12345678#语法，一次只能设置一个变量ENV &lt;key&gt;=&lt;value&gt;#另一种语法，一次可以设置多个变量，多个变量可以使用\\续行来定义ENV &lt;key&gt; &lt;value&gt; ...#调用格式$var_name$&#123;var_name&#125; RUN用于指定docker build过程中运行的程序，可以是多条命令 1234567891011#语法RUN &lt;command&gt; &amp;&amp; &lt;command&gt;...#另一种语法RUN [\"&lt;executable&gt;\",\"&lt;param&gt;\"]#注意RUN命令执行的一般是shell命令，其以\"/bin/sh -c\"来执行这些命令定义多个RUN时会依次执行第一种语法格式默认使用shell来解释执行，因此其父进程为shell，则其id不为1，不能接收unix信号第二种语法格式默认使用内核exec来执行，不支持shell特性如通配等，但可以接收unix信号，若想以shell执行可以使用如下命令RUN [\"/bin/sh\",\"-c\",\"&lt;executable&gt;\",\"&lt;param&gt;\"] CMD类似于RUN，不过该关键字定义的命令运行在docker run过程中 123456789101112#语法CMD &lt;command&gt;#语法2CMD [\"&lt;executable&gt;\",\"&lt;param&gt;\"]#语法3CMD [\"&lt;param1&gt;\",\"&lt;param2&gt;\"]#注意同RUN该指令运行于镜像启动为容器时默认要执行的命令，其执行结束后容器也会终止，可以被run选项覆盖在dockerfile中可以定义多条CMD，但仅最后一条会生效第三种语法格式用于为ENTRYPOINT指令提供默认参数 ENTRYPOINT类似于CMD指令的功能，用于为容器指定默认运行程序，从而使容器像一个单独的可执行程序。 123456789#语法ENTRYPOINT &lt;command&gt;#语法2ENTRYPOINT [\"&lt;executable&gt;\",\"&lt;param1&gt;\",\"&lt;param2&gt;\"]#注意同CMD一般的例如CMD命令，在run执行时可以自己使用命令替换掉，但是ENTRYPOTIN不行，自己后写的命令只会被当作它的参数来运行同时定义CMD和ENTRYPOINT时，CMD会被当作ENTRYPOINT的参数 USER用于指定运行镜像时或运行dockerfile种任何RUN、CMD、ENTRYPOINT等指令指定的程序时的用户名或UID。默认情况下，container的运行身份为root用户。 123456#语法USER &lt;UID&gt;|&lt;UserName&gt;#注意指明的用户需要在/etc/passwd中有该用户的信息root用户不需要上述条件，因为root用户属于内核 HEALTHCHECK用于检查容器工作是否正常 123456789101112131415#语法，运行脚本检查HEALTHCHECK [options] CMD command options： --interval=DUARATION #间隔时间，默认30s --timeout=DURATION #超时时长，默认30s --start-period=DURATION #run之后等待主进程启动的时间，默认0s --retries=N #检查次数，默认3次 #健康检测状态返回值0：表示容器健康1：表示不健康2：保留位，暂不使用#注意通常健康检测时使用CMD配合命令检测，最后加个||exit 1即可，如果正常则不会执行exit 1，如果不正常会执行exit 1 SHELL 用于定义默认的shell环境 12345678#语法SHELL [\"executable\",\"parameters\"]#注意默认linux为：SHELL [\"/bin/sh\",\"-c\"]默认windows为：SHELL [\"cmd\",\"/S\",\"/C\"] ARG用于定义变量，但指令只在build过程使用。 12345#语法ARG &lt;name&gt;[=&lt;default value&gt;]#注意可以在build时使用--build-arg &lt;varname&gt;=&lt;value&gt;来设置 ONBUILD用于在dockerfile中定义一个触发器，当该镜像文件被别人作为基础镜像文件时会执行该指令 123456#语法ONBUILD &lt;INSTRUCTION&gt;#注意ONBUILD不能自我嵌套ONBUILD中最好不要使用ADD或COPY指令，因为无法判断另一个制作镜像的人是否有指定的文件路径 实例实现nginx配置 123456789101112131415161718192021#dockerfileFROM nginx:latestENV NGX_DOC_ROOT='/data/web/html/'ADD entrypoint.sh /bin/#-g表示运行在前台，daemon off表示不使用守护进程运行CMD [\"/usr/sbin/nginx\",\"-g\",\"daemon off;\"]ENTRYPOINT [\"/bin/entrypoint.sh\"]#上面两个组合起来相当于执行 /bin/entrypoint.sh /usr/sbin/nginx -g daemon off#entrypoint.sh#!/bin/sh#cat &gt; /etc/nginx/conf.d/www.conf &lt;&lt; EOFserver &#123; server_name $&#123;HOSTNAME&#125;; listen $&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;; root $&#123;NGX_DOC_ROOT:-/usr/share/nginx/html&#125;;&#125;EOF#由于CMD定义的变成该脚本的参数，执行此命令就是将参数当作命令执行，从而使得nginx变成id为1的进程exec \"$@\" RegistryRegistry用于保存docker镜像，包括镜像的层次结构和元数据。用户可以自建Registry，也可以使用默认的Dockers hub 分类 Sponsor Register：第三方Registry，共客户和docker社区使用 Mirror Registry：第三方Registry，只让客户使用 Vendor Registry：由发布docker镜像的供应商提供的Registry Private Registry：通过设有防火墙和额外的安全层的私有实体提供Registry 搭建私有Registry此处使用harbor来搭建私有Registry，它有良好的UI界面。 1234567891011121314151617181920212223242526272829#安装docker-compose，这是一个用于单机管理和运行多个docker容器的工具yum install -y docker-compose#此处省略harbor下载和解压缩，一般将其解压缩到/usr/local/下#配置harbor.conf#设置ip或主机名hostname = 192.168.163.132#访问协议，默认是http，也可以设置https，如果设置https，则nginx ssl需要设置onui_url_protocol = http#设置最大子进程数，一般小于等于cpu物理核心数max_job_workers = 3#设置管理密码harbor_admin_password = Harbor12345#配置相关数据库db_password = root123#注意本地搭建的私有Registry后会不允许你上传和下载操作，因为docker默认使用https协议，即使你私建CA也无法获取docker信任，因此在此处让docker忽略https安全选项，在/etc/docker/daemon.json中定义即可&#123; \"insecure-registries\": [\"10.0.86.193\"]&#125;另外，如果需要远程登录docker服务器，那么还需要指定在unit file中的ExecStart处添加 –insecure-registry#安装，实际就是根据脚本执行docker-compose命令，命令配置文件就是docker-compose.yml./install.sh#启动|停止服务docker-compose start|stop 资源限制默认docker不限制资源的使用，即docker可以使用物理机的所有资源。 内存12345-m：限制容器可用最大物理内存大小#注意，在容器中使用free命令不是真的swap空间大小--memory-swap：容器可以与磁盘交互的大小，但算法比较特殊，它的数值不代表真的swap大小--oom-kill-disable：设置true时表示禁止被OOM机制(内存不足)杀死--memory-swapiness：设置使用swap的倾向性，0~100，0表示能不用就不用(不是禁用)，100表示能用就用 –memory-swap –memory/-m 功能 正数S 整数M 总大小为S，swap为S-M，物理内存为M 0 整数M 相当于未设置swap unset 整数M 若主机(docker host)启用了swap，则容器可用swap=2*M -1 整数M 同上，容器可使用最大至主机上的所有swap空间的swap资源 CPU12--cpu-shares：指定cpu分配比率--cpu=&lt;value&gt;：指明cpu核心数使用，可以为小数 压测压测一般使用镜像来测试，在docker hub上搜索stress找一个即可，此处不进行演示。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/%E5%AE%B9%E5%99%A8/"}],"author":"Frdqy"},{"title":"zabbix详解","slug":"zabbix详解","date":"2020-01-26T06:03:21.000Z","updated":"2020-01-26T06:07:28.709Z","comments":true,"path":"2020/01/26/zabbix详解/","link":"","permalink":"http://yoursite.com/2020/01/26/zabbix%E8%AF%A6%E8%A7%A3/","excerpt":"概念监控对象主机、交换机、路由器等","text":"概念监控对象主机、交换机、路由器等 采样采样指的是周期性地获取某个关注指标相关的数据。 采样通道，即监控系统通过什么途径获取被监控主机的信息。一般有如下几种： ssh/telnet agent/master，即在被监控主机上部署应用程序 IPMI，intel监控接口 SNMP，简单网络监控协议，通常用于交换机路由器等 JMX，java监控系统，主要用于JVM虚拟机的监控 存储即监控获得的数据和数据的存储方式。 数据 历史数据，指每次采样的结果，保存时间周期较短 趋势数据，指聚合数据结果(最大值、最小值等)，保存时间周期较长 存储系统 关系型数据库：Mysql、Oracle等 RRD：轮询数据库，类似一个环形文件系统，保存指定量或者时长的数据后就直接覆盖之前数据继续存储 非关系型数据库：redis等 报警邮件、短信、微信、电铃等。只要能通过脚本实现即可。 zabbix特性数据采样：snmp、agent、impl、jmx 报警：支持步进式升级报警 数据存储：mysql 展示：php程序，支持绘图，滑动显示等 其他：支持监控模板定义，可适配多台主机；支持网络自动发现；支持分布式监控；支持基于API的二次开发 架构 Zabbix server：服务端监控程序(守护进程)，负责接收agent发送的报告信息；所有配置统计数据等均由其组织进行；监听在某个端口 Zabbix proxy：监控代理，一般用于分布式监控系统中。代理接收当前分布式环境中的数据后统一发送给server Zabbix database：存储监控信息的数据库；也存储配置信息；常用Mysql Zabbix web GUI：用于展示监控信息的web页面 Zabbix agentd：部署在被监控主机上的守护进程，负责收集其本地数据并发往server端或proxy端 Zabbix sender：命令行工具，用于在agent端测试能否向server端发送数据 Zabbix get：命令行工具，用于在server端向agent端拉取数据 监控方式 Agent：客户端模式，可分为主动(active)和被动(passive)模式 SNMP：简单网络管理协议，主要有get、set、trap操作(agent向server主动通信) IPMI：intel平台提供的智慧平台管理接口，用于监测物理特性(cpu温度等)，需要服务器提供硬件层面的接口 JMX：Java管理拓展，用于通过java自己的接口对java程序进行监控。在zabbix使用中，需要使用额外的程序包帮助实现 流程 Poller：server端向agent端索要数据的动作 host：要监控的网络设备，可由IP或DNS名称指定。 host group：主机组。即host的逻辑容器。包含主机和模板，但同一个组内的主机和模板不能互相连接；主机组通常在给用户或用户组指派监控权限时使用。 item：监控项。一个特定监控指标的相关数据，这些数据来自被监控对象。每个item由”key”标识。 application：应用。即一组item的集合。 trigger：触发器。即一个表达式，用于判断监控对象某特定item内所接收到的数据是否在合理范围内，超过合理范围时，触发器状态从”OK”转化为”Problem”，反之亦然。 event：事件。由触发器触发的事件。例如触发器状态转变、新的agent上线等。 action：动作。指对于特定事件的处理方式。通常由触发器触发某事件后执行某动作。 escalation：报警升级。发送警报或执行远程命令的自定义方案，如每隔5分钟发一次警报，共发送5次。 media：媒介。发送通知的手段或通道，如Email等。 notification：通知，通过选定的媒介向用户发送的有关某事件的信息。 remote command：远程命令。即预定义的命令，可在被监控主机处于某一特定条件下时自动执行。 template：模板。用于快速定义被监控主机的预设条目集合，通常包含item、trigger、graph、screen、application以及low-level discovery rule；模板可之间连接至单个主机。 web scenario：web场景。用于检测web站点可用性的一个或多个HTTP请求。 frontend：前端。Zabbix的web接口。 安装配置安装配置mysql；设置zabbix database 1234567891011#安装mariadbyum install mariadb-server -y#编辑/etc/my.cnf，在[mysqld]字段下添加#不进行域名反解和关闭单独表空间skip_name_resolve=ONinnodb_file_per_table=ON#创建数据库create database zabbix charset 'utf8';#授权用户grant all on zabbix.* to 'zbxuser'@'%' identified by 'dqy751421'; 安装zabbix server程序 1yum install -y zabbix 导入zabbix数据库脚本，生成数据库文件 123456mysql -uzbxuser -pdqy751421 zabbix#导入/usr/share/zabbix-mysql目录下的三个文件创建数据表(上面已提前创建数据库)mysql -uzbxuser -pdqy751421 zabbix &lt; /usr/share/zabbix-mysql/schema.sqlmysql -uzbxuser -pdqy751421 zabbix &lt; /usr/share/zabbix-mysql/images.sqlmysql -uzbxuser -pdqy751421 zabbix &lt; /usr/share/zabbix-mysql/data.sql 配置文件修改DB相关值即可启动服务 12345678DBHost=localhost #指明数据库地址DBName=zabbix #指明数据库名DBUser=zbxuser #指明数据库用户DBPassword=dqy751421#指明数据库密码DBPort=3306 #指明mysql数据库端口#启动，监听10051端口systemctl start zabbix-server 环境配置配置文件：/etc/zabbix/zabbix_server.conf Unit File：zabbix-server.service zabbix server配置使用192.168.163.132作为server端 1234567891011121314#/etc/zabbix/zabbix_server.conf#注意初始时数据库相关配置都没有配置，需要手动指定ListenPort=10051 #server默认监听10051SourceIP #在客户端定义的可采样的服务端地址LogType #日志格式，包括syslog、file、consoleLogFile=/var/log/zabbix/zabbix_server.log #日志文件(基于file存放)LogFileSize=0 #日志文件大小，超过后开始滚动(0标识禁止滚动)DebugLevel=3 #定义日志记录级别，默认为warningsDBHost=localhost #指明数据库地址DBName=zabbix #指明数据库名DBUser=zbxuser #指明数据库用户DBPassword=dqy751421#指明数据库密码DBPort=3306 #指明mysql数据库端口DBSocket=/tmp/mysql.sock #指明mysql.sock路径 web配置安装一些基本程序。用于测试的话可以与zabbix安装在一台主机上，不过推荐分开装。 1234567891011121314#安装phpyum install -y httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml#安装web guiyum install -y zabbix40-web zabbix40-web-mysql#配置时区，在/etc/httpd/conf.d/zabbix.conf设置php_value date.timezone Asia/Shanghai#启动httpdsystemctl start httpd#浏览器输入如下地址进行安装zabbixhttp://192.168.163.132/zabbix/setup.php#如果安装有问题，如某个参数填错了，需要在如下文件中修改/etc/zabbix/web/maintenance.inc.php#在浏览器中直接finish启动，默认账号密码是admin、zabbix zabbix agent配置使用192.168.163.135作为一个agent 12345678910111213#安装agentyum install -y zabbix40-agent#配置/etc/zabbix/zabbix_agentd.confServer=192.168.163.132 #被动模式，指明允许来采样的服务器地址ListenPort=10050 #监听的端口ListenIP=0.0.0.0 #监听的地址StartAgent=3 #生成几个子进程来响应ServerActive=IP #主动模式时将样本上交给哪个服务器Hostname=node1.dqy.com #指明主机名#启动服务systemctl start zabbix-agent 监控配置配置顺序：host groups–&gt;host–&gt;applications–&gt;item–&gt;triggers(event)–&gt;action(conditions,operations) 通过condition定义监听哪个event，然后监听到就进行operation操作。operation包含remote command和alert item可以生成简单的graph；多个graph构成screen；多个screen构成slide show 设置host 设置item 设置item时必须选择相应的key。所谓的key可以理解为一串指令的特征码。因为server想要获取agent的某些参数，肯定时agent执行某些命令的结果过滤而来的，而这个命令可能很长，因此使用key来定义一串命令。zabbix有自带的key(一般是系统运行的指标)，若需要自定义，只需在/etc/zabbix/zabbix_agentd.conf文件中的USER-DEFINED MONITORED PARAMETERS字段下添加即可。 另外，有的key可以传递参数，实际就是传给key对应的命令，类似脚本编程时用$传参。 12#在server端使用如下命令查看指定agent端对应的key的值，其中[]内即为参数zabbix_get -s 192.168.163.135 -k \"net.if.in[ens33,packets]\" 设置trigger 一个触发器由一个表达式构成，它定义了监控项所采取的数据的一个阈值，用于监控item的取值范围(表达式定义的是不合理区间，因此结果为真时说明有问题)。每一个触发器仅能关联至一个item，但可以为一个item同时使用多个触发器，从而实现不同级别的报警功能。 1234567&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constantserver：主机名key：主机上关系的相应监控项的keyfunction：评估采集到的数据是否在合理范围内所用的函数，主要有：avg、count、change、date、dayofweek、delta、diff、iregexp、last、max、min、nodata、now、sum等parameter：函数参数。正常表示以秒为单位的数值，如果参数前面加#作为前缀，则表示最近几次的取值。如sum(300)表示300秒内的取值；sum(#10)表示最近10次取值之和。另外avg、count、last、min、max还支持使用第二个参数，用于完成时间限定；例如，max(1h,7d)表示1小时检测依次且将返回一周之前的最大值。对于last函数来说，last(0)表示last(#1)，即最后一次 设置actionaction由condition和operation组成。在Configuration标签下的Actions标签进行编辑。 如上图，在Action标签中定义Condition，指明trigger后选择对应条目即可。 在上图Operation界面定义满足condition后的操作，可以有多个操作(动作可以由多个步骤组成)，通过step来定义各个操作的执行步骤。其中Default operation step duration表示默认默认操作步骤持续时间。下面的steps：1 -1表示当前步骤为第一步持续时长为1；2-2表示第二步持续时长为1；3-4表示第三步持续时长为2步(即由3、4两小步组成)；5-7表示第四步持续时长为3步(即由5、6、7三小步组成)。这种设置可以达到警报升级的作用。 condition：触发此动作的条件，一般通过trigger触发 operation：触发条件满足时要采取的动作。包括send message和remote command。 remote command包括：IPMI命令、custom script(常用)、ssh、telnet、global script 12345#使用remote command之前还需要如下设置#给在agent端给zabbix定义sudo规则，/etc/sudoerszabbix ALL=(ALL) ALL#agent主机设置支持远程命令功能EnableRemoteCommands=1 #注意 不支持active模式的agent；不支持代理模式、可以使用宏、命令长度不超过255字符、zabbix-server仅执行命令而不关心命令是否执行成功 1234+ send message：发送报警信息给关联的用户(一般是server主机上定义的用户)。发信息的信道可以使用脚本来发布(实现打电话、微信等)。具体步骤如下： + 定义Administration的meda type，指明邮件服务器及发件人 + 在Administration的user中的media选项定义收件人、收件时间等 设置报警媒介在Administration标签的Media types标签可以设置报警媒介的信息。zabbix支持的报警媒介有： Email：邮件。通过设置的SMTP邮件服务器向指定用户发送报警信息 Script：脚本。自动调用指定脚本进行报警(脚本位置在配置文件中的AlertScriptsPath字段定义)。在定义脚本时可以使用参数，参数在设置时可以用宏指定。具体宏的介绍在下文。 12345678#使用脚本时可以定义不同的参数，调用时使用宏来作为参数调用#脚本默认放在server端的/var/lib/zabbixsrv/alertscripts目录下，若有新的脚本放入必须重启服务#!/bin/bash#to=$1subject=$2context=$3echo -e \"$context\" | mail -s \"$subject\" \"$to\" SMS、Jabber、Ez Texting：都是北美服务，此处不涉及 设置好报警媒介后到Administration标签下的User标签定义用户的报警媒介，此处可以设置收件人。 自定义图形通常用于将多个监控项的图像结合到一起使用。在Configuration标签下的Hosts标签下选定hosts的graphs即可设置。 定义时相关属性如下： name：图像唯一名称 width、height：宽度和高度，单位为像素 graph type：图像类型，线状图(normal)、堆积面积图(stacked)、饼图(pie)、分离型饼图(exploded) show legend：是否显示图例，即图像数据序列说明 show working time：是否高亮显示工作时间区域，不适用pie和exploded show triggers：是否显示触发器，不适用pie和exploded Y axis MIN value：Y轴最小刻度 Calculated：自动计算 Fixed：固定值，不适用pie和exploded Item：相关item的最近一次取值为其最小刻度 Y axis MAX value：Y轴最大刻度，相关选项同上 Items：图形展示的数据列所来自的item，一个图形中可以同时展示多个item。item相关属性如下： Function：展示各种聚合数据 min：仅展示最小值 avg：仅展示平均值 max：仅展示最大值 all：展示所有，即上述三种数据 Draw stype：绘图风格，仅用于线状图 Line：绘制为简单线条 Filled region：区域填充图，即面积图 Bold line：加粗线条 Dot：虚线图，以稀疏点组成 Dashed line：虚线图，以破折号组成 Y axis side：Y轴显示的位置，可以为图形左侧或右侧 Colour：图形颜色 定义screenscreen即屏幕。屏幕用于集中展示多个数据源的相关信息，可实现快速浏览关注的信息。从根本上讲，screen就是一个图标，可以在创建时指定行数列数(即每行多少个图形，共多少行)，而后在每个格子中指定要展示的内容。 在Monitoring的Screens标签下创建，根据定义显示即可。map也差不多配置，这里不多说。 宏Macro，即一种预设的文本替换模式，可以理解为文本类型的变量。主要分为两类： 内建：{MACRO_NAME} 自定义：{$MACRO_NAME} 可以在三个级别使用： Global：全局宏。在Administration的General右侧的Macros选项中定义 template：模板宏。直接编辑相应主机或模板属性即可 Host：主机宏。在Configuration的Hosts标签下选定某个host后选择上方的Macros标签即可定义主机宏，该宏只对此主机使用。 宏定义优先级：Host&gt;Template&gt;Global 具体宏参照官方文档： []: https://www.zabbix.com/documentation/4.0/manual/appendix/macros/supported_by_location 模板模板是一些列配置的集合，支持模板嵌套定义，用于快速部署和重复应用(链接)。具体配置和host一样，可以指定Application、host、trigger、item、graph、screen、discovery、web。具体过程和普通定义时一样，依次添加各种item和trigger即可。模板可以导出与导入。 维护时间用于实现将某台服务器下线管理而不引起trigger报警。定义在Configuration的Maintenance中。在设置trigger时需要指定Maintenance status not in maintenance来实现在维护时间不触发触发器。 自定义监控项实现用户自定义item key，从而实现特有数据指标的监控。需要定义在agent端且定义好后需要重启agent。 12345678910111213#语法,[*]表示可以接收任意个参数，且这些参数可以在command中使用$1-&gt;$9进行引用#另外，如果在命令中需要使用$符号且key中有参数时，例如awk中打印某一字段时会使用$，那么就要使用$$来保留原来的$。UserParameter=&lt;key[*]&gt;,&lt;command&gt;#编辑配置文件/etc/zabbix/zabbix_agentd.d/目录下新建一个配置文件即可UserParameter=os.memory.used,free -m | awk \"/^Mem/&#123;print $3&#125;\"#重启zabbix-agentd，之后在服务端之间使用os.memory.used作为key即可systemctl restart zabbix-agentd#举例：实现监控mysql数据库的插入、查询、删除命令的使用次数，可能需要做词尾牟定“&gt;”UserParameter=Mysql.dm[*],mysql -h$1 -u$2 -p$3 -e 'SHOW GLOBAL STATUS' | awk '/Com_$4\\&gt;/&#123;print $$2&#125;'#server端执行测试，测试前在agent的数据库需要用户授权访问zabbix-get -s 192.168.163.135 -p 10050 -k \"Mysql.dml[192.168.163.132,root,dqy751421,select]\" 网络发现zabbix基于http、icmp、ssh、ldap、tcp、snmp、telnet等协议扫描指定网络内主机。网络发现主要分为discovery和actions两个阶段，一旦主机被发现，如果想对其进行操作，需要由action来决定。 Discoveryzabbix会周期的扫描事先定义在网络发现规则中的网络地址范围，扫描的频率可以根据每个规则所定义的频率来设定。一旦有主机被发现就会触发Discovery的event事件。有如下八种事件： 事件 产生原因 Service Up 服务上线 Service Down 服务离线 Host UP 主机上线(有服务) Host Down 主机下线(无服务) Service Discovered 服务被发现(第一次) Service Lost 服务丢失 Host Discovered 主机被发现 Host Lost 主机丢失 在Configuration的Discovery标签下进行网络主机发现的定义，如下所示 Name：指明发现服务名称 IP range：定义扫描的ip段 Update interval：扫描间隔(不宜过短，会严重降低zabbix性能) Checks：基于什么协议进行扫描 Device uniqueness criteria：指明基于ip地址来唯一确定主机 注意：网络发现中添加主机时会自动创建interface，哪个检测成功就会创建相应的interface。如果某服务同时相应多个interface那么就会创建多个；如果同一种发现机制返回非唯一数据(多块网卡)，则第一个接口被默认识别，其他的被识别为额外接口；即便是某主机开始时只有agent接口，后来通过SNMP又发现它，同样会为其添加SNMP接口；不同的主机如果返回相同数据，则第一个主机被添加，余下的主机被当作第一个主机的额外接口。 Action网络发现中的事件可以触发action，从而自动执行指定的操作。action如下： Action 解释 Send notifications 发送通知 Adding/removing hosts 添加/移除主机 Enabling/disabling hosts 启用/禁用主机 Adding hosts to a group 添加主机到组 Removing hosts from a group 从组中移除主机 Linking hosts to/unlinking from a template 链接/删除链接模板到主机 Executing remote scripts 执行远程脚本 在配置Action时，切换Discovery条目进行配置。 首先配置Conditions：需要指定Discovery rule为上面定义的Discovery的name；定义Discovery Status为某个event状态即可。 然后配置Operations：一般设置增加到某个组并连接到某个模板实现监控项的一键设置。 自动注册用于减少zabbix-server端不断扫描造成的资源浪费，且不清楚哪些网段主机可能被添加到zabbix中时使用。该功能用于active模式的agent。 1234567891011#配置agent的/etc/zabbix-agentd.conf#配置agent端active模式下监听的server地址ServerActive=192.168.163.132#被动模式地址也配置，因为有的item设置的是被动模式的监控项Server=192.168.163.132#设置主机名Hostname=node2.dqy.com#设置监听地址，此处不要设置为0.0.0.0，因为该ip会被填加到server识别的host的ip地址处ListenIP=192.168.163.136#设置主机唯一标识(只用于auto registration)HostMetadata=artest 该功能同样需要配置相关Action。在Server端配置Action时，切换Auto Registration条目进行配置。具体配置项目如下： 然后配置Operations，一般配置添加至某个hostgroup以及连接模板即可。需要注意的是模板里设置的item可能都是被动监控方式的，此处需要额外配置主动监控的item。 LLD底层发现，server端会向agent端请求一些数据，而server端根据这些数据来填充特定的item值。常见的item有：#IFNAME(网络接口名称)，#FSNAME(文件系统名称) 它主要是用于定义模板时获取不同agent端的不同的网卡接口、文件系统等信息。这些值存放在agent端的某些key当中，key可以通过zabbix的数据库查看 1select key_ from items where key_ like &#39;%discovery%&#39;; 如上图所示，Name随意填写，Key要填写上面数据库命令查到的对应项(有很多，此处不一一列举)。注意，此处定义好后发现主机时会获取相应的key的值填到对应的item项中，如网卡信息填入#IFNAME中，文件系统信息填入#FSNAME中。这些变量都可以在定义host的item时使用，从而获取不同主机的不同信息。 web监控zabbix可以对web站点进行可用性检测，它可以检测获取的html页面中是否包含预设的字符串，也可以实现登录和点击，具体步骤如下： 创建web监控需要先定义一个web scenarios(在configuration中选定host的web scenario即可定义) ​ Name：唯一标识的scenario名称 ​ Application：选择一个已存在的application，web scenario必须属于一个application ​ Update interval：web scenario的执行间隔 ​ Agent：请求模仿的浏览器类型 ​ Variables：用户自定义一些宏，如用户名密码之类 ​ Attempt：执行多少次 web方案包括一个或多个HTTP请求或步骤(step)，每个步骤的执行过程按照预先定义的顺序进行 ​ Name：唯一的step名称 ​ URL：请求的URL ​ Query fields：请求的数据库查询 ​ Post fields：post请求的相关数据和值 ​ Variables：定义变量 ​ Required status codes：希望返回的状态码，一般为200 ​ Required string：希望获取的字符串 ​ TimeOut：请求的超时时长 有的网站存在认证，需要手动提供 ​ HTTP authentication：认证方式 ​ SSL：剩余ssl相关证书方面如密钥文件、证书文件等","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/%E7%9B%91%E6%8E%A7/"}],"author":"Frdqy"},{"title":"ansible详解","slug":"ansible详解","date":"2020-01-22T12:11:38.000Z","updated":"2020-01-22T12:15:57.474Z","comments":true,"path":"2020/01/22/ansible详解/","link":"","permalink":"http://yoursite.com/2020/01/22/ansible%E8%AF%A6%E8%A7%A3/","excerpt":"概念高度模块化的自动化运维工具，基于ssh协议实现了批量系统配置、批量程序部署、批量运行命令等功能。","text":"概念高度模块化的自动化运维工具，基于ssh协议实现了批量系统配置、批量程序部署、批量运行命令等功能。 架构 Host inventory：定义管理主机的清单，包括ip、账号密码(基于密钥)等 Playbooks：定义每个主机扮演不同的角色，每个角色执行不同的命令，使用YAML格式定义 Core Modules：核心模块 Custom Modules：自定义模块 Plugins：用于通知及日志插件 Connection Plugins：基于ssh的连接主机的插件 Ansible：主控进程 执行流程 加载自己的配置文件，默认/etc/ansible/ansible.cfg； 查找对应的主机配置文件，找到要执行的主机或者组； 加载自己对应的模块文件，如command； 通过ansible将模块或命令生成对应的临时py文件(python脚本)， 并将该文件传输至远程服务器； 对应执行用户的家目录的.ansible/tmp/XXX/XXX.py文件； 给文件 +x 执行权限； 执行并返回结果； 删除临时.ansible/tmp/XXX/XXX.py文件，sleep 0退出。 配置文件ansible自身配置文件：/etc/ansible/ansible.cfg 123456789101112131415161718#各种默认选项[default]inventory = /etc/ansible/hosts #这个参数表示资源清单inventory文件的位置library = /usr/share/ansible #指向存放Ansible模块的目录，支持多个目录方式，只要用冒号（：）隔开就可以forks = 5 #并发连接数，默认为5sudo_user = root #设置默认执行命令的用户remote_port = 22 #指定连接被管节点的管理端口，默认为22端口，建议修改，能够更加安全host_key_checking = False #设置是否检查SSH主机的密钥，值为True/False。关闭后第一次连接不会提示配置实例timeout = 60 #设置SSH连接的超时时间，单位为秒log_path = /var/log/ansible.log #指定一个存储ansible日志的文件（默认不记录日志）module_name = command #默认module为command#与权限提升有关[privilege_escalation]become=Truebecome_mothod=sudo #升级方法become_user=root #升级为哪个用户become_ask_pass=False #升级时是否提供密码 设置ssh因为ansible基于ssh控制各个主机，因此使用密钥验证的ssh登录会比较安全和方便。 12345#一次回车确认，全部默认即可。该指令会在用户家目录下生成.ssh文件夹，里面包括私钥文件id_rsa和公钥文件id_rsa.pub。ssh-keygen -t rsa#将公钥复制到指定主机的~/.ssh/authorized_key文件中ssh-copy-id root@192.168.163.135ssh-copy-id root@192.168.163.136 安装12yum install epel-release -yyum install ansible –y ansible命令12345678910111213141516171819ansible &lt;host-pattern&gt; [options] -m MODULE_NAME：指明调用模块名 -a MODULE_ARGS：指明模块参数 -C：不真实运行，模拟运行结果 -f FORKS：定义每次对多少主机进行操作(默认5个) --list-hosts：根据&lt;host-pattern&gt;列出符合的主机 -i INVENTORY：指明host配置文件(默认在/etc/ansible/hosts) --syntax-check：检测playbook的语法是否有错误 -t TREE：将日志输出到指定文件 --private-key=PRIVATE_KEY_FILE：指明用于连接认证的密钥文件 -u REMOTE_USER：指明连接用户名(默认none) -c CONNECTION：指明ssh连接方式(默认smart) -s：远程执行命令时使用sudo命令 -S：远程执行命令时使用su命令 #获取帮助ansible-doc [options] -l：列出可用模块 -s MODULE_NAME：显示指定模块的可设置选项，有“=”的选项是必须设置的 常用模块ping模块12345678910111213141516#主要用于主机连通性测试[root@www ~] ansible all -m ping 192.168.163.136 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125;192.168.163.135 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"discovered_interpreter_python\": \"/usr/bin/python\" &#125;, \"changed\": false, \"ping\": \"pong\"&#125; group模块用于创建用户组 1234567name= #必选项，指定组的名称gid #设置组的GID号，默认依次往后叠加state #指定组的状态，默认为创建(present)，设置值absent则为删除system #设置值为yes，表示创建为系统组，默认为no#添加组ansible all -m group -a \"name=mygrp\" user模块用于管理和创建用户 123456789101112131415161718name= #必选项，指定用户名comment #用户的描述信息createhome #是否创建家目录force #在使用state=absent时, 行为与userdel –force一致.group #指定基本组groups #指定附加组，如果指定为(groups=)表示删除所有组home #指定用户家目录move_home #如果设置为home=时, 试图将用户主目录移动到指定的目录non_unique #该选项允许改变非唯一的用户ID值password #指定用户密码remove #在使用state=absent时, 行为是与userdel –remove一致shell #指定默认shellstate #设置帐号状态，默认为present创建，指定值为absent表示删除system #当创建一个用户，设置这个用户是系统用户。这个设置不能更改现有用户uid #指定用户的uid#添加用户ansible all -m user -a \"uid=5000 name=testuser state=present groups=mygrp shell=/bin/sh\" copy模块用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等 1234567891011121314151617src #被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制。content #用于替换\"src\"，可以直接指定文件的内容，其将生成为目标文件的内容dest= #必选项，将源文件复制到的远程主机的绝对路径backup #当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息directory_mode #递归设定目录的权限，默认为系统默认权限force #当目标主机包含该文件，但内容不同时，设为\"yes\"，表示强制覆盖；设为\"no\"，表示目标主机的目标位置不存在该文件才复制。默认为\"yes\"others #所有的 file 模块中的选项可以在这里使用group #复制后目标文件的属组owner #复制后目标文件的属主mode #复制后目标文件的权限#复制文件ansible all -m copy -a \"src=/etc/fstab dest=/tmp/fstab.ansible mode=600\"#复制目录，若src的目录最后以\"/\"结尾，则只复制目录内的内容，而不复制目录本身ansible all -m copy -a \"src=/etc/pam.d dest=/tmp/\"#使用content生成文件，默认不换行ansible all -m copy -a \"content='hi there\\n' dest=/tmp/hi.txt\" fetch模块用于从远程主机复制文件到本地 12dest= #必选项，用来存放文件的目录src= #必选项，在远程拉取的文件，并且必须是一个file，不能是目录 command模块在远程主机执行命令，但是无法解析管道等shell特性的命令符号。 123456789chdir #在执行命令之前，先切换到该目录free_form= #必选项，要执行的Linux指令，一般使用ansible的-a参数代替。creates #一个文件名，当这个文件存在，则该命令不执行,可以用来做判断removes #一个文件名，这个文件不存在，则该命令不执行#执行ifconfig命令ansible all -m command -a \"ifconfig\"#切换目录后创建目录ansible all -m command -a \"chdir=/var/tmp mkdir hi.dir\" shell模块在远程主机调用shell来执行命令(具体用法与command一样) 1234567chdir #在执行命令之前，先切换到该目录free_form= #必选项，要执行的Linux指令，一般使用ansible的-a参数代替。creates #一个文件名，当这个文件存在，则该命令不执行,可以用来做判断removes #一个文件名，这个文件不存在，则该命令不执行#修改密码ansible all -m shell -a \"echo dqy751421 | passwd --stdin testuser\" file模块主要用于设置文件属性 1234567891011121314151617181920path= #必选项，设置操作对象路径force #需要在两种情况下强制创建软链接，一种是源文件不存在，但之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选项：yes|nogroup #定义文件或目录的属组owner #定义文件或目录的属主mode #定义文件或目录的权限src #当state=link时指明需要连接的源文件recurse #递归设置文件的属性，只对目录有效，后面跟上src：被链接的源文件路径，只应用于state=link的情况dest #被链接到的路径，只应用于state=link的情况state #状态，有以下选项： directory：如果目录不存在，就创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 #创建目录ansible all -m file -a \"path=/var/tmp/hello.dir state=directory\"#创建符号链接，将src的文件，创建成path指向的link文件ansible all -m file -a \"src=/var/tmp/fstab.ansible path=/var/tmp/fstab.link state=link\" cron模块该模块适用于管理cron定时计划 1234567891011121314day #每天应该运行的工作( 1-31, *, */2, etc )hour #小时 ( 0-23, , /2, )minute #分钟( 0-59, , /2, )month #月( 1-12, *, /2, )weekday #周 ( 0-6 for Sunday-Saturday,, )job #指明运行的命令是什么name #定时任务描述reboot #任务在重启时运行，不建议使用，建议使用special_timespecial_time#特殊的时间范围，参数：reboot（重启时），annually（每年），monthly（每月），weekly（每周），daily（每天），hourly（每小时）state #指定状态，present表示添加定时任务，也是默认设置，absent表示删除定时任务user #以哪个用户的身份执行#每3分钟同步一下时间ansible all -m cron -a \"minute=*/3 job='/usr/sbin/ntpdate ntp1.aliyun.com' name=sync_time\" yum模块用于程序包安装 12345678910name= #必选项，所安装的包的名称state #present或者installed表示安装，latest表示安装最新的, absent或removed表示卸载软件。update_cache #强制更新yum的缓存conf_file #指定远程yum安装时所依赖的配置文件（安装本地已有的包）。disable_gpg_check #是否禁止GPG checking，只用于presentor latest。disablerepo #临时禁止使用yum库。只用于安装或更新时。enablerepo #临时使用的yum库。只用于安装或更新时。#安装nginxansible all -m yum -a \"name=nginx state=installed\" service模块用于各种服务进程的管理 123456789name= #服务名称arguments #命令行提供额外的参数enabled #设置开机启动。runlevel #开机启动的级别，一般不用指定。sleep #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。(定义在剧本中。)state #有四种状态，分别为：started表示启动服务， stopped表示停止服务， restarted表示重启服务，reloaded表示重载配置#启动nginxansible all -m service -a \"name=nginx state=started enabled=yes\" script模块将本地脚本复制到远端服务器运行 1234567free_form= #必选项，要运行的脚本本地路径#脚本实例#!/bin/bash#echo \"ansible script\" &gt; /tmp/ansible.txtansible all -m script -a \"/tmp/test.sh\" setup模块可以获取系统变量，也就是facts。 1ansible 192.168.163.135 -m setup | less template模块基于模板方式生成一个文件复制到远程主机，主要用于生成模块化的配置文件。注意文件根据习惯一般以.j2结尾。 12345678910src= #指明模板文件dest= #指明各主机上基于模板生成的文件owner #定义属主group #定义属组mode #定义权限#ansible all -m template -a \"src=/etc/httpd/httpd.conf.j2 dest=/etc/httpd/httpd.conf\"#j2文件listen &#123;&#123; http_port &#125;&#125; playbook是基于YAML设计的用于ansible管理远端主机的配置文件。根据其描述可以执行一些列任务，从而达到连续配置的效果。 核心元素host：关联到的主机 task：任务列表，即host需要执行的动作 variables：执行任务时需要的变量 templates：包含了模板语法的文本文件 handlers：由特定条件触发的任务(通过notify触发) 基础组件 Hosts：运行指定任务的目标主机 remoute_user：在远程主机上执行任务的用户 task：任务列表(模块+模块参数) action：module arguments module：arguments 1234567tasks： – name: TASK_NAME module: arguments notify: HANDLERS_NAMEhandlers: – name: HANDLER_NAME module: arguments 标签可以通过对不同的task定义不同的tag来实现只执行指定tag的任务 12#执行定义在first.yaml文件中拥有指定TAG_NAME的taskansible-playbook -t TAG_NAME first.yaml 变量可以使用系统自带变量和自定义变量。 facts：可以直接使用的变量，需要在playbook中使用”“来引用变量。因为只有playbook会gather facts，这些facts通过setup模块可以查看。 自定义变量。在playbook中自定义变量后，通过命令行传参 123456789101112131415161718#定义配置文件forth.yaml- hosts: 192.168.163.135 remote_user: root tasks: - name: install package &#123;&#123;pkgname&#125;&#125; yum: name=&#123;&#123;pkgname&#125;&#125; state=installed#调用安装varnishansible-playbook -e pkgname=varnish#通过vars标签定义，执行复制操作- hosts: all remote_user: root vars: - pbvar: playbook variable tasks: - name: copy copy: content=&#123;&#123; pbvar &#125;&#125; dest=/var/tmp/vars.txt host inventory变量。可以在host主机清单文件中直接引用 inventory自带的参数，用于host文件中定义连接目标主机时使用 ansible_ssh_host ansible_ssh_port ansible_ssh_user ansible_ssh_pass ansible_sudo_pass 向不同的主机传递不同的变量，格式为： 1234IP/HOSTNAME var1=value1 var2=value2#举例，表示向135这台主机可以传递http_port变量，其值为80192.168.163.135 http_port=80 向组中的主机传递相同的变量，即一个组的主机共享变量 123456[group:vars]var1=value1#举例，表示websrvs组拥有自定义变量http_port[websrvs:vars]http_port=8080 模板文本文件，基于Jinja2语法，使用template模块 12345678910111213141516171819- hosts: all remote_user: root tasks: - name: install nginx yum: name=nginx stata=installed - name: install core file template: src=files/nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart nginx - name: start nginx service service: name=nginx state=started handlers: - name: restart nginx service: name=nginx state=restarted #模板配置文件nginx.conf.j2#facts内置变量worker_processes &#123;&#123; ansible_processor_vcpus &#125;&#125;#host清单定义的变量listen &#123;&#123; http_port &#125;&#125; 条件测试when在task中使用，jinja2语法格式 1234567tasks:- name: install conf file to centos7 template: src=/files/nginx.c7.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == \"7\"- name: install conf file to centos6 template: src=/files/nginx.c6.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == \"6\" 循环在tasks中使用。对迭代项的引用，固定变量名为item，且要在task中使用with_items给定要迭代的元素列表 12345678910111213141516#列表tasks:- name: install some packages yum: name=&#123;&#123; item &#125;&#125; state=installed with_items: - httpd - php - nginx #元组- name: add some users user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; state=present with_items: - &#123; name: 'user11', group: 'group11' &#125; - &#123; name: 'user12', group: 'group12' &#125; - &#123; name: 'user13', group: 'group13' &#125; 角色自包含的目录结构。role文件定义于/etc/ansible/roles/问价夹下。它将playbook原本的设置进行分片，即tasks只定义在tasks文件夹下，其他以此类推。 123456789101112131415161718#此时，nginx就是一个角色，即一个rolemkdir /etc/ansible/roles/nginx/&#123;tasks,vars,templates,files&#125; -pvnginx/ tasks/：至少包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含 vars/：至少包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含 templates/：所有模板文件 files/：存放由copy或script模块等调用的文件 handlers/：至少应该包含一个名为main.yml的文件；其他文件需要在此文件中通过include进行包含 meta/：至少应该包含一个名为main.yml的文件；定义当前角色的特殊设定及其依赖关系；其他文件需要在此文件中通过include进行包含 defaul/：设定默认变量时使用此目录的main.yml文件 #可以在playbook中传递变量给角色- hosts: remote_user: roles: - &#123; role: nginx, username: nginx &#125; #调用角色nginx，传递变量username=nginx - &#123; role: nginx, when: \"ansible_distribution_major_version == '7'\" &#125; #when条件判断 运行与测试12345678#测试，只检测可能发生的改变，不真正执行操作ansible-playbook --check#列出运行任务的主机ansible-playbook --list-hosts#语法检测ansible-playbook --syntax-check first.yaml#执行ansible-playbook all first.yaml 实例以role定义一个playbook。此处以配置nginx为例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#此时，nginx就是一个角色，即一个rolemkdir /etc/ansible/roles/nginx/&#123;tasks,vars,templates,handles,files,meta,default&#125; -pv#定义tasks，直接在tasks目录下新建main.yml文件，内容直接写-name即可，不需要指明tasks标签- name: install nginx yum: name=nginx state=installed when: ansible_os_family == \"RedHat\"- name: install conf template: src=vhost1.conf.j2 dest=/etc/nginx/conf.d/vhost1.conf tags: conf notify: restart nginx- name: start nginx service: name=nginx state=started- name: install site home directory file: path=&#123;&#123; ngxroot &#125;&#125; state=directory- name: install index page copy: src=index.html dest=&#123;&#123; ngxroot &#125;&#125;/#定义template文件，以.j2结尾，此处为vhost1.conf.j2server &#123; listen 80; server-name &#123;&#123; ansible_fqdn &#125;&#125;; location / &#123; root \"/ngxdata/vhost1\"; &#125;&#125;#定义handlers的main.yml文件- name: restart nginx service: name=nginx state=restarted#定义变量于vars/目录下的main.yml文件中，格式为字典格式ngxroot: /ngxdata/vhost1#定义index.html于files/目录下&lt;h1&gt;vhost1&lt;/h1&gt;#在playbook中直接定义roles标签指明即可，此处命名为nginx.yaml- hosts: all remote_user: root roles: - nginx#执行ansible-playbook all nginx.yaml","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"anxible","slug":"anxible","permalink":"http://yoursite.com/tags/anxible/"},{"name":"自动化","slug":"自动化","permalink":"http://yoursite.com/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}],"author":"Frdqy"},{"title":"dhcp、pxe、cobbler","slug":"hcp、pxe、cobbler","date":"2020-01-21T11:49:33.000Z","updated":"2020-01-22T12:13:39.358Z","comments":true,"path":"2020/01/21/hcp、pxe、cobbler/","link":"","permalink":"http://yoursite.com/2020/01/21/hcp%E3%80%81pxe%E3%80%81cobbler/","excerpt":"DHCP基于RARP协议实现动态申请IP地址。监听服务端的udp67，客户端的udp68。","text":"DHCP基于RARP协议实现动态申请IP地址。监听服务端的udp67，客户端的udp68。 工作流程 客户端：dhcp discover，广播报文，发送自己的MAC地址 服务端：dhcp offer，广播报文，提供本地地址池的空闲的IP地址、掩码、网关等 客户端：dhcp request，广播报文，对第一个到达的dhcp offer报文予以回答，申请使用 服务端：dhcp ack，广播报文，同意客户端使用该报文，并通知局域网内所有主机 续租dhcp获得的ip地址有时间限制，因此每当有效时间到达一半时都要进行续租操作。 续租成功 dhcp request dhcp ack 续租失败。失败后要继续广播discover发现报文请求新的IP地址。 dhcp request dhcp nak 配置文件/etc/dncp/dhcp.conf、/usr/share/doc/dhcp-4.2.5/dhcpd.conf.exampl 123456789101112131415161718192021222324252627282930313233#主机名option domain-name \"example\";#dns服务器地址option domain-name-servers ns1.example.org;#默认租约期限，单位为秒default-lease-time 43200;#最长租约期限，单位为秒max-lease-time 86400;#rsyslog相关的日志log-facility local7;#不同主机动态生成ip地址和网关等信息subnet 10.152.187.0 mask 255.255.255.0 &#123; #定义地址范围 range ip1~ip2; #定义默认网关 option routers 10.5.5.1; #定义广播域地址 option broadcast-address 10.5.5.31;&#125;#不同主机固定设置不同选项。hostname只用来区别不同主机，命名随意host host_name &#123; #指明主机的mac地址 hardware ethernet mac_addr; #固定所指明主机分配的ip地址，一般不为 fixed-address ip_addr; #指明当该主机请求dhcp时到server-name去加载filename指定的引导文件 filename \"pxelinux.0\"; server-name \"FQDN\"; #为tftp服务器地址 next-server 192.168.163.131;&#125;#注意若host和subnet同时生效那么以host为准(作用域越小越准确) 分配信息库/var/lib/dhcp/dhcpd.leases 常用命令12#监控dhcp过程dhclient -d PXEpreboot excution environment。主要依赖于dhcp、tftp、yum仓库实现。 流程首先根据dhcp服务器获取IP地址、掩码、网关等信息，然后根据dhcp所指向的next-server和filename连接指定tftp服务器；向tftp服务器加载bootloader、kernel、initrd等文件；然后向与内核相关yum仓库(ftp、http、nfs等)获取rpm包。最后根据kickstart文件实现自定义安装。 tftptftp用于被dhcp指向，它主要存储bootloader、kernel、initrd等信息。默认tftp服务器共享文件保存在/var/lib/tftpboot。此处使用192.168.163.131作tftp服务器。tftp默认工作在udp69端口 12#安装服务端和客户端，安装在地址为192.168.163.131的服务器上yum -y install tftp-server tftp dhcp修改/etc/dhcp/dhcpd.conf文件 123456789101112131415#网关指向安装tftp的服务器地址option routers 192.168.163.2;#指明dns服务器optino domain-name-servers 192.168.163.2;#默认租约期限，单位为秒default-lease-time 43200;#最长租约期限，单位为秒max-lease-time 86400;#指明网段地址和子网掩码subnet 192.168.163.0 netmask 255.255.255.0 &#123; range 192.168.163.100 192.168.163.200; filename \"pexlinux.0\"; #指向tftp服务器，且文件放在tftp服务器的/var/lib/tftpboot目录下 next-server 192.168.163.131;&#125; 配置yum仓库yum仓库主要用于安装时解决各种依赖问题。yum仓库可以使用ftp协议指向，也可以使用http协议指向。这里使用http协议，将yum仓库搭建在http服务器上，目录为/centos/7/x86_64/。 配置kickstart文件该文件用于自动配置装机流程，例如分区，装载网络文件系统等。此处复制一份本机的anaconda-ks.cfg文件即可，将其放在http服务器上(和yum仓库一起)的/var/www/html/kickstarts/目录下，其中要修改： 12#指向指定yum源url --url=\"http://192.168.163.131/centos/7/x86_64/\" 安装syslinuxsyslinux是一个小型的Linux操作系统，也可以看作是一个linux的引导器，可以简化安装Linux的过程。我们需要/usr/share/syslinux/目录下的几个文件来辅助安装linux。 1234567891011121314#安装yum install -y syslinux#需要copy的文件#PXE启动引导程序(NBP)prelinux.0#指定分区启动 如：chain.c32 hd0,1chain.c32#图像基础框架vesamenu.32#目录界面框架menu.c32#内存作为磁盘用(initrd)，用于引导IMG镜像的文件memdisk 准备文件需要复制如下文件到tftp服务器的/var/lib/tftpboot/下： 12345678910111213141516171819202122cp /usr/share/syslinux/&#123;chain.c32,mboot.c32,menu.c32,prelinux.0&#125; /var/lib/tftpboot/cp /boot/&#123;initramfs-3.10.0-1062.el7.x86_64.img,vmlinuz-3.10.0-1062.el7.x86_64&#125; /var/lib/tftpboot/mkdir prelinux.cfg#在prelinux.cfg目录下新建并编辑default文件，该文件为用户所看到的菜单选项#启动读取tftp服务器文件时会首先执行pxelinux.0这个文件#定义使用命令字符界面default menu.c32 #用户选择时间 prompt 5 #超时时间 timeout 30 #菜单项(全局菜单) MENU TITLE CentOS 7 PXE Menu #标签 LABEL linux #可选择的菜单项 MENU LABEL Install Centos7 x86_64 #指明内核 KERNEL vmlinuz-3.10.0-1062.el7.x86_64 #添加参数，其中安装源需要手动指定自己或者网上配置的repo，也要指定kickstart文件 #另外此处需要手动指定一个ip地址，虽然安装之前执行了dhcp，但那个ip是网卡的ip，对于内核来说还没有ip APPEND initrd=initramfs-3.10.0-1062.el7.x86_64.img ip=192.168.163.16 netmask=255.255.255.0 inst.repo=http://192.168.163.131/centos/7/x86_64 ks=http://192.168.163.131/kickstarts/centos7.cfg Cobblerpxe的二次封装。将多种系统的PXE安装通过软件结合起来，用户可以选择安装哪个。 架构 distribution(distro)：不同的发行版，包括内核、initrd等 profile：多个不同的kickstart配置文件 system：同一profile可以安装不同的系统(ip,掩码不同) 安装12345678910#安装cobbleryum -y install cobbler#安装dnsmasq，他是一个轻量化的dns和dhcp配置工具yum install -y dnsmasq#启动tftpsystemctl start tftp#启动httpdsystemctl start httpd#启动cobblerd服务systemctl start cobblerd 配置文件配置文件目录1234567891011/etc/cobbler/settings #cobbler主配置文件/etc/cobbler/dhcp.template #DHCP服务的配置模板/etc/cobbler/tftpd.template #tftp服务的配置模板/etc/cobbler/rsync.template #rsync服务的配置模板/etc/cobbler/iso #iso模板配置文件目录/etc/cobbler/pxe #pxe模板文件目录/etc/cobbler/power #电源的配置文件目录/etc/cobbler/users.conf #web服务授权配置文件/etc/cobbler/users.digest #web访问的用户名密码配置文件/etc/cobbler/dnsmasq.template #DNS服务的配置模板/etc/cobbler/modules.conf #Cobbler模块配置文件 数据目录1234567/var/lib/cobbler/config #配置文件/var/lib/cobbler/kickstarts #默认存放kickstart文件/var/lib/cobbler/loaders #存放的各种引导程序/var/www/cobbler #系统安装镜像目录/var/www/cobbler/ks_mirror #导入的系统镜像列表,cobbler distro文件目录/var/www/cobbler/images #导入的系统镜像启动文件/var/www/cobbler/repo_mirror #yum源存储目录 日志目录12/var/log/cobbler/install.log #客户端系统安装日志/var/log/cobbler/cobbler.log #cobbler日志 检查问题cobbler运行前需要检查各种配置文件。 1cobbler check 解决问题解决每个问题都需要重启服务来检测是否正确解决 123456789101112131415#设置server的值为本机可以连接外网的值，在/etc/cobbler/setting中server：192.168.163.131#指明pxe的IP地址，一般为tftp的地址next_server：192.168.163.131#在该/var/lib/cobbler/loaders目录下放引导文件，就是pxe的pxelinux.0，.32文件等；也可以联网下载#也可以像pxe一样从syslinux中复制过来cobbler get-loaders#安装rsync服务，主要用于同步各种rpm包yum install -y rsyncsystemctl start rsyncd#安装pykickstartyum -y install pykickstart#生成新的超级用户密码放在/etc/cobbler/setting文件中的default_password_crypted字段#将下列命令生成的密码放到default_password_crypted字段openssl passwd -1 -salt '123456' 'frdqy' 实例同步1cobbler sync 创建distro12345678910111213141516#用于定义发行版cobbler distro add [option] --kernel：内核 --initrd：ramdisk --arch：平台 --name：指定发行版名称#导入光盘文件自动生成distro，path指明挂载路径，生成distro文件默认保存在/var/www/cobbler/下#导入完成后会自动生成一个distro和profile文件，其中profile文件不能使用cobbler import --name=\"Centos7\" --path=/media/cdrom#生成后可以使用如下命令查看cobbler distro listcobbler profile list#查看distro或者profile配置信息cobbler profile report --name=Centos7 修改ks文件1234#kickstart文件默认保存在/var/lib/cobbler/kickstarts/sample_end.ks中#需要修改如下信息#指定repo仓库，是导入自动生成的url=\"http://192.168.163.131/cobbler/ks_mirror/centos7/\" 添加profile12#根据kickstart配置指定distro的profilecobbler profile add --name=Centos7 --distro=Centos7 --kickstart=/var/lib/cobbler/kickstarts/sample_end.ks 修改default123456789101112131415161718192021222324#登录界面默认设置保存在/var/lib/tftpboot/pxelinux.cfg/default文件下DEFAULT vesamenu.c32 PROMPT 0 MENU TITLE Cobbler | http://cobbler.github.io/ TIMEOUT 20 TOTALTIMEOUT 6000 ONTIMEOUT centos7-x86_64LABEL local MENU LABEL (local) MENU DEFAULT LOCALBOOT -1 LABEL centos7-Everything-x86_64 kernel /images/centos7-Everything-x86_64/vmlinuz MENU LABEL centos7-Everything-x86_64 append initrd=/images/centos7-Everything-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.163.131/cblr/svc/op/ks/profile/centos7-Everything-x86_64 ipappend 2 LABEL centos7-x86_64 kernel /images/centos7-x86_64/vmlinuz MENU LABEL centos7-x86_64 append initrd=/images/centos7-x86_64/initrd.img ksdevice=bootif lang= text net.ifnames=0 biosdevname=0 kssendmac ks=http://192.168.163.131/cblr/svc/op/ks/profile/centos7-x86_64 ipappend 2 MENU end","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"自动化","slug":"自动化","permalink":"http://yoursite.com/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"dhcp","slug":"dhcp","permalink":"http://yoursite.com/tags/dhcp/"},{"name":"pxe","slug":"pxe","permalink":"http://yoursite.com/tags/pxe/"},{"name":"cobbler","slug":"cobbler","permalink":"http://yoursite.com/tags/cobbler/"}],"author":"Frdqy"},{"title":"varnish详解","slug":"varnish详解","date":"2020-01-20T10:56:28.000Z","updated":"2020-01-20T11:01:12.048Z","comments":true,"path":"2020/01/20/varnish详解/","link":"","permalink":"http://yoursite.com/2020/01/20/varnish%E8%AF%A6%E8%A7%A3/","excerpt":"基本概念有效性机制过期时间 expires：定义过期的绝对时间 Cache-Control：maxage=number，表示缓存number秒时间，是相对时长 Cache-Control：s-maxage=number，同上","text":"基本概念有效性机制过期时间 expires：定义过期的绝对时间 Cache-Control：maxage=number，表示缓存number秒时间，是相对时长 Cache-Control：s-maxage=number，同上 条件式请求 Last-Modified/If-Modified-Since，不基于固定时间来缓存，而是每次缓存客户端向上级服务器请求该资源的时间戳，如果没有改变，上级服务器返回304响应码即可。 Etag/If-None-Match，基于文件内容的校验码机制，其余同上 通常将上述两种请求方式结合起来使用。第一次访问时客户端缓存在本地，同时设置过期时间，然后后续的请求都根据过期时间来判断是否需要向后端服务器请求。如果没有过期则直接本地缓存响应，如果过期了就使用条件式请求，如果服务器返回304则表示缓存仍未过期，此时重新设置过期时间；如果服务器返回200则表示缓存过期，同时将新的响应缓存下来，也同时设置过期时间。 缓存相关报文首部1234567891011#请求报文cache-request-directive： no-cache：不用缓存内容响应 #响应报文，由缓存服务器发送给客户端的报文cache-response-directive： public：公共缓存可缓存(私有也可以) private：仅私有缓存可缓存 no-cache：可缓存，但是响应给客户端之前要强制使用条件式请求判断 no-store：不能存储响应于缓存中 maxage：设置缓存相对时长 Varnish程序架构 主要由varnishd守护进程组成，它包含如下几个部分 Manager process进程，即管理进程 Cache process进程，包含多种类型的线程如accept、worker、expiry、log/stats、storage shared memory log，用于统计缓存命中数据和记录日志的进程，有相关进程varnishlog、varnishncsa、varnishstat等 配置接口：VCL，即定义管理缓存相关设置时需要通过vcl complier编译成c语言，然后把c编译成共享模块，以供Cache进程调用。 程序环境/etc/varnish/varnish.params：配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制 /etc/varnish/default.vcl：配置各Child/Cache线程的缓存工作策略 /usr/bin/varnishd：主程序 /usr/bin/varnishadm：命令行接口 /usr/bin/varnishhist等属于统计命中数据和记录日志的程序 /usr/bin/varnishtest：测试工具 /usr/sbin/varnish_reload_vcl：vcl配置文件重载程序 缓存机制varnish可以使用基于内存的缓存和磁盘文件缓存 malloc[,size]：缓存保存在内存中，指明内存大小 file[,path[,size]]：缓存保存在文件中，指明文件路径和大小 配置文件varnish自身启动的配置文件 1234567891011121314151617181920212223242526272829#/etc/varnish/varnish.params#启动服务时是否重载VCL配置文件RELOAD_VCL=1#默认VCL配置文件VARNISH_VCL_CONF=/etc/varnish/default.vcl#Varnish服务的监听端口，一般改为80VARNISH_LISTEN_PORT=80#定义远程管理端口和地址VARNISH_ADMIN_LISTEN_ADDRESS=127.0.0.1VARNISH_ADMIN_LISTEN_PORT=6082#上述管理接口远程连接时候需要的密钥文件(客户端和服务端必须一样才可以连接)VARNISH_SECRET_FILE=/etc/varnish/secret#使用缓存类型，此处为内存缓存，大小为256MVARNISH_STORAGE=\"malloc,256M\"#设置varnish进程的属主和属组VARNISH_USER=varnishVARNISH_GROUP=varnish#运行时修改的参数(和缓存相关的参数都支持运行时修改，否则重启会导致缓存失效)，此处定义的是线程池DAEMON_OPTS=\"-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300\" thread_pool：线程池数量(不超过cpu物理核心数) thread_pool_min：每个线程池的最小线程数 thread_pool_max：每个线程池的最大线程数 thread_pool_timeout：空闲进程被销毁的超时时长 thread_queue_limit：每个线程池的后援队列长度 thread_pool_add_delay：创建线程时的等待时间(一般为0) thread_pool_destroy_delay：销毁线程时的等待时间(防止突然有大量请求) thread_pool_fail_delay：创建线程失败时隔多久再重试 send_timeout：varnish发送给客户端的超时时长 timeout_idle：varnish与客户端保持连接时长 需要缓存的后端服务器相关配置 12345678910#/etc/varnish/default.vclbackend default &#123; #指明后端主机ip和端口 .host = \"ip_addr\"; .port = \"80\"; #设置连接超时时长 .connect_timeout = 0.5s #设置最大连接数 .max_connections = 50;&#125; varnishadm123456#通过定义在/etc/varnish/varnish.params的管理员ip和端口来进入命令行模式，需要指明密钥文件varnishadm -T 127.0.0.1:6082 -S /etc/varnish/secret vcl.load &lt;configname&gt; &lt;filename&gt;：将filename编译成配置文件configname vcl.use &lt;configname&gt;：使用configname配置文件 param.show &lt;param&gt;：显示指定参数 backend.list：列出反向代理的主机 VCL配置基本概念varnish的缓存管理策略。 vcl是“域”专有类型的配置语言(类似于iptables的hook)。所谓的“域”可以理解为：当用户请求达到缓存服务器时，缓存服务器会有很多的功能模块来对请求进行判断，比如是否需要缓存等；且每个模块都会指明该模块结束后下一个模块是什么，这些模块就叫做”域”，也叫做状态引擎。 VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此之间互相隔离；每个状态引擎可使用return(x)指明关联至哪一个下一级引擎；每个状态引擎对应vcl配置文件的一个配置段，以sub定义。 执行流程首先收到用户请求，在查本地缓存前先执行vcl_recv，可以执行一些预处理操作(很多规则在此处定义)。之后执行vcl_hash判断是否本地有缓存，此时有多种情况。如果缓存命中，则可以执行vcl_response，也可以执行vcl_pass到后端处理；如果缓存没命中，可以执行vcl_miss，然后可以直接后端处理或者调用vcl_pass后再到后端处理；如果不是可识别的协议，那么调用vcl_pipe直接传输给后端服务器进行响应。如果需要手动更改缓存项生效或者失效则使用vcl_purge之后会调用vcl_synth并构成响应报文执行vcl_deliver。 注意，有两个特殊的引擎： vcl_init：在所有请求处理之前都要执行的vcl代码；主要用于初始化VMODs vcl_finl：所有请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs 内置变量 req.*：引用由客户端发给varnish的请求报文首部。 req.http.Cookie：客户端的请求报文中Cookie的值 req.http.User-Agent：客户端浏览器信息 req.url：客户端请求的资源 bereq.*：引用由varnish发给后端服务器的请求报文的首部。 bereq.http.HEADERS(User-Agent、Referer等) bereq.request：请求方法 bereq.url：请求的资源 bereq.proto：请求的协议版本 bereq.backend：指明要调用的后端主机 beresp.*：引用由后端主机响应给varnish的响应报文的首部。 beresp.http.HEADERS(User-Agent、Referer等) beresp.status：响应的状态码 beresp.backend.name：后端服务器的主机名 beresp.ttl：后端服务器响应的内容跟的余下可缓存时长 resp.*：引用由varnish响应给client的响应报文的首部。 resp.proto：协议版本 obj.*：引用存储在缓存空间中的缓存对象的属性；只读。 obj.hits：此对象从缓存中命中的次数 obj.ttl：对象的ttl值 obj.grace：表示可以接受缓存过期多久，即过期在规定时间内仍然可用 server.*：指明后端服务器的ip主机名 server.ip server.hostname client.*：指明客户端的ip client.ip 变量定义域 缓存实例强制对某类资源请求不检查 1234567#定义在vcl_recv中#?i表示不区分大小写vcl_recv &#123; if (req.url ~ \"(?i)^/(login|admin)\")&#123; return(pass); &#125;&#125; 对于特定类型的资源，例如公共的图片，取消其私有标识，并强行设定其可以由varnish缓存的时长 12345678910#定义于fetch中vcl_fetch &#123; #判断是否是可公共缓存，一般有s-maxage标识则表示可公共缓存 if (beresp.http.Cache-Control !~ \"s-maxage\") &#123; if (bereq.url ~ \"(?i)\\.(jpg|png|gif|css|js|jpeg)$\") &#123; unset beresp.http.Set-Cookie; set beresp.ttl=3600s; &#125; &#125;&#125; 将真实的客户端ip传给后端服务器 12345678910#原则放在任何地方都行，但由于要传客户端ip地址，需要放在recv下vcl_recv &#123; if (req.restart == 0) &#123; if (req.http.X-Fowarded-For) &#123; set req.http.X-Forwarded-For = req.http.X-Forwarded-For + \",\" + client.ip; &#125; else &#123; set req.http.X-Forwarded-For = client.ip; &#125; &#125;&#125; purge实现缓存修剪 123456789101112131415161718#定义访问控制acl purgers &#123; #表示只允许下列规定的ip或网段执行purge \"127.0.0.1\"; \"192.168.0.0\"/24;&#125;#定义在recv中，且放在最前面vcl_recv &#123; if (req.method == \"PURGE\") &#123; if (!client.ip ~ purgers) &#123; return(synth(403,\"Purging not allowed for \" + client.ip)); &#125; return(purge); &#125;&#125;#使用curl的-X选项请求页面即可使其缓存失效，用-I查看curl -X PURGE http://192.168.163.131/index.htmlcurl -I PURGE http://192.168.163.131/index.html ban实现多文件缓存修剪 12345678910111213141516171819#定义访问控制acl baners &#123; #表示只允许下列规定的ip或网段执行ban \"127.0.0.1\"; \"192.168.0.0\"/24;&#125;#手动在varnishadm命令行下执行#禁止对所有.js结尾的文件的缓存ban req.url ~ .js$#定义在vcl_recv中if (req.method == \"BAN\") &#123; if (!client.ip ~ baners) &#123; return(synth(403,\"baning not allowed for \" + client.ip)); &#125; ban(\"req.http.host == \" + req.http.host + \"&amp;&amp; req.url == \" + req.url); return(synth(200,\"Ban added\"));&#125; 代理实例代理多台后端主机 12345678910111213141516171819202122232425262728#导入directors模块import directors;#定义多台主机backend one &#123; .host = \"localhost\"; .port = \"80\";&#125;backend two &#123; .host = \"192.168.163.131\"; .port = \"80\";&#125;#在vcl_init中初始化多个主机为一组sub vcl_init &#123; new varnish = directors.round_robin(); varnish.add_backend(one); varnish.add_backend(two); #可以基于权重定义 new varnish1 = directors.random(); varnish1.add_backend(one,10); varnish1.add_backend(two,5);&#125;#在vcl_recv中调用定义的组sub vcl_recv &#123; set req.backend hint = varnish.backend();&#125; 基于cookie绑定不同的主机 12345678910#以hash定义组sub vcl_init &#123; new h = directors.hash(); h.add_backend(one,1); h.add_backend(two,1);&#125;#hash键设定为客户端的cookiesub vcl_recv &#123; set req.backend_hint = h.backend(req.http.cookie);&#125; 健康检测实例1234567891011121314151617181920#定义probeprobe www_probe &#123; #用于健康检测的页面，默认为“/” .url = \"/index.html\"; #定义多久检测一次 .interval = 1s; #定义响应超时时长 .timeout = 1s; #定义检测几次 .window = 8; #在定义的检测次数中检测需要成功多少次，即8此探测中成功5次则说明健康 .threshold = 5; #期望得到的响应码，默认为200 .expected_response 200;&#125;#在backend中调用backend one &#123; ... .probe = www_probe;&#125; 日志varnishstat 1234567varnishstat -1：只显示1次 -l：列出可以显示的所有字段列表 -f filed：指定只显示哪个字段#常用字段MAIN.cache_hit：缓存命中次数MAIN.client_req：收到的客户端请求数 varnishtop 1234varnishtop -1：只显示一次 -i taglist：只显示有限个标签内容 -x taglist：排除有限个标签的内容","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"varnish","slug":"varnish","permalink":"http://yoursite.com/tags/varnish/"},{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"keepalived高可用集群","slug":"keepalived高可用集群","date":"2020-01-19T10:00:42.000Z","updated":"2020-01-20T11:12:35.690Z","comments":true,"path":"2020/01/19/keepalived高可用集群/","link":"","permalink":"http://yoursite.com/2020/01/19/keepalived%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/","excerpt":"概念keepalivedkeepalived是高可用集群，可以结合nginx和lvs实现如健康检测、为集群所有节点生成ipvs规则(在配置文件中预先定义)、基于脚本调用接口进行脚本执行等功能。另外，在结合vrrp协议后，通过定义虚拟路由，可以实现冗余负载均衡器的功能，从而解决负载均衡器的单点故障问题。","text":"概念keepalivedkeepalived是高可用集群，可以结合nginx和lvs实现如健康检测、为集群所有节点生成ipvs规则(在配置文件中预先定义)、基于脚本调用接口进行脚本执行等功能。另外，在结合vrrp协议后，通过定义虚拟路由，可以实现冗余负载均衡器的功能，从而解决负载均衡器的单点故障问题。 VRRP路由器使用VRRP功能后，会根据优先级确定自己在备份组中的角色。优先级高的路由器成为Master路由器，优先级低的成为Backup路由器。Master拥有对外服务的虚拟IP，提供各种网络功能，并定期发送VRRP报文(通过配置文件中指定的多播域发送)，通知备份组内的其他设备自己工作正常；Backup路由器只接收Master发来的报文信息，用来监控Master的运行状态。当Master失效时，Backup路由器进行选举，优先级高的Backup将成为新的Master。 在抢占方式下，当Backup路由器收到VRRP报文后，会将自己的优先级与报文中的优先级进行比较。如果大于通告报文中的优先级，则成为Master 路由器；否则将保持Backup状态。抢占后的路由会发送ARP请求自己的MAC地址并回答自己，由于ARP是广播类型，因此局域网内的所有主机都能收到新的路由的MAC地址，从而更新各自的信息。 在非抢占方式下，只要Master路由器没有出现故障，备份组中的路由器始终保持Master或Backup状态，Backup路由器即使随后被配置了更高的优先级也不会成为Master路由器。 如果Backup路由器的定时器超时后仍未收到Master路由器发送来的VRRP报文，则认为Master路由器已经无法正常工作，此时Backup路由器会认为自己是Master路由器，并对外发送VRRP报文。备份组内的路由器根据优先级选举出Master路由器，承担报文的转发功能。 架构 核心组件：vrrp stack、ipvs wrapper、checkers 控制组件：配置文件分析器 其他组件：IO复用器、内存管理组件 配置前提 各节点时间必须同步 确保iptables及selinux清空与关闭 各节点之间可通过主机名互相通信(使用/etc/host实现) 各节点之间的root用户可以基于密钥认证的ssh服务完成互相通信 配置额各节点支持multicast多播通信 1ip link set multicast on dev ens33 安装1yum -y install keepalived 配置文件主配置文件：/etc/keepalived/keepalived.conf 主程序文件：/usr/sbin/keepalived Unit File：keepalived.service Unit File环境配置文件：/etc/sysconfig/keepalived 组成部分 GLOBAL CONFIGURATION Global definitions static routes VRRPD CONFIGURATION VRRP synchronization group：vrrp同步组 VRRP instance：vrrp服务器 LVS CONFIGURATION Virtual server groups Virtual servers：ipvs集群的vs和rs 地址转换配置主要实现负载均衡器的冗余配置，一台挂了可以启动另一台(实现ip地址的转换)从而避免单点故障问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748! Configuration File for keepalivedglobal_defs &#123; #配置邮件提醒 notification_email &#123; root@localhost &#125; #邮件发件人 notification_email_from Alexandre.Cassen@firewall.loc #邮件服务器地址 smtp_server 127.0.0.1 smtp_connect_timeout 30 #定义虚拟主机名 router_id LVS_DEVEL #定义vrrp协议的多播地址，用于定义虚拟主机的广播域 vrrp_mcast_group4 224.0.100.33 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;#配置虚拟路由器vrrp_instance VI_1 &#123; #定义该虚拟主机是主(MASTER)还是备(BACKUP)，主只能有一个，其余都是备 state MASTER #定义网卡设备 interface eth0 #定义虚拟路由器唯一标识 virtual_router_id 51 #该虚拟主机优先级 priority 100 #vrrp通告间隔1s advert_int 1 #认证，同一组内认证要一样 authentication &#123; auth_type PASS auth_pass 1111 &#125; #定义虚拟主机ip，用于与外部通信。可以指明设备和网卡别名，不设置则默认设置为网卡的辅助地址 #IPADDR/MASK dev STRING label LABEL virtual_ipaddress &#123; 192.168.200.16 &#125; #定义工作模式为非抢占式 nopreempt #工作在抢占式，节点上线后出发新选举操作的延迟时长 preempt_delay 300&#125; lvs配置使用DR模型。Director地址为172.16.0.99，两个RS地址为172.16.0.6、172.16.0.7(各自还需要设置别名172.16.0.99) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#不需要使用ipvsadm生成规则，直接配置virtual_server字段即可virtual_server 172.16.0.99 80 &#123; #每隔几秒检测一次 delay_loop 1 #调度算法 lb_algo wrr #集群类型 lb_kind DR #协议 protocol TCP #错误页面服务器 sorry_server ip:port #定义RS read_server 172.16.0.6 80 &#123; #定义权重 weight 1 #定义健康检测方式 HTTP_GET &#123; #对指定url检测，根据path指定 url &#123; path / #只有响应码为200才正常 status_code 200 &#125; #重复检测几次 nb_get_retry 3 #重试前延迟多久 delay_before_retry 2 #连接超时时长 connect_timeout 3 &#125; &#125; read_server 172.16.0.7 80 &#123; #定义权重 weight 1 #定义健康检测方式 HTTP_GET &#123; #对指定url检测，根据path指定 url &#123; path / #只有响应码为200才正常 status_code 200 &#125; #重复检测几次 nb_get_retry 3 #重试前延迟多久 delay_before_retry 2 #连接超时时长 connect_timeout 3 &#125; &#125;&#125; 实例nginx和keepalived实现单主高可用故障转移。 使用三台虚拟主机模拟三个RS，其ip地址分别为192.168.10.11、192.168.10.12、192.168.10.13；两台主机模拟两个冗余nginx反带服务器，使用keepalived实现单点故障冗余以及RS健康检测。 后端3个RS运行httpd，用虚拟主机实现： 12345678910111213141516171819202122232425262728#/etc/httpd/conf.d目录下新建配置文件vhost.conf&lt;VirtualHost 192.168.10.11:80&gt; ServerName 192.168.10.11 DocumentRoot \"/data/web/vhost1\" &lt;Directory \"/data/web/vhost1\"&gt; Options FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.10.12:80&gt; ServerName 192.168.10.12 DocumentRoot \"/data/web/vhost2\" &lt;Directory \"/data/web/vhost1\"&gt; Options FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.10.13:80&gt; ServerName 192.168.10.13 DocumentRoot \"/data/web/vhost3\" &lt;Directory \"/data/web/vhost1\"&gt; Options FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 接着，为了使keepalived结合nginx，用于检测nginx服务是否挂了，如果挂了就开启nginx，如果开启不了nginx就降低优先级让另一台nginx来抢占即可。这里需要使用脚本来实现。 12345678910111213141516171819202122232425262728293031323334#脚本一般定义在实例之外，方便调用vrrp_script &lt;SCRIPT_NAME&gt; &#123; #脚本命令，脚本执行失败会执行下述命令 script \"\" #间隔多久检测 interval INT #失败了，即上述命令返回值为1时权重减少多少 weight -INT #失败多少此后降低优先级 fall INT #成功多少次后恢复优先级 rise INT&#125;#在vrrp_instance的track_script中根据脚本名调用脚本track_script &#123; SCRIPT_NAME&#125;#检测nginx是否正常工作的脚本vrrp_script chk_nginx &#123; #killall -0表示查看nginx是否可以杀死，但不动手，从而检测nginx是否在运行(可以杀死说明在运行) script \"killall -0 nginx &amp;&amp; exit 0 || exit 1\" interval 1 weight 5 fall 2 rise 1&#125;#根据/etc/keepalived/down文件是否存在来修改优先级，可以实现对某个主机下线做修复操作vrrp_script chk_down &#123; #如果文件存在就降低优先级 script \"[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0\" interval 1 weight -5&#125; 在两台nginx主机上配置nginx负载均衡。 123456789upstream websrvs &#123; server 192.168.10.11:80; server 192.168.10.12:80; server 192.168.10.13:80;&#125;#在server的location中定义location / &#123; proxy_pass http://websrvs;&#125; 编写通知脚本，实现keepalived状态发生变化时进行邮件通知以及启动nginx服务 123456789101112131415161718192021222324252627#!/bin/bash#contact='root@localhost'notify() &#123; local mailsubject=\"`hostname` to be $1, vip floating\" local maibody=\"`date +%F %T`: vrrp tansition, `hostname` changed to be $1\" echo \"$mailbody\" | mail -s \"$mailsubject\" $contact&#125;case $1 inmaster) systemctl start nginx notify master ;;backup) systemctl start nginx notify backup ;;fault) systemctl stop nginx notify fault ;;*) echo \"Usage: `basename $0` &#123;master|backup|fault&#125;\" exit 1 ;;esac 上述脚本定义在vrrp_instance中执行，当keepalived的状态改变时会执行对应的脚本 12notify_master &#39;&#x2F;etc&#x2F;keeplived&#x2F;notify.sh master&#39;notify_backup&#39;&#x2F;etc&#x2F;keeplived&#x2F;notify.sh backup&#39; 注意以上使用的是单主机的keepalived和nginx的调度，在整个调度中都会有一个主机处于空闲状态，浪费资源，因此可以使用双主调度。只需要再配置一个vrrp_instance即可，要注意两个主机唯一标识、认证以及优先级的设计，可以设计第一台的两个虚拟主机优先级一个是100，另一个是90；同理第二台主机分别是90和100(注意两台主机的100和对应的90是一组)，这样就可以实现没有空闲主机的情况，增加利用率。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://yoursite.com/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}],"author":"Frdqy"},{"title":"LVS四层负载均衡","slug":"LVS四层负载均衡","date":"2020-01-17T10:12:13.000Z","updated":"2020-01-17T10:12:57.112Z","comments":true,"path":"2020/01/17/LVS四层负载均衡/","link":"","permalink":"http://yoursite.com/2020/01/17/LVS%E5%9B%9B%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"概念Cluster：计算机集合，为解决某个特定问题组合起来形成的单个系统","text":"概念Cluster：计算机集合，为解决某个特定问题组合起来形成的单个系统 系统扩展方式Scale UP：向上扩展，即增加单个服务器容量 Scale OUT：向外扩展，即增加服务器数量(Cluster) 会话保持由于使用负载均衡后，用户的请求会被负载均衡器分配到不同的后端服务器中，那么如何记录用户的会话身份就显得很重要。主要有如下三种方式： session sticky：每个用户绑定固定的后端服务器，可以根据源ip或者cookie来绑定 session replication：即将每个后端主机的session信息互相同步 session server：采用一个固定的session服务器专门保存会话信息 Linux Cluster类型LB：Load Balanceing，负载均衡 HA：High Availability，高可用；A=MTBF/(MTBF+MTTR)。(平均无故障时间)/(平均无故障时间+平均修复时间) HP：High performance，高性能 分布式存储：类似于集群概念。将客户端请求通过一个服务器分发给多个服务器，其中起分发功能的服务器叫做元数据服务器，它保存各个数据在数据服务器的位置，即只存储数据的元信息。数据服务器负责真正存储数据，且为了安全一份数据通常在两个不同的数据服务器之间做冗余。另外，如果用户请求一个大文件，且请求量很大，可以将该大文件切片并放在不同的数据服务器上，一次发给用户即可。该结构模型类似文件系统模型。 分布式计算：将一个单一大问题分隔成数个小问题来解决。例如处理100亿条日志，需要提取访问量前10的日志信息，则可以根据服务器数量，将总体分隔成多个部分进行分开计算，再整合，再计算，这就叫分布式计算。 硬件F5的Big-ip；Citrix的Netscaler；A10的A10 软件传输层(DPORT)： lvs(Linux Virtual Server) nginx(stream模块) haproxy(mode tcp) 应用层(自定义请求模型)： http：nginx、httpd、haproxy fastcgi：nginx、httpd LVSLinux virtual server 术语它是工作在传输层的内核软件，也叫四层路由器。它根据请求报文的目标IP和目标协议及端口将其转发至某RealServer(RS)，根据调度算法来挑选RS。 VS：虚拟主机也叫Director，即用于调度分发客户端请求的服务器，也叫负载均衡器 RS：真实服务器，即用于处理客户端请求的服务器 ipvsadm：lvs的用户空间命令行工具，规则管理工具，用于管理集群服务及RS ipvs：lvs工作于内核空间的INPUT上的一个框架 CIP：客户端的IP VIP：VS用于响应客户端请求的IP DIP：VS用于响应RS的IP RIP：RS的IP 类型lvs-nat修改请求报文的目标IP和端口，适用于多目标的DNAT RIP和DIP必须处于同一IP网络，且应该使用私网地址；RS网关指向DIP 请求报文和响应报文都必须经由Director转发；Director可能成为系统瓶颈 支持端口映射，可修改请求报文的目标PORT VS即Director必须是Linux系统，RS可以是任何系统 lvs-dr不修改IP和端口，而修改MAC地址。即为请求报文重新生成一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是挑出的RS的RIP所在接口的MAC地址。 确保前端路由器将目标IP为VIP的请求报文发往Director 法一：在前端网关做静态绑定，但不灵活。 法二：在RS上使用arptables做MAC访问控制 法三：在RS上修改内核参数以限制arp通告及应答级别(arp_announce、arp_ignore) arp_announce：默认0，表示在接入网络时把本机所有接口的所有信息向每个接口上的网络进行通告；1表示尽量避免向非直连网络进行通告；2表示避免向非本网络通告。 arp_ignore：默认0，表示可使用本地任意接口上配置的任意地址进行响应；1表示尽在请求的目标ip配置在本地主机的接收请求报文的接口上时才给予响应。 RS的RIP可以使用私网地址，也可使用公网地址；RIP与DIP在同一IP网络；RIP网关不能指向DIP，以确保响应报文不经由Director RS跟Director在同一物理网络(同一交换机，不能隔路由器) 请求报文要经由Director，但响应报文不能经由Director，而是经由RS直接发往client 不支持端口映射 lvs-tun隧道概念，不修改请求报文的IP首部(源IP为CIP，目标IP为VIP)，而是在原有请求的IP报文之外新加一个IP首部(源IP为DIP，目标IP为RIP)，之后将报文发往挑选出的RS，最后RS直接响应给客户端(源IP为VIP，目标IP为CIP)。但会引起超出MTU的问题。 DIP、VIP、RIP都是公网地址 RS的网关不能指向DIP 请求报文要经由Director，但响应报文不能经由Director 不支持端口映射 RS的OS得支持隧道功能 lvs-fullnat不同于nat，它修改目标IP和源IP(CIP修改为DIP，VIP修改为RIP) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关不会指向DIP RS收到的请求报文源IP是DIP，因此只需响应给DIP；但Director还要将其发往Client 请求和响应报文都经由Director 支持端口映射 此模型默认不支持 总结lvs-nat、lvs-fullnat的请求都经过Director，区别在于nat模型中，RIP的网关要指向DIP；而fullnat的RIP和DIP未必在同一IP网络，但他们要能通信。且nat进修改请求报文的目标ip，而fullnat修改请求报文的源ip和目标ip。 lvs-dr、lvs-tun的请求报文都经过Director，响应报文都由RS直接发往Client。区别在于dr模型通过封装新的MAC首部实现，通过MAC转发；而tun模型通过在原有的IP报文之外再封装新的IP实现转发，支持远距离通信。 调度方法根据调度时是否考虑各RS当前的负载状态，可分为静态方法和动态方法两种。 静态方法仅根据算法本身进行调度。 RR：roundrobin，轮询 WRR：weighted RR，加权轮询，即将RS虚拟出多个，把个数作为权重 SH：Source Hashing，实现session sticky，源ip地址hash；在Director内存中维护一张hash表，客户端IP和RS的IP一一对应。(第一次请求时使用WRR并记录源地址hash和对应RS的IP)。缺点是当RS挂掉时对应的客户端的session也会丢失。 DH：Destination Hashing，目标地址hash，将发往同一个目标地址的请求始终转发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡。 动态方法主要根据每个RS当前的负载状态进行调度，负载一样再考虑算法本身。负载值(overhead) LC：least connection，最少连接 overhead=activeconns*256+inactiveconns WLC：weighted LC，加权最少连接 overhead=(activeconns*256+inactiveconns)/weight SED：shortest Expection Delay，最短期望延迟 overhead=(activeconns+1)*256/weight NQ：Never Queue LBLC：Locality-Based LC，动态DH算法 LBLCR：LBLC with Replication，带复制功能的LBLC 安装12#在Director安装yum install ipvsadm -y 管理集群123456789#增、改ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]]#删ipvsadm -D -t|u|f service-address service-address： -t：TCP协议端口，VIP:TCP_PORT -u：UDP协议端口，VIP:UDP_PORT -f：firewall MARK，是一个数字 [-s scheduler]：指定集群调度算法，默认为WLC 管理集群的RS123456789#增、改ipvsadm -a|e -t|u|f service-address [-g|i|m] [-w weight]#删ipvsadm -d -t|u|f service-address -r server-address server-address： rip[:port] -g：gateway，dr类型 -i：ipip，tun类型 -m：masquerade，nat类型 删除和查看12345678910111213141516171819#删除ipvsadm -C#查看ipvsadm -L|l [options] --numeric,-n：数字格式ip地址和端口 --exact；精确显示 --connection,-c：查看具体连接信息，即哪些请求被转发到哪些RS --stats：统计数据 conns：连接数 InPkts：入栈报文数量 OutPkts：出栈报文数量 InBytes：入栈字节数 OutBytes：出栈字节数 --rate：速率数据 CPS：每秒建立的连接数 InPPS：每秒入栈报文数 OutPPS：每秒出栈报文数 InBPS：每秒入栈字节数 OutBPS：每秒出栈字节数 保存和重载123456#保存ipvsadm -S &gt; /etc/sysconfig/ipvsadmipvsadm-save &gt; /etc/sysconfig/ipvsadm#重载ipvsadm -R &lt; /etc/sysconfig/ipvsadmipvsadm-restore &lt; /etc/sysconfig/ipvsadm 实例NAT集群使用nat模型实现集群。一台Director(两块网卡，一个VIP，一个DIP)，两台RS。 首先配置RS1、RS2，他们ip地址分别为192.168.163.11、192.168.163.12，网关地址为192.168.163.254，该网关地址也是Director的DIP。Director的VIP为一个外网地址(注意Director必须开启核心转发功能)。由此外网主机就可以通过Director的VIP地址访问两台RS. 12345678910111213141516#创建集群ipvsadm -A -t VIP_address:port -s rr#创建集群上的ruleipvsadm -a -t VIP_address:port -r 192.168.163.11 -mipvsadm -a -t VIP_address:port -r 192.168.163.12 -m#修改集群调度算法为wrr(加权rr)ipvsadm -E -t VIP_address:port -s wrr#修改rule权重ipvsadm -e -t VIP_address:port -r 192.168.163.11 -m -w 2ipvsadm -e -t VIP_address:port -r 192.168.163.12 -m -w 3#删除一条ruleipvsadm -d -t VIP_address:port -r 192.168.163.1#注意，port根据具体服务选择，比如web服务一般是80端口，telnet就设置23端口即可。不同的端口相互隔离。 DR集群使用dr模型实现集群。一台Director(一块网卡，只要VIP)，两台RS。RS和Director在同一网段(网关一样)。 Directory地址设置为172.16.0.99(VIP)，不需要DIP地址。 两台RS地址设置分别为172.168.0.7(RIP)、172.168.0.8(RIP) 1234567891011121314151617181920212223#设置内核参数，/proc/sys/net/ipv4/conf/echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce#设置RS的另一个ip地址，设置在lo的别名上ifconfig lo:0 172.16.0.99 netmask 255.255.255.255 broadcast 172.16.0.99 up#设置RS的路由条目#因为需要由RS直接将结果反回给Client，所以设置路由条目，将目的ip为VIP的全部转发经由lo:0来转发，这样发送给Clent的源ip就是VIP，与用户请求的目的IP一样route add -host 172.168.0.99 dev lo:0#设置Director的ip别名#因为我们设置的VIP是172.16.0.99，即外网Client通过VIP访问，我们需要在与外界通信的物理网卡上配置别名，ip地址改为VIP。#此处broadcast只是将本网段的广播全都转发给172.16.0.99，正常的ARP仍可以响应ifconfig ens33:0 172.16.0.99 netmask 255.255.255.255 broadcast 172.16.0.99 up#Director添加集群ipvsadm -A -t 172.168.0.99:80 -s rr#创建集群上的ruleipvsadm -a -t 172.168.0.99:80 -r 172.168.0.7 -mipvsadm -a -t 172.168.0.99:80 -r 172.168.0.8 -m 防火墙标记使用iptables在请求进入Director的Prerouting时加不同的防火墙标记，当请求经由input链时按照lvs根据防火墙标记设计的规则就可以实现对不同的端口的访问全部绑定一起进行调度。 1234567#将80和443端口进行iptables打包iptables -t mangle -A PREROUTING -d 172.16.0.99 -p tcp -m multiport --dports 80,443 -j MARK --set-mark 3#根据mark添加集群ipvsadm -A -f 3 -s rr#添加RSipvsadm -a -f 3 -r 172.16.0.7 -gipvsadm -a -f 3 -r 172.16.0.8 -g 会话保持使用ipvsadm的-p选项实现调度算法之上的会话绑定。即客户端第一次访问时仍然按照选定的算法来调度，但是同一客户端之后的访问都会被绑定到第一次调度的主机上。 12#在上面基础上修改集群，默认360sipvsadm -E -f 3 -s rr -p 全端口绑定1234#端口设0表示全端口转发，且此时必须设置-p选项ipvsadm -A -t 172.16.0.99:0 -s rr -pipvsadm -a -t 172.16.0.99:0 -r 172.16.0.7 -gipvsadm -a -t 172.16.0.99:0 -r 172.16.0.8 -g 存在问题 Director存在单点故障问题(SPoF)，解决方法使用高可用集群实现。 keepalived，它既可以冗余Director也可以检测RS的生命状态 heartbeat/corosync 某RS不可用，Director仍然会调度请求该RS，可以通过网络层(ping)、传输层(端口探测)、应用层检测(请求某关键资源) keeplived ldirectord Idirectord工作在Director主机上，对后端主机进行健康检测并修改Director的规则。启用ldirectord后，会根据配置文件需要检测的RS自动添加Director的规则条目，对无法访问的将自动删除。 由于ldirectord不在官方仓库和epel仓库中，因此要使用rpm安装。 配置文件1234567891011121314151617181920212223242526#超时时长checktimeout=time#每隔多久检测一次checkinterval=time#所有RS全挂使用什么来处理请求fallback=127.0.0.1:80#是否自动重载配置文件autoreload=yes#日志文件logfile=\"\"#通知邮箱emailalert=\"\"#通知频率emailalertfreq=\"\"#定义VIP，也可以根据防火墙标签定义virtual VIP_ADDRESS:PORT #定义RIP read=RIP:PORT gate(dr模型) #指明该集群应用层协议 service=http #指明检测主页 request=\"index.html\" #请求主页包含关键字 receive=\"Test Page\" #向指定虚拟主机发送请求 virtualhost=www.x.y.z","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"lvs","slug":"lvs","permalink":"http://yoursite.com/tags/lvs/"},{"name":"负载均衡","slug":"负载均衡","permalink":"http://yoursite.com/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"}],"author":"Frdqy"},{"title":"nginx详解","slug":"nginx详解","date":"2020-01-15T11:16:04.000Z","updated":"2020-01-20T11:07:36.234Z","comments":true,"path":"2020/01/15/nginx详解/","link":"","permalink":"http://yoursite.com/2020/01/15/nginx%E8%AF%A6%E8%A7%A3/","excerpt":"事件驱动模型事件驱动指当用户进程发起磁盘io时，该进程告诉内核一个回调接口，即内核加载磁盘数据到内核空间后会通知发起该动作的进程。随后，进程接收到回调信号后，参与数据从内核空间到进程空间的过程。在Linux中，事件驱动的系统调用叫做epoll，由libevent包提供。","text":"事件驱动模型事件驱动指当用户进程发起磁盘io时，该进程告诉内核一个回调接口，即内核加载磁盘数据到内核空间后会通知发起该动作的进程。随后，进程接收到回调信号后，参与数据从内核空间到进程空间的过程。在Linux中，事件驱动的系统调用叫做epoll，由libevent包提供。 程序架构 nginx基于master-worker模型，即一个主控进程master生成多个子进程worker来处理用户请求。其中master负责加载和分析配置文件、管理worker进程和平滑升级。 特性异步、事件驱动、非阻塞 并发请求：epoll 文件io：sendfile，mmap 模块化：支持动态装载和卸载，包括core module、http modules、mail modules和stream modules(传输层代理，即4层代理) 功能 静态web服务器资源 结合FastCGI协议实现反代动态资源请求 http/https协议的反向代理 imap4/pop3协议的反向代理 tcp/udp的反向代理 环境主程序文件：/usr/sbin/nginx unit file：nginx.service 配置文件：/etc/nginx/nginx.conf、/etc/nginx/conf.d/*.conf、fastcgi、mimetypes等 安装123yum install epel-release -yyum makecacheyum install nginx -y 配置文件123#修改配置文件后使用如下命令检查和重载配置文件nginx -tnginx -s reload 运行必备12345678#可以用用户名，也可用组名user user [group];#指定nginx进程路径pid /path;#指明包含其他配置文件路径include file | mask;#指明动态装载的模块load_module file; 性能优化12345678#worker进程数量，通常小于等于cpu的物理核心数worker_process number | auto;#将cpu与nginx进程绑定，主要用于专机专用worker_cpu_affinity cpumask | auto;#指定worker进程的nice值[-20,19]worker_priority number;#所有的worker进程所能打开的文件数量上限worker_rlimit_nofile 调试相关123456#是否以守护进程的方式运行nginx，通常设置在centos6上，因为7已经编程systemd管理daemon on | off;#是否以master/worker模型运行nginx；默认为onmaster_process on | off;#错误日志路径和日志级别，自我管理，不使用rsyslogerror_log file [level]; 事件驱动1234567放在events段中#每个worker进程能够打开的最大进程并发数worker_connections number;#指明并发连接请求的处理方法use method;#处理连接请求的方法；on表示各worker轮流处理，off表示各个请求到达会通知所有workeraccept_mutex on | off; http相关套接字配置123456789101112131415161718192021222324#配置虚拟主机server&#123; listen address[:port]|port; default_server：设定为默认主机 ssl：限制只能通过ssl连接提供服务，即通过https backlog=number：后援队列长度 rcvbuf=size：接收缓冲区大小 sndbuf=size：发送缓冲区大小 server_name SERVER_NAME; 指明虚拟主机的名称，可以跟多个由空白字符分隔的字符串 支持*通配任意字符长度、支持~起始的字符做正则表达式模式匹配 匹配机制：首先是字符串精确匹配，然后是左侧匹配，然后是右侧匹配，最后是正则匹配 #设置root就说明是正向服务器 root /path; #设置proxy_pass说明是反向代理服务器，此时root无效 proxy_pass http://ip;&#125;#在keep_alive模式下是否启用nodelay选项，用于处理用户请求资源过小时是否组合多个资源发送tcp_nodelay on | off;#在sendfile模式下是否启用nopush选项。用于一次性将整个file(包括头部)放在一个packet中发送过去。tcp_nopush on | off;#动态资源是否直接在内存空间发送而不经过用户空间sendfile on | off; 路径配置12345678910111213141516171819202122232425#设置web路径映射，用于指定本地文件系统上的资源路径；可以用在http、server、location、if in locationroot#根据不同的url进行更详细的设置。nginx会根据用户请求的url来检查定义的所有location，并找出最佳匹配应用。location [ = | ~ | ~* |^~ ] url &#123;...&#125; =：对url精确匹配 ~：对url正则匹配，区分字符大小写 ~*：对url正则匹配，不区分字符大小写 ^~：对url左半部分做匹配检查，不区分字符大小写 不带符号：匹配起始于此url的所有url 优先级：=、^~、~、~/~*、不带符号#定义路径别名，仅用于locationalias path;#注意location中使用root指令和alias指令的意义不同，root给定的路径相当于location中url左侧的/；而alias相当于右侧/。#设置默认资源，定义于http、server、locationindex file...;#自定义特定错误码的错误页error_page code... [=[response]] url;#try_files file... url; 客户端请求配置12345678910111213141516#设定保持连接的超时时长，0表示禁止长连接，默认为75skeepalive_timeout time;#一次长连接上所允许请求的最大资源数，默认为100keepalive_requests number;#对哪种浏览器禁用长连接keepalive_disable none | browser...;#向客户端发送响应报文的超时时长，当客户端突然断线时，服务器会重复写，这就是两次重复写的间隔时长send_timeout time#用于接收客户端请求报文的body部分的缓冲区大小；默认为16k，超出此大小时将其暂存到client_body_temp_path指令所定义的位置client_body_buffer_size size;#设定用于存储客户端请求报文的body部分的临时存储路径及其子目录结构和数量client_body_temp_path [level1 [level2 [level3]]]; client_body_temp_path path /var/tmp/client_body 2 1 1 1：表示用一位16进制数表示一级子目录 2：表示用2位16进制文件表示二级子目录 2：表示用2位16进制文件表示三级子目录 客户端限制配置1234#限制响应给客户端的传输速率，0表示无限制，单位bytes/secondlimit_rate rate;#限制对指定的请求方法之外的其他方法limit_except method...&#123;...&#125; 文件操作优化1234567891011121314#是否启用异步io功能aio on | off | threads[=pool];#是否启用O_DIRECT标记directio size | off;#是否打开nginx缓存功能，可以缓存文件描述符、文件大小、最后一次修改时间、打开的目录结构、没有找到或者没有权限访问的文件的相关信息open_file_cache off | max=N [inactive=time]; max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现缓存管理 inactive=time：缓存项的非活动时长，小于此处时间未被命中或者命中次数少于open_file_cache_min_use指定的次数的缓存项即为非活动项。#缓存有效性检查频率，默认60sopen_file_cache_valid time;#在open_file_cache指令的inactive指定时长内，至少被命中多少次的可以被归为活动项open_file_cache_min_uses number;#是否缓存查找时发生错误的文件信息open_file_cache_errors on | off; 重要模块访问控制模块123456789101112131415#实现基于ip的访问控制ngx_http_access_module allow address | CIDR | unix | all; deny address | CIDR | unix | all;#实现基于用户的访问控制，使用basic机制进行用户认证ngx_http_auth_basic_module模块 auth_basic string | off; auth_basic_user_file file; location /admin/ &#123; alias /webapps/app1/data; auth_basic \"Admin Area\"; auth_basic_user_file /etc/nginx/.ngxpasswd; #密码使用htpasswd命令实现 &#125; 状态输出模块123456789101112131415161718#用于输出nginx的基本状态信息ngx_http_stub_status_module location /basic_status&#123; stub_satus; &#125; #用于输出日志ngx_http_log_module log_format name string... access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; #可以在location中设置不记录指定页面的日志 access_log off; open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; max：缓存的最大文件描述符数量 min_uses：在inactive指定的时长内访问大于等于此值被当作活动想 inactive：非活动时长 valid：验证是否为活动项的时间间隔 压缩模块12345678910111213141516#gzip压缩ngx_http_gzip_module gzip on | off; #压缩比 gzip_comp_level level; #哪些浏览器不压缩，需要禁止 gzip_disable regex...; #允许压缩的最小长度 gzip_min_length length; #支持实现压缩功能时为其配置的缓冲区数量和每个缓冲区的大小 gzip_buffers number size; #作为代理服务器接收到被代理服务器的响应报文时，在何种条件下启用压缩功能 gzip_proxied off | expired | no-cache | no-store off：不启用 #压缩过滤器，只对指定mime压缩 gzip_types mime-type; https模块123456789101112131415#https配置，只能配置在一个ip上，监听tcp/443端口ngx_http_ssl_module ssl on | off; #当前虚拟主机使用的PEM格式证书 ssl_certificate file; #当前主机上与其证书相匹配的私钥 ssl_certificate_key file; #ssl协议版本 ssl_protocols [TLSv1.2]; #ssl会话缓存 ssl_session_cache off | nono | [builtin[:size]] [shared:name:size]; builtin[:size]：使用openssl内建的缓存，此缓存为每worker进程私有 [shared:name:size]：在各worker之间使用一个共享的缓存 #客户端一侧连接可以服用ssl cache中缓存的ssl有效时长 ssl_session_timeout time; rewrite模块123456789101112131415161718192021222324252627282930313233#rewrite模块，主要是对请求的url进行替换ngx_http_rewrite_module#将客户端请求根据regex匹配后进行修改/重定向rewrite regex replacement [flag] flag： last：在服务器端实现，匹配修改后再从头开始匹配所有的rewrite break：在服务器端实现，匹配修改后直接跳到rewrite后开始执行 redirect：在客户端实现，服务器收到请求后匹配到将修改后的url发给客户端的浏览器，由其再次访问，返回的是302状态码 permanent：同上，但是返回的是301状态码 #举例 #将对png的请求全部换为jpg请求 rewrite /(.*)\\.png$ /$1.jpg #所有请求改成https请求 rewrite /(.*)$ https://www.dqy.io/$1#不处理，直接返回状态码或URL给客户端return code [text];return code URL;return URL;#是否将重写记录日志中rewrite_log on | off;#引入一个新的配置，条件满足时执行，server、location中定义if(condition)&#123;...&#125; 比较操作符： == != ~：正则匹配，区分大小写 ~*：不区分大小写的正则匹配 !~：不匹配，区分大小写 !~*：不匹配，不区分大小写 -e,!-e：文件是否存在 -f,!-f：是否是文件 -d,!-d：是否是目录 -x,!-x：是否可执行 引用模块12345678910111213#引用相关模块，可以防盗链ngx_http_referer_module valid_referers none | blocked | server_name | string... none：请求报文没有首部 blocked：请求报文的referer首部没有值，可能别防火墙删除 server_names：可以指定主机名 arbitrary_string：直接字符串，可以使用*通配 regular expression：正则表达式匹配，使用~开头 #举例 valid_referers none block server_names *.dqy.com *.frdqy.com ~\\.dqy\\.; if($invalid_referer)&#123; return 403; &#125; proxy模块123456789101112131415161718192021222324252627282930313233343536373839404142434445#proxy_pass URLserver &#123; ... server_name HOSTNAME; location /url&#123; #此处路径不带url，即指明ip地址和端口后不加额外的路径符号时，将location的url附加在路径后 proxy_pass http://host[:port]; #此处指明了URL，那么会将下面的url替换为location的url porxy_pass http://host[:port]/url &#125; #若location的url是正则匹配或者在if语句中使用proxy，那么proxy不能指定到具体的url&#125;#proxy_set_header field value设定发往后端主机的请求报文的请求首部的值，可以实现将客户端真正IP作为首部值发给后端服务器proxy_set_header X-Real-IP $remote_addr;#上下实现同样功能，通常使用下文的方式proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for#缓存相关#定义缓存路径proxy_cache_path /data/nginx/cache levels=1:1:1 keys_zone=pcache:10m max_size=2g levels：子目录分层，\"1代表一个子目录\" keys_zone：定义缓冲区名称 max_size：定义缓冲区大小#在server中调用缓存server &#123; ... #指明使用的缓冲区名称 proxy_cache pcache; #指明请求的哪些当作hash的键 proxy_cache_key $request_uri; #指明对哪些请求方法进行缓存 proxy_cache_methods GET HEAD; #指明缓存内容在规定时间内(默认10min)被访问多少次不会被剔除缓存 proxy_cache_min_uses 1; #指定状态码的网页缓存多少时间 proxy_cache_valid 200 302 10m;&#125;#定义连接超时时长，默认60s，最长75sproxy_connect_timeout time;#定义从后端服务器传送数据到代理服务器的超时时长proxy_read_timeout time;#代理服务器向后端服务器发请求的超时时长(后端太忙不回应)proxy_send_timeout time; fastcgi模块12345678910#主要用于fastcgi协议的反代，和proxy相似fastcgi_pass ip:port;#指明默认主页fastcgi_index index.php;#指明nginx反带给后端服务器的参数，其中SCRIPT_FILENAME要指明后端的Docunmentroot地址，使得url能够拼在路径后找到真正的资源位置fastcgi_param SCRIPT_FILENAME /date/apps/$fastcgi_script_name;include fastcgi_params;#缓存内容与proxy相似，只是名字换成fastcgi#保持连接，默认nginx反带fpm服务器后会自动断开fastcgi_keep_conn on | off; upstream模块12345678910111213141516171819202122232425262728293031#用于定义一组服务器，即将多个相同功能的服务器定义成一个组，从而实现负载均衡。#定义在http上下文中#不加weight默认为1，为轮询，修改后自动为加权轮询upstream websrvs &#123; server 192.168.10.11:80 weight=2; server 192.168.10.12:80;&#125;#在server中的location中定义，其中反代时使用定义的upstream定义的名称location / &#123; proxy_pass http://websrvs&#125;server参数： #最大失败次数，为0不检测 max_fails=number; #多长时间后端主机不响应认为后端主机挂了 fail_timeout=time; #最大并发连接数 max_conns=number; #后端服务器全挂后使用backup标记的server响应 backup; #将某台服务器停止，用于灰度发布(更新) down; #基于用户ip地址绑定后端服务器，类似于lvs的SH算法 ip_hash; #同上 hash $remote; #将客户端请求的url当作键来绑定某个后端服务器 hash $request_uri#注意，这里hash算法可以采用一致性hash算法，即hash key [consistent]。首先根据权重将后端主机分为多个虚拟主机，然后用后端虚拟主机的ip对2^32取模，结果将会是后端主机分散在一个圆上(0~2^32-1)。然后将请求的url的hash值对2^32取模，这样它也会落在之前的圆上，然后顺时针取离其取模值最近的一台虚拟主机进行处理，这就是一致性hash算法。#指明nginx的每个worker保持多少个连接keepalive 32;","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://yoursite.com/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}],"author":"Frdqy"},{"title":"时间、日志、sudo","slug":"时间、日志、sudo","date":"2020-01-14T08:49:00.000Z","updated":"2020-01-14T08:49:54.899Z","comments":true,"path":"2020/01/14/时间、日志、sudo/","link":"","permalink":"http://yoursite.com/2020/01/14/%E6%97%B6%E9%97%B4%E3%80%81%E6%97%A5%E5%BF%97%E3%80%81sudo/","excerpt":"时间管理chronyc是基于NTP(网络时间协议)的实现。","text":"时间管理chronyc是基于NTP(网络时间协议)的实现。 配置文件：/etc/chrony.conf 12345678#设置本机为时间服务器，允许某网段主机同步allow 192.168.0.0/16#设置本机向谁同步时间，server和iburst为关键字server 0.centos.pool.ntp.org iburst#日志文件logdir /var/log/chrony#自身作为ntp服务器时，即使自己没有同步到网络ntp服务器，也向请求的客户端同步时间local stratum 10 chronyc命令 123chronyc sources：查看ntp服务 activity：查看ntp服务是否在线 日志管理rsyslog支持C/S架构，也支持单机运行。 配置文件：/etc/rsyslog.conf，/etc/rsyslog.d/*.conf 12345678910111213141516#rsyslog.conf格式主要由MODULES、GLOBAL、RULES组成MODULES：管理模块加载 $ModLoad imudp：udp输入模块，用于配置成日志服务器 $UDPServerRun port：指明开启哪个端口接收输入 $ModLoad imtcp：tcp输入模块，用于配置成日志服务器 $UDPServerRun port：指明开启哪个端口接收输入 RULES：日志规则，用于指定哪个设施(facility)的什么级别(priority)的日志记录在哪(target) facility.priority targettarget： 文件：将日志记录于指定文件中。通常位于/var/log目录下，\"-\"表示异步写入 用户：将日志通知指定用户，即发送给指定用户的终端 日志服务器：@host，把日志送往指定的服务器地址 host：日志服务器地址，监听在tcp或udp协议的514端口 管道：通过管道传送给其他进程 facility设施，从功能或程序上对日志收集进行分类，常见的分类有如下几个： auth、authpriv、cron、daemon、kern、lpr、mail、mark、news、security、user、loacl0-7，syslog等 priority日志级别。主要要分为(从左-&gt;右级别一次提高)： debug、info、notice、warn、err、crit、alert、emerg(panic) 指定级别 1234*：所有级别none：没有级别priority：此级别和高于此级别的所有级别&#x3D;priority：仅此级别 日志保存至数据库安装syslog-mysql模块 1yum install syslog-mysql -y 导入该模块自带的sql语句 1mysql &lt; /usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql 创建用户 1GRANT ALL ON Syslog.* TO &#39;rsyslog&#39;@&#39;192.168.%.%&#39; IDENTIFIED BY &#39;dqy751421&#39;; 配置rsyslog使用ommysql模块 123456789#配置文件保存在/etc/rsyslog.conf#MOUDLES$ModLoad ommysql#RULESfacility.priority :ommysql:DBHOST,DB,DBUSER,DBUSERPASSDBHOST：数据库地址DB：数据库名称DBUSER：数据库用户名DBUSERPASS：数据库用户密码 SUDO权限能够让获得权限的用户以另外一个用户的身份运行指定命令 授权文件：/etc/sudoers 编辑命令：visudo 123456789101112131415#授权项who where=(whom) commands%group where=(whom) commandswho：用户名where：限制哪台主机whom：以谁的身份%group：以哪个组的身份commands：可以执行的命令#注意使用组来限制时必须是基本组，不能是附加组使用newgrp命令可临时切换组在命令处加！可以实现排除某些命令，如：!/bin/su，即排除su命令命令必须全路径可以指定哪些命令要密码哪些命令不要密码，在命令前加PASSWD或NOPASSWD即可 sudo命令123sudo [option] -k：清空当前保存的用户密码 -l：列出当前用户可以执行哪些命令 别名12345678#在配置文件中可以定义别名，注意别名必须全大写，且命令必须全路径User_Alias：用户别名Cmnd_Alias：命令别名#举例User_Alias USERADMIN=frdqyCmnd_Alias NETADMINCMD=/usr/sbin/ipUSERADMIN ALL=(ALL) NETADMINCMD","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"chronyc","slug":"chronyc","permalink":"http://yoursite.com/tags/chronyc/"},{"name":"sudo","slug":"sudo","permalink":"http://yoursite.com/tags/sudo/"},{"name":"rsyslog","slug":"rsyslog","permalink":"http://yoursite.com/tags/rsyslog/"}],"author":"Frdqy"},{"title":"Iptables详解","slug":"Iptables","date":"2020-01-14T08:48:22.000Z","updated":"2020-01-21T11:52:33.399Z","comments":true,"path":"2020/01/14/Iptables/","link":"","permalink":"http://yoursite.com/2020/01/14/Iptables/","excerpt":"概念防火墙即Firewall是一种隔离工具，它工作在主机或网络边缘，对于进出本主机或本网络的报文根据事先定义的检查规则作匹配检测，对于能够被规则匹配到的报文作出相应处理的组件。","text":"概念防火墙即Firewall是一种隔离工具，它工作在主机或网络边缘，对于进出本主机或本网络的报文根据事先定义的检查规则作匹配检测，对于能够被规则匹配到的报文作出相应处理的组件。 根据作用域不同主要分为主机防火墙和网络防火墙。 规则链/钩子/hook：这是一种用于实现检查功能的机制。主要分为如下五种： prerouting：进主机路由前 input：进本机用户空间前 output：从本地用户空间出来后 forward：不是发往本机而是需要转发时 postrouting：转发后，出网卡前 规则组成部分一条规则由规则匹配条件和处理动作组成。 匹配条件：基本匹配条件、扩展匹配条件(由扩展模块定义) 处理动作：基本处理动作、扩展处理动作(由扩展模块定义)、自定义处理动作 规则定义原则同一类原则，控制范围小的(严格的)放在前面；不同类原则，访问频繁的放在前面。 链链主要分为内置链和自定义链。内置链就是上文的五个链；自定义链可以实现更灵活的管理机制 架构 filter：过滤，防火墙 nat：地址转换，用于修改源ip或目标ip mangle：拆解报文，作出修改再封装(ttl、防火墙标记等) raw：关闭nat表上启用的连接追踪功能，即将连接记录在内存中 功能-链表每个功能只能在特定的规则链上生效(生效优先级从上到下)。 raw：PREROUTING、OUTPUT mangle：PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUTING nat：PREROUTING、INPUT、OUTPUT、POSTROUTING filter：INPUT、FORWARD、OUTPUT 报文流向流入本机：PREROUTING、INPUT 由本机流出：OUTPUT、POSTROUTING 转发：PREROUTING、FORWARD、POSTROUTING iptables命令高度模块化。由诸多扩展模块实现其检查条件或处理动作的定义。模块文件存放在/usr/lib64/xtables/目录下。 1234567891011121314151617181920212223iptables [-t table] COMMAND chain [-m matchname [per-match-options]] -j targetname [per-target-options] -t table：raw、mangle、nat、[filter](默认为filter) COMMAND： 链管理： -N：自定义一条新的规则链 -x：删除自定义的规则链 -P：设置默认策略(ACCEPT、DROP、REJECT) -E：重命名自定义链(引用计数器不为0的自定义链不能被重命名或删除) 规则管理： -A：追加 -I：插入，要指明位置，省略时表示第一条 -D：删除 指明规则序号 指明规则本身 -R：替换指定链上的指定规则 -F：清空指定规则链 -Z：置零 查看： -L：列出链上所有规则(L必须放在下列选项的最后) -n：以数字格式显示地址和端口号，不进行反解 -v：显示详细信息 -x：显示计数器结果的精确值 --line-numbers：显示规则序号 匹配条件基本匹配条件无需加载任何模块，由iptables自行提供。 123456-s：指明检查的源地址或网段，所有地址为0.0.0.0-d：指明检查的目的地址或网段，所有地址为0.0.0.0-p：指明协议，包括tcp、udp、udplite、icmp、icmpv6、all等-i：指明数据报文流入的接口，只用于PREROUTING、INPUT、FORWARD-o：指明数据报文流出的接口，只用于FORWARD、OUTPUT、POSTROUTING-j：指明匹配后如何处理，包括ACCEPT、DROP、REJECT 扩展匹配条件1-m match_name per_option：使用特定模块和模块对应选项 隐式扩展使用-p选项指明了特定的协议时，不需再使用-m选项指明扩展模块。因为每个协议在/usr/lib64/xtables/目录下都有对应的可加载模块。 1234567891011121314tcp: [!] --sport port[:prot]：匹配报文的源端口，可以是范围 [!] --dport port[:prot]：匹配报文的目的端口，可以是范围 [!] --tcp-flags mask comp：mask表示要检查的标记位(逗号隔开)、comp表示标记位为1； [!] --syn：匹配第一次握手icmp： [!] --icmp-type num：指明icmp类型#举例，允许ssh22端口连接iptables -A INPUT -d 192.168.163.131 -p tcp --dport 22 -j ACCEPTiptables -A OUTPUT -s 192.168.163.131 -p tcp --sport 22 -j ACCEPT#允许本地ping别的主机，发送是8，响应是0iptables -A INPUT -d 192.168.163.131 -p icmp --icmp-type 0 -j ACCEPTiptables -A OUTPUT -s 192.168.163.131 -p icmp --icmp-type 8 -j ACCEPT 显式扩展必须使用-m选项指明要调用的扩展模块的扩展机制。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162multiport：以离散的方式开放多个端口 [!] --sports port[,port]：指定多个源端口 [!] --dports port[,port]：指定多个目的端口#举例iptables -I INPUT -d 192.168.163.131 -p tcp -m muliport --dports 22,80,139,445,3306 -j ACCEPT iprange：以连续地址快的方式来指明多IP地址匹配条件 [!] --src-range from[-to]：指明源地址范围 [!] --dst-range from[-to]：指明目的地址范围#举例iptables -I INPUT -d 192.168.163.131 -p tcp -m multiport -dports 22,80,139,445,3306 -m iprange --src-range 192.168.163.100-192.168.163.130 -j REJECTtime：以时间来控制数据包 --timestart hh:mm[:ss] --timestop hh:mm[:ss] [!] --weekdays day[,day...] [!] --monthdays day[,day...] --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --kerneltz：使用内核配置的时区而非默认的UTC#举例iptables -R INPUT 3 -d 192.168.163.131 -p tcp --dport 23 -m iprange 192.168.163.100-192.168.163.130 -m time --timestart 10:00:00 --timestop 16:00:00 --weekdays 1,2,3,4,5 --kerneltz -j ACCEPTstring：根据二进制流检查(明文编码才可以检查) --algo &#123;bm|kmp&#125;：指定匹配算法，必须指定 [!] --string pattern：指定要匹配的字符串 [!] --hex-string pattern：指定要匹配的十六进制字符串 --from offset：指定起始偏移 --to offset：指定结束偏移#举例iptables -I OUTPUT -m string --algo bm --string \"dqy\" -j REJECTconnlimit：限制同一ip的最大并发连接数 --connlimit-upto n：限制连接数小于n --connlimit-above n：限制连接数大于n#举例iptables -R INPUT 2 -d 192.168.163.131 -s 192.168.163.0/24 -p tcp -dport 3306 -m connlimit --connlimit-upto 3 -j ACCEPTlimit：用于限制报文发包速率(令牌桶算法) --limit rate/&#123;second|minute|day...&#125;：指明连接速率 --limit-burst：指明令牌数量#举例iptables -I INPUT 6 -d 192.168.163.131 -p icmp --icmp-type 8 -m limit --limit-burst 8 --limit 20/minute -j ACCEPTiptables -I INPUT 6 -d 192.168.163.131 -p icmp --icmp-type 0 -j ACCEPT#可以使用-syn和limit来控制建立新请求的速度state：连接追踪，用于查看报文状态 [!] --state state(NEW(缓存中没有)、ESTABLISHED、UNTRACKED(raw表关闭追踪)、RELATED(与某个ESTABLISHED有关)、INVALID(无法识别))#举例iptables -A INPUT -d 192.168.163.131 -p tcp -m multiport --dports 21:23,80,139,445,3306 -m state --state NEW -j ACCEPTiptables -A INPUT -m state --state ESTABLISHED -j ACCEPTiptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT#注意该方法可以大大简化规则的编写。首先INPUT链第一条允许状态为ESTABLISED通过，OUTPUT链第一条允许ESTABLISHED通过。其余的之后再写即可。另外，由于ftp连接时需要2个端口，因此要用到RELATED状态，即在INPUT里设置一条关于tcp协议的RELATED状态放行即可。使用该方法前需要先装载内核模块nf_conntrack_ftp即可。(使用modprobe安装)#追踪配置文件#追踪到的连接/proc/net/nf_conntrack#调整可记录的连接数最大值/proc/sys/net/nf_conntrack_max#超时时长，存放各类协议的超时/proc/sys/net/netfilter/*timeout* 处理动作基本处理动作12ACCEPT：接收DROP：直接丢弃 扩展处理动作12345678REJECT：接收后返回拒绝消息 --reject-with type：指明拒绝类型 LOG：记录日志 --log-level：指明日志等级 --log-prefix：指明日志名称(区别信息) RETURN：返回链调用，一般在自定义链中使用 用户自定义链自定义链必须要被已有的链引用才能生效。 123456#首先新建一个ruleiptables -N new_rules#然后在new_rule中写相关的规则iptables -A new_rules -d 192.168.163.131 -p icmp -j REJECT#最后在已有的链中调用(此处在INPUT中调用)，只要在动作指明新建的规则名即可iptables -I INPUT 5 -d 192.168.163.131 -p icmp -j new_rules 保存1iptables-save &gt; /path 载入123iptables-restore &lt; /path -n：不清楚原有规则 -t：仅分析不提交 规则优化思路使用自定义链管理特定应用的相关规则，模块化规则管理 优先放行双向状态皆为ESTABLISHED的报文 服务于不同类别的功能的规则，匹配到报文可能性更大的放在前面 服务于同一类别的功能的规则，匹配条件较严格的放在前面 设置默认策略，即白名单机制 不要使用iptables -P设置默认策略 建议在规则最后定义策略作为默认策略 nat转换nat转换主要用于隐藏客户端主机或者服务器主机，也用于解决ipv4地址数量问题。 snat：隐藏客户端访问外网，规则要定义在POSTROUTING上 dnat：隐藏服务端，接收客户端访问，规则要定义在PREROUTING上 1234567891011121314151617181920212223#SNAT，用于静态ip，不能限制端口的开放SNAT --to-source [ipaddr[-ipaddr]]：指明将虚地址转换为哪个公有地址，可以是范围(根据NAT服务器网卡决定) --random：随机转换一个地址 --persistent：固定转换地址#举例iptables -t nat -A POSTROUTING -s 192.168.163.0/24 -j SNAT --to-source 172.16.0.6#MASQUERADE，用于动态ipMASQUERADE：当外网地址不固定时，使用此target，但会消耗很多资源#DNAT，只开放有限端口DNAT --to-destination [ipaddr[-ipaddr]][:port[-port]]：指明将公网ip转为哪个虚ip --random：随机转换一个地址 --persistent：固定转换地址#举例，NAT_IP为nat服务器的网卡ipiptables -t nat -A PREROUTING -d NAT_IP -p tcp --dport 80 -j DNAT --to-destination 192.168.163.131:80#REDIRECT，用于单个主机的端口映射 --to-ports port[-port]#举例iptables -A PREROUTING -t nat -d 192.168.163.131 -p tcp --dport 80 -j REDIRECT --to-ports 8080","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}],"author":"Frdqy"},{"title":"存储共享","slug":"存储共享","date":"2020-01-12T11:48:52.000Z","updated":"2020-02-02T11:02:15.617Z","comments":true,"path":"2020/01/12/存储共享/","link":"","permalink":"http://yoursite.com/2020/01/12/%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB/","excerpt":"存储概念DAS：Direct Attached Storage 接口类型：”block”","text":"存储概念DAS：Direct Attached Storage 接口类型：”block” 特点：存储设备直连服务器 设备：SATA、SAS、IDE、SCSI、USB NAS：Network Attached Storage 接口类型：”file” 特点：将存储功能从服务器分离，通过网络协议来存取数据 协议：CIFS、NFS SAN：Storage Area Network 接口类型：”block” 特点：与NAS类似，但是每个每个存储阵列都有自己的文件管理系统 协议：ISCIS、FCSAN、FCOE FTP文件传输协议。连接主要有两种，一种是命令连接，用于客户端和服务器保持通话，传输命令，一般服务器监听21号端口；一种是数据连接，用于传输数据，一般服务器监听20号端口。但是现在ftp不是固定20号传输数据，会在通话时告诉客户端自己开了哪个端口，在那个端口进行数据传输。 PAM用于实现认证的第三方库，是一个高度模块化的文件。其配置文件在/etc/pam.d/目录下。每个用到pam的程序都有对应的配置文件。 vsftpd它是一个ftp的服务端程序，是轻量级的安全的ftp程序。 路径映射：用户家目录。vsftpd以ftp用户的身份运行进程，默认用户即为ftp用户，匿名用户的默认路径即为ftp用户的家目录/var/ftp。 注意：用户通过ftp登录后的权限取决于两个方面。第一是文件系统的权限，即ftp文件在服务器上的属主或属主权限。第二个是ftp服务器开放的权限。用户的权限是这两个权限的交集。 用户类别匿名用户：anonymous，其实就是ftp用户，它的登录目录为/var/ftp 系统用户：系统上拥有的用户，在/etc/vsftpd/ftpusers下定义用户名，在/etc/pam.d/vsftpd下定义了pam模块使用passwd和shadow来验证系统用户的登录。以系统用户身份登录后默认目录为其家目录。 虚拟用户：不是系统用户，可以定义在mysql数据库或普通文本文件中，相应的需要修改pam模块来验证。 守护进程standalone：独立守护进程；由服务进程自行监听套接字，用于访问比较繁忙的服务 transient：瞬时守护进程；由systemd代为监听套接字，有请求就启动服务进程 配置文件1234#主程序在/usr/sbin/vsftpd#主配置文件在/etc/vsftpd/vsftpd.conf#数据根目录在/var/ftp#systemd管理单元在/usr/lib/systemd/system/vsftpd.service 匿名用户12345678910111213#/etc/vsftpd/vsftpd.conf#是否启用匿名账号，默认YESanonymous_enable=YES#是否可以上传文件，默认NOanon_upload_enable=NO#是否可以创建目录，默认NOanon_mkdir_write_enable=NO#是否可以删除文件或目录，默认NOanon_other_write_enable=NO#是否全局只读，默认YESanon_world_readable_only=YES#设置匿名优先级anon_umask=077 系统用户1234567891011121314151617181920#/etc/vsftpd/vsftpd.conf#是否启用系统本地用户，默认YESlocal_enable=YES#本地用户是否具有写权限，默认YESwrite_enable=YES#设置本地用户上传文件的掩码(666-022=644)local_umask=022#辅助配置文件/etc/vsftpd/ftpusers，黑名单列在此文件中的用户均禁止访问ftp服务#禁锢所有本地用户于其家目录中；需要事先去除用户对家目录的写权限chroot_local_user=YES#禁锢列表中的用户于其家目录中；需要事先去除用户对家目录的写权限chroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_list#自定义白名单和黑名单，文件列表定义在/etc/vsftpd/user_list中userlist_enable=YES#NO表示白名单，YES表示黑名单userlist_deny=NO|YES 日志传输1234#是否启用日志xferlog_enable=YESxferlog_file=/var/log/xferlogxferlog_std_format=YES 并发连接1234#设置最大并发连接数max_clients=2000#单ip最大连接数max_per_ip=50 NFS网络文件系统。监听tcp2049端口。 其实NFS也像ext一样，是内核中的一个模块，通过VFS统一接口后挂载到用户层调用。但是用户在访问nfs系统时，通过内核后直接走套接字连接一台服务器，最终访问的是服务器上的文件系统，该文件系统可以是ext、xfs等任意文件系统。这个过程有一个问题，因为内核通过用户id来分辨用户，但此时服务器和客户端本地假如出现相同的id的用户，那就会出现访问控制问题。因此，需要使用统一的认证服务来确保不论是服务器还是本地用户都进行统一认证，即使用一个统一的认证数据库，这样就不会出现用户冲突的问题。常见的认证服务有：ldap、nls等。 辅助类服务rpc.mountd：用于检查连接的主机ip是否允许连接 rpc.lock：用于防止同时读写的冲突 rpc.statd：保存每个连接的状态 1234567#安装dnf install -y nfs-utils#启动systemctl start rpcbindsystemctl start nfs#注意，一定要先启动rpcbind，因为rpcbind主要是在nfs共享时通知客户端nfs端口号，可以理解为nfs的一个中介服务 配置文件12345678910111213141516171819202122232425262728293031#配置文件存放在/etc/exports和/etc/exports.d目录下#语法/path clients1(export_option) clients2(export_option)clients: single host：ipv4、ipv6、fqnd network：ip/mask wildcards：主机名通配，例如：*.top netgroups：NIS域内的主机组，例如：@group_name anonymous：使用*通配所有主机General options： ro：只读 rw：读写 sync：同步 async：异步 secure：客户端端口小于1024User ID Mapping： anonuid=user_id：设置映射用户id anongid=group_id：设置映射用户组id root_squash：压缩root用户，一般映射为nfsnobody no_root_squash：不压缩root用户 all_squash：压缩所有用户 anonuld and anongld：将压缩的用户映射为此处指定的用户 #举例#在192.168.163.132配置如下条目并重启nfs服务/etc/ 192.168.163.131(rw,all_squash)systemctl restart nfs#在192.168.163.131主机上使用如下命令检测showmount -e 192.168.163.132#挂载132主机的etc目录到本地的/mnt/media下mount -t nfs 192.168.163.132:/etc /mnt/media/ 常用命令1234#修改配置文件后重新导出配置文件，即立即生效exportfs -rav#查看指定nfs服务器开启哪些挂载目录showmount -e ip 配置流程首先在服务器端编辑/etc/exports创建目录条目，然后在客户端直接挂载即可。 sambasamba是一款跨平台的服务器文件共享方案。 NetBIOS：用于广播实现主机名解析 SMB：实现文件系统共享 12345#安装#服务器端yum install -y samba#客户端yum install -y samba-client 服务端服务端：samba、samba-common、samba-libs 配置文件：/etc/samba/smb.conf 主程序：nmbd、smbd。前者用于提供主机名解析(为了windows解析)，后者用于共享文件的访问。 systemd unit：smb.service、nmb.service 监听端口：137/udp、138/udp、139/tcp、445/tcp 配置文件12345678910111213141516171819202122232425262728#/etc/samba/smb.conf#Networkworkgroup：工作组server string：设定类似win的鼠标悬停信息netbios name：当前主机名interfaces：监听网卡接口或ip地址hosts allow：白名单，允许哪些网段或ip访问hosts deny：黑名单，禁止哪些网段或ip访问#Logginglog file：指明日志文件路径max log size：日志大小，超出会滚动日志(保存旧的，创建新的)#Standalone serversecurity：运行的安全模式，目前为user，且必须为系统账号，但使用samba独立密码passdb backend：加密方式#Sharewritable：用户是否对家目录有写权限comment：注释信息path：需要共享的路径browseable：是否可浏览guest ok：是否被匿名用户访问write list：拥有写权限的用户列表read only：是否只读#检测，修改过配置文件后使用如下命令进行检测testparm 创建samba用户1234#创建用户useradd smbuser#设置samba密码smbpasswd -a smbuser 创建共享文件12345678910mkdir /data/samba/files/ -pv#编辑/etc/samba/smb.conf[myfiles] comment = A test shared dir path = /data/samba/files public = yes browseable = yes write list = smbuser#可以基于组权限设置，使用+号或@write list = +group_name 设置文件系统权限1setfacl -m u:smbuser:rwx /data/samba/files/ 客户端smbclient：交互式命令行客户端，类似于lftp mount.cifs：挂载cifs文件系统的专用命令 123456#匿名访问smbclient -L 192.168.163.131#指定用户查看是否能访问smbclient -L 192.168.163.131 -U user1#以指定的用户登录myfiles为定义在/etc/samba/smb.conf的一个字段smbclient //192.168.163.131/myfiles -U user1 挂载1mount.cifs //192.168.163.131/myfiles /mnt -o username=smbuser,password=dqy751421 注意samba有自己的用户管理系统，因此对于权限的要求更严谨。 要确保客户端当前用户对挂载点有写权限；要确保映射目录对远程服务器对应id用户也有写权限；挂载的目录samba设置也要有写权限 用户管理有关命令1234567891011121314151617smbpasswd [option] username -a：添加 -x：删除 -d：禁用 -e：启用pdbedit [option] -L：列出所有samba服务中的用户 -a：添加samba用户 -u：要管理的用户 -x：删除samba用户 -t：从标准输出接收密码 #显示samba服务的相关共享的信息smbstatus -b：显示简要信息 -v：显示详细信息 配置流程首先需要在服务器创建用户，且设置samba的用户密码。然后在配置文件/etc/samba/smb.conf中单独设置一个选项来配置要映射的文件夹路径。最后客户端直接挂载即可。注意点还是权限的管理。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"nfs","slug":"nfs","permalink":"http://yoursite.com/tags/nfs/"},{"name":"ftp","slug":"ftp","permalink":"http://yoursite.com/tags/ftp/"},{"name":"samba","slug":"samba","permalink":"http://yoursite.com/tags/samba/"}],"author":"Frdqy"},{"title":"mariadb详解","slug":"mariadb详解","date":"2020-01-11T10:08:37.000Z","updated":"2020-01-11T10:11:32.772Z","comments":true,"path":"2020/01/11/mariadb详解/","link":"","permalink":"http://yoursite.com/2020/01/11/mariadb%E8%AF%A6%E8%A7%A3/","excerpt":"数据管理模型：层次模型、网状模型、关系模型 数据分类：结构化数据、非结构化数据、半结构化数据","text":"数据管理模型：层次模型、网状模型、关系模型 数据分类：结构化数据、非结构化数据、半结构化数据 关系模型二维关系表：row，col 索引：index 视图(虚表)：view SQL接口标准查询语言。类似于shell的接口，提供编程功能。 DDL数据定义语言 create、alter、drop、show DML数据管理语言 insert、delete、update、select SQL代码存储过程：procedure。执行命令无返回数据。 存储函数：function。执行命令有返回数据。 触发器：trigger。当前表满足某个条件时执行。 事件调度器：event scheduler。周期性计划 用户和权限用户：用户名和密码 权限：管理类、程序类、数据库、表、字段 事务组织多个操作作为一个整体，要么全部成功执行，要么失败全部回滚。 ACID标准A：原子性 C：一致性 I：隔离性 D：持久性 约束constraint，向数据表插入的数据要遵守的限制规则 主键：一个或多个字段的组合，填入主键中的数据，必须不同于已存在的数据，不能为空。一个表存在一个主键。 外键：一个表中某字段中能插入的数据，取决于另外一张表的主键中的数据。 唯一键：一个或多个字段的组合，填入唯一键中的数据，必须不同于已存在的数据，可以为空。一个表可存在多个唯一键。 检查性约束：取决于表达式的要求。 索引将表中的某一项或某些字段抽取出来，单独将其组织成一个独特的数据结构 常见索引：B+ Tree，mysql中使用该数据结构。 注意：索引有利于读请求但不利于写请求。对于B+树，查询数据的IO平均次数为O(log n)；如果没有索引需要逐条匹配，IO平均次数为O(n)。不利于写是因为B+数插入删除操作时可能会引起平衡的调整。 关系运算选择：挑选出符合条件的行 投影：挑选出符合需要的列 连接：将多张列表关联起来 MariaDB特性插件式存储引擎，存储管理器有多种实现版本，彼此之间的功能和特性可能略有区别，可灵活选择。 存储引擎MyISAM：不支持事务；表级锁；崩溃后不保证安全恢复 InnoDB：支持事务；行级锁；外键；热备 程序组成Clientmysql：CLI交互式客户端程序 mysqldump：备份工具 mysqladmin：管理工具 Servermysqld mysqld_safe：建议运行的服务端程序 mysqld_multi：多实例 补充：三类套接字地址 ipv4/ipv6，3306/tcp Unix sock：/var/lib/mysql/mysql.sock或/tmp/mysql.sock本地套接字文件，用于进程间通信，共享内存。 配置文件ini风格，一个文件为多个程序提供配置 [mysql]：客户端配置 [mysqld]：服务端配置 1234567891011#mysql的各类程序启动都读取不止一个配置文件，且按顺序读取，重复定义的最后读取的最终生效#使用my_print_defaults查看启动配置文件Default options are read from the following files in the given order:/etc/my.cnf ~/.my.cnf#注意，客户端连接服务端时服务端会反解客户端的IP为主机名，需要关闭此功能[mysqld]skip_name_resolve#设置独立表空间(每个表的索引数据等都独立)[mysqld]innodb_file_per_table 数据类型1234567#查看mysql支持的字符集show character set;show collation;#设置默认utf-8编码在[client]和[mysqld]字段下面均添加default-character-set=utf8#检查字符编码show variables like \"char%\"; 字符型定长字符CHAR(#)：不区分字符大小写 BINARY(#)：区分字符大小写 变长字符VARCHAR(#)：不区分字符大小写，需要多占一个或多个字符结束空间 VARBINARY(#)：区分字符大小写，需要多占一个或多个字符结束空间 对象存储有最大的存储限度，但是具体分配时根据实际长度分配。 TEXT：不区分字符大小写 BLOB：区分字符大小写 内置类型SET：集合，限制数据为集合内的组合 ENUM：枚举，限制填写数据，且写入数据库的真实数据为枚举的索引。 数值型INT系列，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT、DECIMAL 浮点数系列，包括FLOAT、DOUBLE 日期型DATE、TIME、DATETIME、TIMESTAMP、YEAR(2)、YEAR(4) 修饰符UNSIGNED：无符号 NOT NULL：非空 DEFAULT value：默认值 PRIMARY KEY：主键 UNIQUE KEY：唯一键 FOREIGN KEY：外键 AUTO_INCREMENT；自动增长 客户端命令12345678910111213141516171819202122232425262728mysql [option] [database] -u[username]：设置用户名。可以不带空格。 -h[hostname]：设置主机名。可以不带空格。 #mysql用户账号由两部分组成'USERNAME'@'HOST' #其中HOST限制了此用户可通过哪些远程主机连接当前的mysql服务。其表达方式如下 %：匹配任意长度字符。如192.186.%.% _：匹配任意单个字符 -p[PASSWARD]：设置密码。可以不带空格。 -D[db_name]：设置连接服务器后的默认连接数据库 -e 'SQL COMMAND'：连接至服务器并让其执行此命令后直接放回 -P[port]：指明mysql服务器端口，默认3306 -S[sock]：指明使用的套接字文件路径 #服务端命令 DDL、DML、DCL，每句结果以;结尾 mysql&gt;help contens mysql&gt;help \"具体的contents内容\" #客户端命令 mysql&gt;help \\u db_name：选择数据库 \\q：退出 \\d CHAR：设定新的语句结束符 \\g：语句结束标记，默认为; \\G：同上，但结果以竖排方式显示 \\s：查询状态 \\c：取消当前语句，类似shell的ctrl+c \\! shell_command：执行shell命令 \\. sql脚本路径：执行sql命令 服务端命令数据库管理创建123CREATE &#123;DATABASE|SCHEMA&#125; [IF NOT EXISTS] db_name; [DEFAULT] CHARACTER SET [&#x3D;] charset_name | [DEFAULT] COLLATE [&#x3D;] collation_name 修改123456789ALTER &#123;DATABASE | SCHEMA&#125; [db_name] [DEFAULT] CHARACTER SET [&#x3D;] charset_name | [DEFAULT] COLLATE [&#x3D;] collation_name#或者ALTER &#123;DATABASE | SCHEMA&#125; db_name UPGRADE DATA DIRECTORY NAME#例如：修改字符集为utf-8alter database mysql character set &#39;utf-8&#39;; 删除1DROP &#123;DATABASE | SCHEMA&#125; [IF EXISTS] db_name SHOW12SHOW &#123;DATABASES | SCHEMAS&#125; [LIKE &#39;pattern&#39; | WHERE expr] 表管理创建12345678910CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name (create_definition,...) [table_options] [partition_options]create_definition： 字段：col_name、data_type 键：PRIMARY KEY(col1,col2...)、UNIQUE KEY(col1,col2...)、FOREIGN KEY(col1,col2...) 索引：KEY|INDEX [index_name](col1,col2...)table_options： ENGINE&#x3D;engine_name 修改123456789101112131415161718192021ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name [alter_specification [, alter_specification] ...] [partition_options]alter_specification： 字段： 添加：ADD [COLUMN] col_name data_type [FIRST|AFTER col_name] 删除：DROP [COLUMN] col_name 修改：CHANGE [COLUMN] old_col_name new_col_name column_definition [FIRST|AFTER colname] 键： 添加：ADD &#123;PRIMARY|UNIQUE|FOREIGN&#125; KEY (col1,col2...) 删除： 主键：DROP PRIMARY KEY 外键：DROP FOREIGN KEY fk_symbol 索引： 添加：ADD &#123;INDEX|KEY&#125; [index_name] (col1,col2...) 删除：DROP &#123;INDEX|KEY&#125; index_name 表选项： ENGINE&#x3D;engine_name #补充：查看索引：show index from table_name; 删除1DROP TABLE [IF EXISTS] tbl_name[,tbl_name]... 复制表结构1CREATE TABLE tbl_name like other_table_name 复制表数据12#复制表数据时需要手动定义各个数据的格式CREATE TABLE tbl_name (col1,col2...) SELECT clause 查看表结构1DESC tbl_name; 索引管理创建1234CREATE [ONLINE|OFFLINE] [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name [index_type] ON tbl_name (index_col_name,...) [index_option] 删除1DROP [ONLINE|OFFLINE] INDEX index_name ON tbl_name 数据管理插入123456789101112INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [(col_name,...)] &#123;VALUES | VALUE&#125; (&#123;expr | DEFAULT&#125;,...),(...),... [ ON DUPLICATE KEY UPDATE col_name&#x3D;expr [, col_name&#x3D;expr] ... ]#举例insert into student(col1,col2) value(val1,val2);replace into student(col1,col2) value(val1,val2);#注意字符型要用引号，数值型不能用引号 查找select执行顺序为先执行from，确定哪个表；接着执行where，挑选满足的行；然后执行group by对选择的行进行分组；然后执行having对挑选出的组进行过滤；然后使用order by对挑选出的进行排序；然后执行select选择特点列；最后根据limit移除不需要的行。 1234567891011121314151617181920#显示所有行select * from tbl_name;#指定字段显示别名select col1 AS col1_alias,col2 from tbl_name;#where挑选select col1... from tbl_name where clause; where clause： 操作符：&gt;,&lt;,&gt;&#x3D;,&lt;&#x3D;,&#x3D;&#x3D;,!&#x3D; 判断空：IS NULL,IS NOT NULL 列表：IN (1,2,3) 通配：LIKE &#39;d%&#39; 正则统配：RLIKE &#39;^d&#39; 组合条件：and、or、not 范围：between...and...#group by分组，分组用来聚合(统计)，通常用Having对组进行过滤#常见聚合有count，sum，avg，max，minselect count(*) AS col1_alias,col2 from tbl_name group by col_name;#order by排序，desc表降序，ASC表升序，默认为升序select * from tbl_name order by col_name [DESC]; 删除12#注意，一定要使用whereDELETE FROM tbl_name [WHERE clause] [ORDER BY...] [LIMIT row_count] 更新123456#注意，一定要使用whereUPDATE [LOW_PRIORITY] [IGNORE] table_reference SET col_name1&#x3D;&#123;expr1|DEFAULT&#125; [, col_name2&#x3D;&#123;expr2|DEFAULT&#125;] ... [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] 用户账号与权限管理1234#mysql用户账号由两部分组成'USERNAME'@'HOST'#其中HOST限制了此用户可通过哪些远程主机连接当前的mysql服务。其表达方式如下 %：匹配任意长度字符。如192.186.%.% _：匹配任意单个字符 创建用户1CREATE USER &#39;username&#39;@&#39;host&#39; [IDENTIFIED BY &#39;password&#39;]; 删除用户1DROP USER &#39;username&#39;@&#39;host&#39;[,&#39;username&#39;@&#39;host&#39;]; 授权用户12345678#若用户不存在可以自动创建GRANT priv_type... ON [object_type] db_name.tbl_name TO &#39;username&#39;@&#39;host&#39; [IDENTIFIED BY &#39;password&#39;]; priv_type：select、drop、all... db_name.tbl_name： *.*；所有库的所有表 db_name.*：指定库的所有表 db_name.tbl_name：指定库的指定表 db_name.routine_name：指定库的存储过程或存储函数 回收授权1REVOKE priv_type ON db_name.tbl_name FROM &#39;username&#39;@&#39;host&#39;; 查看权限1234#查看自身权限SHOW GRANTS;#查看授权SHOW GRANTS FOR &#39;username&#39;@&#39;host&#39;; 查看当前用户1SELECT user(); 注意mysql服务进程启动时会读取mysql库的所有授权表至内存中，因此运行时修改可能不会立即生效。但是GRANT和REVOKE执行时会重建授权表，会立即生效。 12#权限修改立即生效FLUSH PRIVILEGES; 加固mysql12mysql_secure_installation#会让你设置root密码等","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"mariadb","slug":"mariadb","permalink":"http://yoursite.com/tags/mariadb/"}],"author":"Frdqy"},{"title":"LAMP配置","slug":"LAMP配置","date":"2020-01-11T10:08:04.000Z","updated":"2020-01-11T10:11:09.337Z","comments":true,"path":"2020/01/11/LAMP配置/","link":"","permalink":"http://yoursite.com/2020/01/11/LAMP%E9%85%8D%E7%BD%AE/","excerpt":"概念L：Linux A：apache(httpd)","text":"概念L：Linux A：apache(httpd) M：mysql、mariadb P：php、perl、python 安装流程mariadb12#安装服务端dnf install mariadb PHP123456#此处使用php-fpm模块，php-mysqlnd 不能安装php#php-mysqlnd是php对mysql的支持库#php-fpm是php对网页的接口#php-mbstring是对汉字支持#php-xcache优化php代码执行速度dnf install php-mysqlnd php-fpm php-mbstring php-xcache Httpd123dnf install httpd#查找fcgi模块，没有则不能与后端通信，即php通信httpd -M | grep fcgi 配置文件php服务配置文件：/etc/php-fpm.conf，/etc/php-fpm.d/*.conf php配置文件：/etc/php.ini、/etc/php.d/*.ini/ 123456789101112131415161718192021#/etc/php-fpm.conf，使用;注释pid：进程iderror_log：错误日志路径log_level：日志记录级别daemonize：是否以守护进程方式运行(默认为no，需要通过systemctl来管控)#/etc/php-fpm.conf.d/www.conf，用于管理与www页面的结合listen：指明监听端口listen.allowed_clients：允许来自哪些ip的客户端进行请求listen.backlog：指定后援队列，只允许访问的等待队列长度pm：设置子进程管理方式pm.max_children：设置最大并发数pm.start_servers：服务启动时启动多少个子进程pm.min_spare_servers：最小空闲进程数pm.max_spare_servers：最大空闲进程数pm.process_idle_timeout：空闲进程多少秒后被杀死pm.max_requests：每个进程最多响应多少个请求后将其杀死pm.status_path：设置fpm状态页路径ping,path：允许进程pingping.responce：允许服务器给ping回复php_value[session.save_path]：session保存路径 mariadb1234567891011121314151617#修改配置文件/etc/my.conf.d/server.cnf(没有就自己建一个)，在[mysqld]字段中添加如下条目#不对用户ip进行反向解析skip_name_resolve#设置独立表空间(每个表的索引数据等都独立)innodb_file_per_table#安全加强mysql_secure_installation#授权一个用户用于访问GRANT ALL ON testdb.* TO 'dqy'@'localhost' IDENTIFIED BY 'dqy751421'#设置默认字符集#查看show variables like \"char%\"#修改/etc/my.conf.d/server.cnf(没有就自己建一个)在[client]和[mysqld]字段下添加default-character-set=utf8 httpd主要配置与php有关，其他具体配置见http详解 1234567891011#配置/etc/httpd/conf.d/fcgi.conf(没有则自建)#设置默认主页，即访问目录不指明具体网页时的访问对象DirectoryIndex index.php#关闭正向代理ProxyRequests Off#反向代理。匹配所有以php结尾的访问，将其转接到127.0.0.1:9000端口，且其网页放在/var/www/html/目录下(后向引用)ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1#注意如果设置了虚拟主机，那么就把上述命令放到虚拟主机配置文件里所谓的反向代理就是http服务器将接收到动态请求再向php服务器请求，此时http服务器身份为客户端。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"lamp","slug":"lamp","permalink":"http://yoursite.com/tags/lamp/"},{"name":"php配置","slug":"php配置","permalink":"http://yoursite.com/tags/php%E9%85%8D%E7%BD%AE/"},{"name":"mysql配置","slug":"mysql配置","permalink":"http://yoursite.com/tags/mysql%E9%85%8D%E7%BD%AE/"}],"author":"Frdqy"},{"title":"http详解","slug":"http详解","date":"2020-01-10T11:50:40.000Z","updated":"2020-01-11T10:07:16.504Z","comments":true,"path":"2020/01/10/http详解/","link":"","permalink":"http://yoursite.com/2020/01/10/http%E8%AF%A6%E8%A7%A3/","excerpt":"基础概念端口号","text":"基础概念端口号 0~1023：永久地分配给固定的应用使用 1024~41591：注册端口，分配给程序注册为某应用使用 41592+：客户端程序随机使用，为动态端口 BSD SocketIPC的一种实现，允许不同主机上的进程进行通信 Socket API封装了内核中socket通信相关的系统调用 SOCK_STREAM：tcp套接字 SOCK_DGRAM：udp套接字 SOCK_RAW：raw套接字 Socket Domain套接字地址格式 AF_INET：Ipv4地址族 AF_INET6：Ipv6地址族 AF_UNIX：同一主机上的不同进程间基于socket通信时使用的地址(基于内存的伪文件，不走tcp协议) http超文本传输协议，监听tcp80端口 特征无连接的协议。服务器无法持续追踪访问者的来源。cookie和session分别是客户端和服务器端用来保存用户个人特征信息的文件。例如身份验证、特点客户的浏览喜好等等。 协议版本http/1.0：引入cache、MIME、Method机制 MIME：多用途互联网邮件扩展协议。用于解决将非文本信息按照某种编码转换成文本格式传输到客户端后还能解码还原成原来格式，因此http可以传输非文本信息。 Method：GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS http/1.1：增强缓存功能 http/2.0：借鉴spdy协议进行大面积优化 工作模式由请求报文和响应报文组成。一次请求和一次响应叫做一次http事务。 报文格式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#request&lt;method&gt;&lt;request-URL&gt;&lt;version&gt;&lt;HEADERS&gt;&lt;entity-body&gt;#response&lt;version&gt;&lt;status&gt;&lt;reason-phrase&gt;&lt;HEADERS&gt;&lt;entity-body&gt;#method请求方法，标明客户端希望服务器对资源执行的动作GET：请求获取资源HEAD：请求资源但不要资源，只要首部POST：提交表单PUT：上传资源到服务器端，需要服务器开启DAVTRACE：追踪请求到达服务器中间经过的代理服务器OPTIONS：请求服务器返回对指定资源支持的请求方法#version http协议版本HTTP/&lt;major&gt;.&lt;minor&gt;#status1XX：无大意义，表信息提示2XX：请求成功3XX：特殊意义重定向等4XX：客户端错误5XX：服务器错误#常见状态码200：成功301：请求的URL永久重定向302：请求的URL临时重定向304：响应客户端的条件式请求，服务器某URL没有改变，则返回此状态码401：需要输入账号密码403：请求被禁止404：服务器找不到资源500：服务器内部错误502：代理服务器从后端服务器收到了一条伪响应(Bad Gateway)，即服务器不响应#补充：代理正向代理：代理客户端向服务器端请求反向代理：代理服务器端向客户端响应请求#headers，一般分为5类请求或响应报文可以有任意个首部，每个首部都有首部名称，后面跟一个冒号，而后加空格加值#通用首部：请求响应都适用Date：报文的创建时间Connection：连接状态，如keep-alive，closeVia：显示报文经过的中间节点Cache-Control：控制缓存#请求首部：用于请求报文Host：请求的服务器的地址和端口Referer：从哪个上级资源跳转Uer-Agent：客户端浏览器型号(用于服务器条件式响应)Accept：通知服务器自己可接受的媒体类型(text/html,application/javascript,images/jpeg等)Accept-Charset：文本编码格式Accept-Encoding：接受的压缩格式，如gzipAccept-Language：接受的语言#条件式请求首部If-Modified-Since：自上次请求后请求的资源是否修改If-Unmodified-Since：是否没有修改If-None-Match：本地缓存中存储的文档的Etag标签是否与服务器文档的Etag不匹配If-Match：#安全请求首部Authorization：向服务器发送认证请求Cookie：客户端向服务器发送cookie#代理请求首部Proxy-Authorization：向代理服务器认证#响应首部：用于响应报文Age：响应持续时长Server：服务器程序软件名称和版本Accept-Ranges：服务器可接受的请求范围类型Vary：服务器查看的其他首部列表Set-Cookie：：向客户端设置cookieWWW-Authorization：质询认证表单(401)#实体首部：用于描述&lt;entity-body&gt;信息Allow：列出对此实体可使用的请求方法Location告诉客户端真正实体位于何处Content-Encoding：实体编码Content-Language：实体语言Content-Length：实体长度Content-Location：实体真正位置Content-Type：实体对象类型ETag：实体的扩展标签Expires：实体的过期时间Last-Modified：最后一次修改时间#扩展首部：自定义首部 web资源http一次请求和响应的内容叫做一个web资源。一个页面通常由多个资源组成。因此打开一个网址时每个资源都要单独进行http请求。每个资源通过完整的URL进行标识，即标识了资源在服务器的路径。 12345http://www.frdqy.top/index.htmlScheme://Server[:port]/[path]#scheme：方案，即什么协议#Servier[:port]协议和端口#基本语法：&lt;scheme&gt;://[&lt;user&gt;:&lt;passwd&gt;@]&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; 静态资源：无需服务端额外处理的资源。如文本、图片、视频等。 动态资源：服务端需要执行额外程序作出处理，且发送给客户端的程序是运行的结果。如php、jsp等 请求过程首先，建立连接，服务器接收或拒绝请求。然后，服务器接收请求，即接收网络上主机请求报文中对某特定资源的一次请求过程。接着，对请求报文进行解析，获取客户端请求的资源及请求方法(删除、编辑等)等相关信息。然后，从服务器本地磁盘中获取请求的资源。之后，构建响应报文并发送给客户端。最后，记录日志。 相关命令curl1234567curl [option] URL... -A：设置用户代理 -e/--refer：指明上级访问 -H：自定义首部信息 -I：只返回首部信息，即head方法 --limit-rate rate：限制传输速度 --compressed：要求返回压缩格式 https基于ssl的http协议。监听tcp443端口。 首先，客户端发送可供选择的加密方式，并向服务器请求证书，服务器端发送证书以及选定的加密方式给客户端，客户端取得证书后验证证书合法后生成临时会话密钥，并使用服务器端的公钥加密此数据发送给服务器，完成密钥交换。然后服务器用此密钥加密用户请求的资源，响应给客户端即可。 httpd特性 高度模块化，类似于linux，更换模块时不需要编译，直接重载即可 MPM机制，即多路处理模块。实现并发请求。 prefork：多进程模型(二级模型)，每个进程响应一个请求。主进程负责生成子进程及回收子进程，每个子进程处理一个请求。它会预留几个空闲进程用来随时响应用户请求，且包含最大空闲与最小空闲进程的概念，即预留的空闲进程的大小有规定。 worker：多进程多线程模型(三级模型)，每个线程处理一个用户请求。主进程负责生成和回收子进程，而子进程负责生成和回收线程，每个线程负责响应用户请求。 event：事件驱动模型。每个进程响应多个请求。主进程生成和回收子进程，子进程基于事件驱动机制直接响应多个请求。 程序环境配置文件/etc/httpd/conf/http.conf /etc/httpd/conf.d/*.conf，多用于自定义配置文件存放 模块配置文件：/etc/httpd/conf.modules.d/*.conf 123#配置格式#其中，指令可以不区分大小写，但是值如果为路径时要区分大小写指令 值 主程序文件/usr/sbin/httpd 日志文件/var/log/httpd。其中access_log为访问日志，erroe_log为错误日志。 站点文档/var/www/html unit文档/usr/lib/systemd/system/httpd.service 模块文件路径/usr/lib64/httpd/modules 常用配置修改端口12345Listen [IP-address:]port [protocol]#省略ip表示0.0.0.0#Listen指令可重复出现多次#修改监听socket，需要重启服务进程#限制必须通过ssl通信时，protocol定义为https 持久连接12345KeelAlive On|Off#双重标准，满足一个就断开(时间超过15，或请求数量大于100)#时间加ms可以为毫秒级KeepAliveTimeOut 15MaxKeepAliveRequests 100 错误检查12#每次修改配置文件后进行语法错误检查httpd -t MPM即多路处理模块。实现并发请求。 prefork配置12345678&lt;IfModule prefork.c&gt;StartServers 8 #开启服务时启动的空闲进程数MinSpareServers 5 #最小空闲子进程数MaxSpareServers 20 #最大空闲子进程数ServerLimit 256 #允许服务器处于活跃状态的子进程数MaxClients 256 #最大允许启动子进程数MaxRequestsPerChild 4000 #每个子进程最大处理请求数量&lt;/IfModule&gt; worker配置123456789101112&lt;IfModule worker.c&gt;StartServers 4 #开启服务时启动的空闲进程数MaxClients 300 #最大允许启动线程数MinSpareThreads 25 #最小空闲线程数MaxSpareThreads 75 #最大空闲线程数ThreadsPerChild 25 #每个进程生成多少线程MaxRequestsPerChild 0 #单个线程最大处理请求数量，0表示不限制&lt;/IfModule&gt;#上述配置存在问题，初始生成100个线程，但最大允许75个线程，因此刚启动就会杀掉一个进程#使用如下命令查看，即每0.5s查看一次systemctl restart httpd ; watch -n0.5 'ps aux | grep httpd' DSO动态模块加载。 123#配置指定实现模块加载#注意，模块相对路径为：定义在/etc/httpd/conf/httpd.conf的ServerRootLoadModule &lt;mod_name&gt; &lt;mod_path&gt; 主服务器即中心主机。 123456#当前服务器的主机名ServerName#服务器别名ServerAlias#定义URL的根路径与文件系统的映射关系DocumentRoot 基于IP访问控制使得DocumentRoot定义的资源对有限的对象开放访问。可以通过文件系统路径和URL路径两种方式实现控制。 文件系统路径1234567891011121314151617181920212223242526272829303132#对整个目录控制&lt;Directory \"\"&gt;...&lt;/Directory&gt;#对某个文件控制&lt;File \"\"&gt;...&lt;/File&gt;#正则表达式控制&lt;FileMatch \"PATTERN\"&gt;...&lt;/FileMatch&gt;#举例&lt;Directory \"\"&gt;...#接收所有请求Require all granted#拒绝所有请求Require all denied&lt;Requireall&gt; #接收IP地址或网段 require ip IP_ADDR #拒绝IP地址或网段 require not ip IP_ADDR #接收host主机名 require host HOST_NAEM #拒绝host主机名 require not host HOST_NAEM&lt;/Requireall&gt;...&lt;/Directory&gt; URL路径1234567&lt;Location \"\"&gt;...&lt;/Location&gt;#正则URL&lt;LocationMatch \"PATTERN\"&gt;...&lt;/LocationMatch&gt; option选项定义于Directory内，用于控制目录特性 12345678#Indexes指明URL的路径下不存在请求的主页时，将目录索引列表返回给用户。该方法很危险，一般下载站使用。访问具体资源时不受影响。#FollowSymLinks允许跟踪符号链接文件，即网络目录中存在符号链接至其他目录的文件时是否显示对应的文件内容#AllowOverride一般设置为none不允许重现配置文件 目录索引1DirectoryIndex定义了访问目录而不指明具体页面时的默认页面，一般为index.html 路径别名用于修改目录映射 12345678#在alias_module中定义一个alias#其中PATH1是需要修改的原目录路径，PATH2是目标目录路径Alias PATH1 \"PATH2\"#举例#表示将/DocumentRoot/images/目录映射到/usr/share/backgrands/，此后网页中访问/image/时会自动映射到对应目录中去#注意，对于http2.4来说，访问控制严格，需要将对应目录也设置&lt;Directory&gt;Alias /images/ \"/usr/share/backgrands/\" 默认字符集1AddDefaultCharset UTF-8 日志记录正确和错误的访问日志。 1234567891011121314#日志格式定义于/etc/httpd/conf/httpd.conf中的log_config_module字段中#中间是定义的宏，\"cominned\"是该格式的名字，在后面使用CustomLog来指定使用哪个格式 LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b \\\"%&#123;Referer&#125;i\\\" \\\"%&#123;User-Agent&#125;i\\\"\" combinedCustomLog \"logs/access_log\" combined%h：远程主机名，一般为ip地址%l：基于identd远程登录的远程用户名，一般没人用%u：记录认证的用户名%t：时间%r：请求报文的首行(请求URL、方法、协议版本)%s：状态码，%&gt;s表示的是发生重定向后的最后一次状态码%b：响应报文的大小，不包括首部，单位为字节%&#123;Referer&#125;i：请求报文首部中的referer值，即从哪个页面中的超链接跳转至当前页面%&#123;User-Agent&#125;i：请求报文中首部User-Agent的值，即发出请求的客户端的应用程序 错误日志 12#存放于/var/log/httpd/error.log中主要是记录服务器加载错误模块等服务器端的错误。注意，用户访问不存在的资源时不是服务端错误。 访问日志12#存放于/var/log/httpd/access.log用于记录正常的访问记录 用户访问控制认证质询客户端第一此发送请求时，服务器拒绝该请求，响应码为401，并返回一个www-authenticate要求客户端提交账号和密码。 认证客户端输入账号和密码后再次发起请求报文(Authorization)，认证通过后服务器发送响应的资源。认证方式有两种basic和digest(前者为明文，后者为摘要hash)。现在一般网页都使用基于服务器应用的认证，而不是用http的认证。 认证配置12345678910111213141516171819202122232425262728293031323334#定义安全域#可以基于用户控制，也可以基于用户组控制&lt;Directory \"\"&gt;...#指明验证方式AuthType basic#验证提示信息AuthName \"STR\"#用户密码存放文件(使用htpasswd 用户名 )AuthUserFile \"PATH/FILE\"#用户组文件保存路径AuthGroupFile \"PATH/FILE\"#指明对哪些用户控制Require user username1 username2...#对所有定义在文件中的用户配置Require valid-user#指明对哪些组控制Require group GROUP_NAME...&lt;/Directory#举例。在/etc/httpd/conf.d/下新建一个admin.conf，单独模块方便删除#使用htpasswd在/etc/httpd/conf.d/创建一个隐藏文件，定义密码和用户&lt;Directory \"/data/web/www/admin\" &gt; options None AllowOverride None Authtype basic AuthName \"This is Admin\" AuthUserFile \"/etc/httpd/conf.d/.htpasswd\" Require user tom dqy&lt;/Directory&gt;#定义组文件GROUP_NAME:user1 user2 htpasswd12345678910#用于创建账号密码文件htpasswd [options] /PATH/TO/FILE username -c：在指定路径创建存储文件，仅在第一次使用 -m：md5加密 -s：sha格式加密 -D：删除指定用户 -b：添加指定用户#举例htpasswd -c /tmp/test.user tomhtpasswd -b /tmp/test.user jerry 751421 虚拟主机一个物理服务器服务多个网站。实现方法有基于ip，即为每个虚拟主机准备至少一个ip地址(一块网卡可以有多个ip地址)。有基于port，即每个虚拟主机使用至少一个独立的port。基于FQDN，即基于主机的主机名(host)解析。 ip比较昂贵，端口也不能随便修改，因此一般使用基于主机名的host解析方式。该方式需要配置dns。 1234567891011121314151617181920#一般定义于/etc/httpd/conf.d下单独文件&lt;VirtualHost IP_ADDR:PORT&gt; ServerName FQDN DocunmentRoot \"\"&lt;/VirtualHost&gt;#在2.2中需要加一个命令NameVirtualHost IP:PORT#举例#在/etc/httpd/conf.d/下定义一个模块&lt;VirtualHost 192.168.163.131:80&gt; ServerName www.frdqy.io DocumentRoot \"/data/web/frdqy\" &lt;Directory \"/data/web/frdqy\"&gt; options None AllowOverride None Require all granted &lt;/Directory&gt; CustomLog \"log/frdqy_access_log\" combined&lt;/VirtualHost&gt; 压缩资源1234567891011121314#defalte_module，定义于/etc/httpd/conf.d/compress.conf#设置过滤器，只压缩文本格式文件SetOutputFilter DEFLATE#限制压缩格式AddOutputFilterByType DEFLATE text/plainAddOutputFilterByType DEFLATE text/htmlAddOutputFilterByType DEFLATE text/xmlAddOutputFilterByType DEFLATE text/cssAddOutputFilterByType DEFLATE text/javascriptAddOutputFilterByType DEFLATE application/xhtml+xmlAddOutputFilterByType DEFLATE application/xmlAddOutputFilterByType DEFLATE application/x-javascript#设置压缩等级DeflateCompressionLevel 9 支持https配置12345678910#为服务器申请数字证书：创建私有CA、为服务器创建证书签署请求、CA签署#配置httpd支持使用ssl，及使用的证书。需要在配置文件/etc/httpd/conf.d/ssl.conf中配置DocumentRootServerName#CA证书存放路径SSLCertificateFile#私钥存放路径SSLCertificateKeyFile 压力测试ab，webbench，http_load，seige，loadrunner，jmeter，tcpcopy 1234ab [options] URL -n num：总请求数 -c num：模拟的并行数 -k num：以持久连接模式测试","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"}],"author":"Frdqy"},{"title":"DNS和bind详解","slug":"DNS和bind详解","date":"2020-01-08T12:46:38.000Z","updated":"2020-01-08T12:47:42.342Z","comments":true,"path":"2020/01/08/DNS和bind详解/","link":"","permalink":"http://yoursite.com/2020/01/08/DNS%E5%92%8Cbind%E8%AF%A6%E8%A7%A3/","excerpt":"概念Domain name service，基于C/S架构，使用udp53端口与tcp53端口，其中udp实现解析，tcp实现区域传送。","text":"概念Domain name service，基于C/S架构，使用udp53端口与tcp53端口，其中udp实现解析，tcp实现区域传送。 网址：FQDN(Full Qualified Domain Name) 顶级域名：.com、.net、.org、.gov、.edu、mail 国家或地区域：.lq、.tw、.cn、.hk等 二级域：自己定义的独一无二的字符串 hosts文件：dns解析时首先匹配本地的这个文件，如果有条目匹配则直接访问。 dns缓存：本地内存中缓存了最近的名称解析结果，但是结果有效性有期限，这个期限由服务器提供。 查询类型递归：本地主机向本地DNS服务器查询是递归 迭代：本地DNS服务器向根查询是迭代 解析类型名称-&gt;IP叫做正向解析 IP-&gt;名称叫做反向解析 注意：二者的名称空间不同，即解析不是遵循同一颗树。 正向解析时，例如解析www.frdqy.top，解析树的根为“.”，其次为top，然后是frdqy，最后为www。 反向解析时，例如解析1.2.3.4时，解析树的根为“in-addr.arpa”，其次为1，然后是2，依次往下。可见ip地址与访问的ip地址在解析树中是相反的。 DNS服务器负责解析至少一个域：主DNS服务器、副DNS服务器(用于主服务器挂了顶上去) 不负责域解析：缓存DNS服务器 主DNS服务器维护所负责解析的域数据库的服务器，读写操作都可以进行。 从DNS服务器从主服务器那或其他从DNS服务器那同步一份数据库，但只能进行读操作。 主从同步配置序列号：数据库的版本号，主服务器数据库内容发生变化时，其版本号递增 刷新时间间隔：从服务器每隔多久到主服务器检查序列号更新状况 重试时间间隔：从服务器请求同步失败时再次发起同步请求的时间间隔 过期时长：从服务器联系不到主服务器时，多久后放弃同步数据，并本身停止服务 注意：主服务器数据发生改变时要主动通知从服务器进行更新，不需要等待刷新间隔 区域数据库文件资源记录记录类型：A、AAAA、PTR、SOA、NS、CNAME、MX等 SOA：起始授权记录，一个区域解析库只能有一个SOA记录，且必须放在第一条 NS：域名服务记录，一个区域解析库可以有多个NS记录，其中一个为主。 A：地址记录，用于主机名到IPV4地址的映射 AAAA：地址记录，用于主机名到IPV6地址的映射 CNAME：别名记录 PTR：实现反向解析，即IP到主机名的映射 MX：邮件交换器，可以有多个 定义格式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#IN是关键字，RR_TYPE是资源类型，VALUE是资源的值#name是指转换名称，例如正向解析就是主机名是名称，反向解析ip是名称语法：name [ttl] IN RR_TYPE VALUE#一个区域只能有一个SOA，且必须放在第一位SOA： name：当前区域的名字，正向是地址，反向是ip value：有多部份组成： 当前区域的区域名称(也可以使用主DNS服务器名称) 当前区域管理员的邮箱地址；不能使用@符号，用.替代 主从服务协调属性定义及否定答案的ttl 举例： www.frdqy.top 86400 IN SOA www.frdqy.top admin.frdqy.top( 01;serial 2H;refresh 10M;retry 1W;expire 1D;negative answer ttl ) #一个区域可以有多个NS记录NS： name：当前区域的名字 value：当前区域某DNS服务器的名字 举例： www.frdqy.top 86400 IN NS ns1.frdqy.top www.frdqy.top 86400 IN NS ns2.frdqy.top#可以有多个，名称后加数字，越小优先级越大#要多指明一个优先级MX： name：当前服务器的区域名称 value：当前区域邮件交换器的主机名 举例： www.frdqy.top IN MX 10 mx1.frdqy.top www.frdqy.top IN MX 20 mx2.frdqy.top #可以有多个。同一个主机可以有多个ip，同一个ip可以有多台主机A： name：某主机名 value：某IPV4地址 举例： www.frdqy.top IN A 1.2.3.4 www.frdqy.top IN A 1.2.2.4 web.frdqy.top IN A 1.2.3.4 #同上，用于IPV6地址AAAA： name：某主机名 value：某IPV6地址 #反向解析#注意ip地址特殊格式，ip要反过来写且加特定后缀#例如1.2.3.4的记录应写成4.3.2.1.in-addr.arpa.PTR： name：ip地址 value：主机名 举例： 4.3.2.1.in-addr.arpa. IN PTR www.frdqy.top #别名CNAME： name：主机名别名 value：主机名的正式名称 举例： web.frdqy.top IN CNAME www.frdqy.top #注意TTL可以从全局继承@可以表示当前区域的名称相邻的两条记录其name相同时，后面的name可以省略MX、NS等类型记录的VALUE为主机名，此主机名后应该有一个A记录 完整查询流程首先客户端根据输入的网址在本地文件hosts中查询是否有对应条目，如果有则直接访问。否则查询本地DNS缓存，如果缓存中有则直接访问。否则查询DNS服务器，DNS服务器拿到地址判断是否是自己的域，如果是则查询本地数据库将结果返回。否则在DNS服务器的本地缓存冲查询，如果有也将其返回。否则以迭代的方式向根、顶级域依次查询，最终将查询结果返回。 注意：由直接负责的DNS服务器返回的结果是权威结果，而由DNS服务器的缓存返回的结果是不权威结果。 BINDbind是dns协议的一种实现，它的守护进程名为named。bind安装完成后，默认即可做缓存名称服务器使用，即可以被别的主机指向来向根查询解析库结果。如果没有专门负责解析的区域可以直接启动服务。 程序rndc：远程控制器，监听953/tcp端口，但是一般默认监听于本地127.0.0.1地址，仅允许本地使用 bind-libs：被bind和bind-utils包中的程序共同用到的库文件 bind-utils：bind客户端程序集，如dig，host bind：提供dns server程序、几个常用的测试程序 bind-chroot：选装，让named运行于jail模式下，解决安全问题 配置文件主配置文件保存在/etc/named.conf，它包含其他文件/etc/named.rfc1912.zones、/etc/named.root.key 12345678910111213#named.conf#注意默认全局监听在127.0.0.1上，需要手动改成可与外界通信的地址，或者直接去掉地址表示本机所有地址。#每条语句必须以分号结尾#dnssec默认开启，可能会影响解析过程，需要手动设置no(学习时)#named-check命令可以帮助检查配置文件是否有语法错误[root@localhost named]# named-checknamed-checkconf named-checkzone全局配置段options日志配置段logging区域配置段zone 解析库文件/var/named目录下，一般名字为ZONE_NAME.zone 注意：一台服务器可为多个服务器提供解析、必须要有根区域解析库文件(named.ca)、还应该有两个区域解析库文件：localhost和127.0.0.1的正反向解析(正向为named.localhost，反向为named.loopback) 测试工具dig用于测试DNS服务，不使用本地hosts文件 12345678910111213dig [option] name [@SERVER] [query options] -t RR_TYPE：指明记录类型 @SERVER：通过服务器检测 [query option] +[no]trace：跟踪解析过程 +[no]recurse：进行递归解析 #正向解析dig -t A www.baidu.com#反向解析dig -x 185.199.109.153#手动区域传送dig -t axfr DOMAIN [@SERVER] host123host [option] name [@SERVER] -t RR_TYPE：指明记录类型 @SERVER：使用指定服务器测试 nslookup123456nslookup [option] [name] [server]#交互模式nslookup&gt;server IP：以指定的IP为DNS服务器进行查询&gt;set q=RR_TYPE：要查询的资源记录类型&gt;name：要查询的名称 rndcnamed服务控制命令 123456#查看日志rndc status#刷新缓存rndc flush#重载配置文件或指定的zonerndc reload [zone] 配置正向解析以frdqy.top为例 定义区域1234567891011121314#在主配置文件中实现/etc/named.conf#master：主区域；slave：从服务器；hint：根服务器；forward：转发服务器#file：区域数据文件，默认为相对路径/var/named下#ZONE_NAME即为域名zone \"ZONE_NAME\" IN &#123; type &#123;MASTER|SLAVE|HINT|FORWARD&#125;; file \"ZONE_NAME.zone\";&#125;;#举例(配置在/etc/named.rfc1912.zones中，它被/etc/named.conf包含)#区域名为：frdqy.top.zone \"frdqy.top\" IN &#123; type master; file \"frdqy.top.zone\";&#125; 定义区域解析库文件在/var/named/目录下建立区域配置文件frdqy.top.zone。注意要修改权限的属组。 1234567891011121314151617181920212223242526272829#主要配置A记录#区域名称可以使用@替代，即frdqy.top.可以由@替换#ORIGIN宏会自动添加在没有完全定义字段名后面$TTL 3600$ORIGIN frdqy.top.@ IN SOA ns1.frdqy.top. dnsadmin.frdqy.top. ( 2020010801 1H 10M 3D 1D ) IN NS ns1 IN MX 10 mx1 IN MX 20 mx2ns1 IN A 192.168.163.131mx1 IN A 192.168.163.3mx2 IN A 192.168.163.4www IN A 192.168.163.2web IN CNAME wwwbbs IN A 192.168.163.9bbs IN A 192.168.163.9#修改权限chgrp named /var/named/frdqy.top.zonechmod o= /var/named/frdqy.top.zone#检查语法错误named-checkconfnamed-checkzone frdqy.top. /var/named/frdqy.top.zone 服务器重载123rndc reload或systemctl reload named.service 配置反向解析定义区域1234567891011121314#在主配置文件中实现/etc/named.conf#master：主区域；slave：从服务器；hint：根服务器；forward：转发服务器#file：区域数据文件，默认为相对路径/var/named下#ZONE_NAME为反向区域的名字，即反写的网段地址.in-addr.arpazone \"ZONE_NAME\" IN &#123; type &#123;MASTER|SLAVE|HINT|FORWARD&#125;; file \"ZONE_NAME.zone\";&#125;;#举例zone \"168.192.in-addr.arpa\"&#123; type master; file \"192.168.zone\";&#125;; 定义区域解析库文件12345678910111213141516171819202122#主要配置PTR记录$TTL 3600$ORIGIN 168.192.in-addr.arpa.@ IN SOA ns1.frdqy.top. dnsadmin.frdqy.top. ( 2020010801 1H 10M 3D 1D ) IN NS ns1.frdqy.top.2.163 IN PTR ns1.frdqy.top.3.163 IN PTR mx1.frdqy.top.4.163 IN PTR mx2.frdqy.top.#修改权限chgrp named /var/named/192.168.zonechmod o= /var/named/192.168.zone#检查语法错误#第一个参数是区域名，和/etc/named.conf中zone定义的一样named-checkzone 168.192.in-addr.arpa /var/named/192.168.zonenamed-checkconf 服务器重载123rndc reload或systemctl reload named.service 主从服务器配置从服务器是针对主服务器的某个区域来配置的，即若主服务器有多个区域的解析，从服务器一般只同步一个区域。当然，也可以全部同步。因此，一台服务器既可以当主也可以同时当从(理解主从是针对区域的概念)。并且从服务器可以级联配置，即从服务器可以从另一台从服务器来同步区域数据。 从定义从区域1234567891011#type为类型#file为slaves目录下的解析库文件#master指明主服务器的ip地址，有多个需要用“;”分离#不需要写解析文件，直接reload即可同步zone \"ZONE_NAME\" IN&#123; type slave; file \"slaves/ZONE_NAME.zone\" masters &#123; MASTER_IP1;MASTER_IP2; &#125;&#125;#配置文件语法检查named-checkfoncig 重载配置文件123rndc reload或systemctl reload named.service 主确保区域文件中为每个从服务器配置了 NS记录，且正向解析的文件中每个服务器的NS记录都需要配置一个A记录，A记录的地址为真正服务器的地址。然后重载配置文件即可。 子域授权正向解析授权在/var/named/区域解析配置中添加一条NS记录以及对应的A记录即可 123#在frdqy.top.域上对ops.frdqy.top子域授权ops.frdqy.top IN NS ns1.ops.frdqy.topns1.ops.frdqy.top IN A IP 定义转发域转发域分为区域转发和全局转发。被转发服务器必须允许为当前服务做递归。 区域转发仅转发对某特定区域的解析请求 1234567#first：首先转发，转发器不响应就迭代查询#only：只转发，不响应则等待zone \"ZONE_NAME\" IN &#123; tyep forward; forward &#123; first|only &#125;; forwarders &#123; SERVER_IP; &#125;;&#125; 全局转发本地没有通过zone定义的区域请求全部转发给/etc/named.conf指定的转发器 1234567#在/etc/named.conf的option字段中添加option&#123; ... forward &#123;only|first&#125;; forwarders &#123;SERVER_IP;&#125;; ...&#125;; 安全相关设置acl访问控制链表。把一个或多个地址归并一个命名的集合，随后通过此名称即可对此集合内的所有主机实现统一调用。在配置文件中定义acl后需要配合访问控制指令在zone或者全局配置文件中使用。 12345678910111213141516#只能放在option之前acl acl_name&#123; ip; net/prelen;&#125;#举例，表示整个网络的主机都可以acl myacl&#123; 192.168.0.0/16; 127.0.0.0/8;&#125;;#举例，表示主机132受到控制acl slaves&#123; 192.168.163.132; 127.0.0.1;&#125; 内置aclnone：没有一个主机 any：任意一个主机 local：本机 localnet：本机所在的ip网络 访问控制指令1234allow-query&#123;&#125;;允许查询的主机allow-transfer&#123;&#125;;允许向哪些主机做区域传送(应该设置为只向从服务器传送)allow-recursion&#123;&#125;;允许哪些主机进行递归查询allow-update&#123;&#125;;允许动态更新区域解析库的文件(一般设置为none，不允许任何更新) 视图bind视图即view是主要用来实现只能dns，即实现不同的用户解析到不同的ip上。 1234567891011121314151617181920212223242526272829#定义view VIEW_NAME&#123; match-clients &#123; IP; &#125;; zone ZONE_NAEM_1 IN &#123; type; file; &#125;; zone ZONE_NAEM_2 IN &#123; type; file; &#125;;&#125;;#举例，同一个zone要定义在不同的view实现智能解析view internal &#123; match-clients &#123; 192.168.163.0/24; &#125;; zone \"frdqy.top\" IN &#123; type master; file \"frdqy.top/internal\" &#125;; &#125;;#all要放在最后，精确匹配的放在前面view external &#123; match-clients &#123; all; &#125;; zone \"frdqy.top\" IN &#123; type master; file \"frdqy.top/external\"; &#125;;&#125;;","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"dns","slug":"dns","permalink":"http://yoursite.com/tags/dns/"},{"name":"bind","slug":"bind","permalink":"http://yoursite.com/tags/bind/"},{"name":"dig","slug":"dig","permalink":"http://yoursite.com/tags/dig/"}],"author":"Frdqy"},{"title":"运维安全基础","slug":"运维安全基础","date":"2020-01-07T12:37:54.000Z","updated":"2020-01-17T10:13:53.335Z","comments":true,"path":"2020/01/07/运维安全基础/","link":"","permalink":"http://yoursite.com/2020/01/07/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/","excerpt":"加密算法和协议概要单向加密只能加密不能解密，用于特征码的制作，即验证数据完整性。","text":"加密算法和协议概要单向加密只能加密不能解密，用于特征码的制作，即验证数据完整性。 特性 定长输出 有雪崩效应，即小小的改动可以引起很大变化 常用算法md5：消息摘要算法，128位定长输出 sha1：安全hash算法，160位定长输出 对称加密主要有DES、AES、Blowfish、IDEA、RC6等加密方式 特性 加密解密使用同一密钥 将原始数据分割成为固定大小的块，逐个进行加密 缺陷 密钥过多 密钥分发困难 公钥加密密钥分为公钥与私钥，用公钥加密的数据只能使用与之配对的私钥进行解密 公钥：从私钥中提取产生，可公开给所有人，称为pubkey 私钥：通过工具创建，使用者自己留存，必须保证其私密性，称为secret key 用途数字签名：主要在于让接收方确认发送方的身份 密钥交换：发送方用对方公钥加密一个对称密钥，并发送给对方 数据加密 常用算法RSA、DSA(数字签名算法) 密钥交换公钥加密、DH算法。很少使用公钥加密实现密钥交换，因此下面只说DH算法实现的密钥交换。 背景：假设A，B，C三个人，A与B需要正常通信，C监听A与B的通信，现在需要A与B进行密钥的交换。 首先，A选择两个大素数假设为p，g，将这两个数明文发给B，此时C也收到这两个数。然后，A自己生成一个数x，将p^x%g的结果发送给B；同样，B也生成一个数y。将p^y%g的结果发送给A，此时C也可以获得这个结果，但是在有限时间内无法求出x或者y。最后，A将拿到的结果^x，B将拿到的结果^y，此时两个结果是一样的。因此这就实现了密钥交换，而此时C无法算出x和y，因此无法知道真正的密钥。 加密解密通讯过程加密过程背景：假设3个人：A，B，C。其中A与B想要通信，而C想要监听A与B的通信。(假设A发送给B数据) 首先，A将待发送的数据使用单向加密算法提取出特征码；然后A使用自己的私钥将特征码加密附加在数据后面；接着，A生成一个临时的对称密钥来加密整段数据(待发送数据和加密后的特征码)；然后，A使用B的公钥加密临时的对称密钥，并附加在整段数据后面；最后发送给B。 解密过程B拿到数据后首先使用自己的私钥来解密加密的对称密钥；然后使用对称密钥解密整段数据(真实数据和加密后的特征码)；接着使用A的公钥解密特征码(验证A的身份)；最后使用单向加密算法加密数据得到特征码与之比较，相同则数据完整性得到验证。 存在问题加密与解密过程都需要拿到对面的公钥，因此如果没有第三方可靠机构来提供公钥的验证，那么可能发生中间人攻击。即A想要B的公钥时，C表示我就是B然后把自己的公钥发送给A，接着向B表示自己是A，同时获取B的公钥与提供自己的私钥，这样AB认为自己可以正常通信，其实通信过程都经过C，这就是中间人攻击。 解决问题为了解决上述问题提出了CA的概念，即证书颁发机构。它保证通信双方能够安全的拿到对方的公钥，是一个双方都公信的第三方可信机构。 具体实现是CA首先自己给自己颁发一个证书，这个证书不通过网络传输，而是面对面交付给对方，里面包含CA机构的公钥。然后各个机构会像CA申请注册证书，里面包括该机构的公钥及有效期等信息。CA经过实地考察后没问问题会颁发电子证书给各个机构(有CA公钥可以解密CA证书)，这样当双方通信需要对方公钥时，双方通过交换证书来获得公钥(要验证证书是否有效，名称是否正确等)，从而避免假公钥的问题。 openssl开源实现ssl协议的程序 通信流程背景：A为通信客户端，B为通信服务端 首先A生成一组随机数RNC，发送client_hello信息将RNC发送给B，B也生成一组随机数RNS，发送server_hello将RNS发送给A。这个过程中双方协商使用什么加密方法进行通信(仅仅协商方法，不涉及具体密钥)。 然后，B将自己的证书发送给A，且请求A的证书；A得到证书后会检查证书有效期等信息，没问题则将自己的证书发给B，B也会检查相关信息。接着A将此前发送的所有信息使用hash签名后用自己私钥加密发给B端，B端用A公钥(从交换的证书中获得)解密后验证hash完整性，没有问题则继续进行后续通信。 上述过程如果没有问题，即最后的hash验证没有问题，则进入下面阶段。 首先A生成一个随机的密钥PMS，且使用对方的公钥加密发送给对方，这样，双方都拥有PMS、RNS、RNC，进行相同计算后即是双方通信时所需要的最终密钥。最后双方可以基于这个密钥进行通信。 组成部分libencrypt库，主要实现加密解密功能，由开发者使用 libssl库，主要实现ssl功能 openssl，是多用途命令行工具 openssl命令123456openssl [optino] help：查看帮助 version：查看版本信息 enc：对称加密相关 dgst：单向加密相关 ca：生成ca相关 对称加密1234567891011openssl enc [option] file -e：加密 -des3：指明使用des加密 -d：解密 -a：编码为base64编码格式 -salt：加杂质信息 -in file：指明要加密的文件 -out file：指明加密后生成的文件#举例openssl enc -e -des3 -a -salt -in ./fstab -out ./fstab.encopenssl enc -d -des3 -a -salt -in ./fstab.enc -out ./fstab 单向加密12openssl dgst [option] file -md5：使用md5加密 生成用户密码12openssl passwd -1 -salt 12345#-1表示基于md5算法 生成随机数1234openssl rand [option] number_length -base64：使用base64编码 -hex：使用16进制编码#常用于生成salt 公钥加密主要包括RSA，DSA、DH等 123456789#生成密钥(私钥)，保存至path目录下openssl genrsa -out path length_num#生成私钥且只能自己可读密钥保存至tmp目录下，密钥长度为2048(必须是2的次方)#注意，使用括号括起来是为了使其在子shell中运行而不影响当前shell的umask权限(umask 077; openssl genrsa -out /tmp/mykey 2048)#提取公钥openssl rsa -in /tmp/mykey -puout Linux随机数生成器1234567/dev/random：仅从熵池中返回随机数，熵池用尽则阻塞进程/dev/urandom：从熵池中返回随机数，随机数用尽会利用软件生成伪随机数(不安全)熵池：内存中存储随机数的空间熵池随机数来源： 硬盘io中断时间间隔 键盘io中断时间间隔 建立私有CA可以使用openssl命令建立CA，也可以使用OpenCA软件。这里只讲openssl命令 配置文件：/etc/pki/tls/openssl.cnf 生成私钥12#根据上述配置文件的描述放到规定目录下，命名要规范(umask 077; openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096) 生成自签证书123456#-new表示生成新证书签署请求；#-x509表示自签证书；#-key指明密钥路径(会自动从私钥中抽取公钥)#-out指明生成路径#-days指明有效期限，默认365天openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 创建目录及文件1234mkdir /etc/pki/CA/&#123;certs,crl,newcerts&#125;touch /etc/pki/CA/&#123;serial,index.txt&#125;#给明第一个证书的序列号echo 01 &gt; /etc/pki/CA/serial 请求签署CA以httpd为例 申请的主机生成私钥1234#在服务的目录下创建ssl目录mkdir /etc/httpd/ssl ; cd /etc/httpd/ssl#生成私钥(umask 077; openssl genrsa -out httpd.key 4096) 生成请求命令1openssl req -new -key httpd.key -out httpd.csr -days 365 请求传送给主机略，一般直接硬盘拷走 在CA主机上签署证书1openssl ca -in /tmp/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365 查看证书签署信息12#查看证书签署的subject信息openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -subject 吊销CA首先客户端获取要吊销的serial 1openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -serial -subject 其次，CA主机ijnx吊销操作 12openssl ca -revoke /etc/pki/CA/newcerts/serial.pem#其中serial为对应要吊销的序列号 最后生成吊销编号(只在第一次吊销时执行) 1echo 01 /etc/pki/CA/crinumber 更新证书吊销列表 1234openssl ca -gencrl -out thisca.crl#查看crl文件openssl crl -in /path/xxx.crl -noout -text","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"openssl","slug":"openssl","permalink":"http://yoursite.com/tags/openssl/"},{"name":"安全基础","slug":"安全基础","permalink":"http://yoursite.com/tags/%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/"}],"author":"Frdqy"},{"title":"SELinux简介","slug":"SELinux简介","date":"2020-01-06T13:11:45.000Z","updated":"2020-01-06T13:12:33.201Z","comments":true,"path":"2020/01/06/SELinux简介/","link":"","permalink":"http://yoursite.com/2020/01/06/SELinux%E7%AE%80%E4%BB%8B/","excerpt":"概念增强型的Linux系统。","text":"概念增强型的Linux系统。 普通的linux使用DAC(自由访问控制)机制来管理用户权限，DAC对进程没有束缚，即进程拥有该进程的发起者的权限，这是很危险的，如果被别人提权，那么别人也就拥有了该用户的权限。 SELinux采用了MAC(强制访问控制)来解决上述问题。它规定了进程的权限是有限的，即使进程发起者有其他的权限，但是由其启动的进程只有发起时所规定的权限。 因此，在开启了SELinux的系统中，进程的权限不仅受到属组和属主的限制，还受到MAC的限制，可以理解为类似沙箱的环境，即使进程的发起者拥有访问沙箱外的权限，沙箱内的进程也无法访问沙箱外的空间。 工作模式strict每个进程都受到SELinux的控制 targeted仅有限个进程受到SELinux控制 SELinux状态enforcing强制，每个受限的进程都必然受限(因为工作模式处于targeted时并不是每个程序都受到限制，因此存在不受限的程序)。 permissive启用，每个受限的进程违规操作不会被禁止，但会被记录到日志中 disabled禁用 1234567#获取当前SELinux状态getenforce#设置当前SELinux状态，仅当前有效#永久有效需要修改/etc/sysconfig/selinuxsetenforce 0|1 0：设置为permissive状态 1：设置为enforcing状态 安全上下文SELinux为每个进程提供的安全标签，其标签为user:role:type:sensitivity:category。但是有用的主要是第三段。用于定义不同的权限范围，类似定义不同的沙箱。另外，某一目录下的文件默认拥有该文件的类型，即tmp目录内的文件类型为tmp***等等。 12345678910111213141516[root@localhost ~]@ ls -Z system_u:object_r:admin_home_t:s0 anaconda-ks.cfg system_u:object_r:admin_home_t:s0 anaconda-ks.cfg_bakunconfined_u:object_r:admin_home_t:s0 anaconda-ks.cfg_symbolic system_u:object_r:admin_home_t:s0 initial-setup-ks.cfgunconfined_u:object_r:admin_home_t:s0 testunconfined_u:object_r:admin_home_t:s0 test_symbolic#修改安全上下文chcon [option] file -t type_name：修改指定标签 -R：递归打标签 #还原默认安全上下文restorecon file -R：递归还原 SELinux规则库定义了处于哪些type域的进程可以访问哪些type文件。 此时访问流程变为：当进程发起文件访问时，首先检查进程的属主和属组是否可以访问，其次检查SELinux规则库内定义的该进程的域是否能够访问该类型的文件(读/写)，若失败则拒绝访问并记录到日志中。 布尔型规则一个程序运行时有多种功能，比如文件上传和下载功能。不同的功能的权限和危险程度也是不同的，因此SELinux可以实现将程序的功能设定为开启或关闭，这就是布尔型规则。 123456789101112#显示当前系统的所有SELinux的布尔型状态[root@localhost ~]@ getsebool -aabrt_anon_write --&gt; offabrt_handle_event --&gt; offabrt_upload_watch_anon_write --&gt; on#得到布尔型标签getsebool [option] file -a：显示所有#设置布尔型标签setsebool [option] file -P：写入配置文件中，永久有效 日志文件12345#注意，并不是所有日志都是文本文件[root@localhost ~]@ ls /var/log/audit/audit.log /var/log/audit/audit.log[root@localhost ~]@ file /var/log/audit/audit.log/var/log/audit/audit.log: data","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"SELinux","slug":"SELinux","permalink":"http://yoursite.com/tags/SELinux/"}],"author":"Frdqy"},{"title":"内核管理","slug":"内核管理","date":"2020-01-06T13:11:17.000Z","updated":"2020-01-06T13:13:40.989Z","comments":true,"path":"2020/01/06/内核管理/","link":"","permalink":"http://yoursite.com/2020/01/06/%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86/","excerpt":"内核特点 支持模块化。各模块以.ko结尾(kernel object) 支持模块运行时动态装载或卸载 单内核设计，却借鉴了微内核模块化机制的特点","text":"内核特点 支持模块化。各模块以.ko结尾(kernel object) 支持模块运行时动态装载或卸载 单内核设计，却借鉴了微内核模块化机制的特点 组成部分核心文件保存在/boot/下，名称为vmlinuz-VERSION-release 123456789101112ls /boot/config-4.18.0-80.el8.x86_64efigrub2initramfs-0-rescue-75fbe50f6f2b4dbfae8dc77fbbd4d906.imginitramfs-4.18.0-80.el8.x86_64.imginitramfs-4.18.0-80.el8.x86_64kdump.imgloaderlost+foundSystem.map-4.18.0-80.el8.x86_64vmlinuz-0-rescue-75fbe50f6f2b4dbfae8dc77fbbd4d906vmlinuz-4.18.0-80.el8.x86_64 模块文件保存在/lib/modules/下，名称为VERSION-release 123#ls /lib/modules/4.18.0-79.el8+2.x86_64 4.18.0-80.el8.x86_64 ramdisk内核的辅助性文件，本质是一个简装本的根文件系统，不是必须的文件，如果内核能直接驱动rootfs那么就不需要此文件。它可以加载目标设备驱动、逻辑设备驱动、文件系统驱动 存放在/boot/目录下叫做initramfs-VERSION.img 在centos6上叫做initrd，在centos7上叫做initramfs，可以通过dracut工具创建。 基于内存的磁盘设备，在内存区域模拟一个硬盘空间。当系统启动时，内核需要加载根文件系统，而根文件系统放在磁盘上，那么内核需要有该磁盘的相应驱动程序才可以读磁盘从而获取根文件系统，但是驱动程序都保存在文件系统中，这就成了一个死循环。因此设置了一个ramdisk，作为一个临时根文件系统，他是在安装操作系统时通过扫描本地磁盘接口从而获取相应的驱动程序放在内存中即ramdisk中，那么当内核需要读取根文件系统时就可以先把ramdisk当作根，然后通过其内的驱动来读取磁盘中的根文件系统，此时再把ramdisk的根切换到真正的根文件系统中，这样就完成了内核加载根的过程。 12345#自行创建initrd.imgdracut [option] initrd-image kernel-name --with=&lt;module&gt;：需要额外装载的模块#例如dracut /boot/initramfs-$(uname -r).img $(uname -r) 重要内核参数net.ipv4.ip_forward：核心转发(即同主机不同网卡之间的转发) vm.drop_caches：缓存丢弃，即关闭缓存 kernel.hostname：主机名 net.ipv4.icmp_echo_ignore_all：忽略所有ping操作 伪文件系统proc123456789内核状态和统计信息的输出接口；同时提供了配置接口&#x2F;proc&#x2F;sys 只读：&#x2F;proc&#x2F;@&#x2F;@ 可写：&#x2F;proc&#x2F;sys&#x2F;可接收用户指定的值来修改内核 修改： sysctl [option] name -a：显示所有可修改的值&#x2F;proc&#x2F;sys&#x2F;目录下的参数值 -w name&#x3D;value：修改某值 -p cfg_path：立即生效配置文件在&#x2F;etc&#x2F;sysctl.d&#x2F;*.conf，修改后可永久有效 sys1234567用于输出内核识别出的各硬件相关属性信息，也有内核对硬件特性的可设置参数，可定制硬件工作特性udev：通过读取&#x2F;sys目录下的硬件设备信息创建对应的硬件设备文件，方便管理配置文件一般在&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;目录以及&#x2F;usr&#x2F;lib&#x2F;udev&#x2F;rules.d&#x2F;#例子&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;70-persistent-ipoib.rules保存了网卡硬件信息，如果有多块网卡想交换则修改这里同时还要修改&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;下的网卡信息要想上述更改生效需要使用modprobe -r卸载在装载模块 内核相关命令编译选择符号123[ ]：不要此模块[M]：编译成内核模块，用到时再装载[*]：直接编译进内核核心 内核信息获取uname123456#显示系统信息uname [option] -r：显示内核的release号 -n：显示主机名，即hostname -v：显示编译版本号 -a：显示所有信息 lsmod12#显示内核状态，内容来自/proc/moduleslsmod modinfo12345#显示单个模块信息modinfo name -k：指明内核(适用多内核) -F field：显示指定字段 -n：显示文件路径 内核模块管理modprobe1234#实现模块的动态装载和卸载，不加选项则安装指定模块#正在使用的模块不要随意卸载modprobe [option] name -r：卸载模块 depmod12#生成依赖关系depmod [option] name insmod123#安装指定模块，但是无法解决依赖关系#filename必须是具体模块路径，可使用modinfo -n module_nameinsmod [option] filename rmmod12#删除指定模块rmmod module_name 内核编译开发环境Centos6/7：Development tools、server platform development、ncurses相关包 硬件信息cpu123#查看cpu信息，主要看平台型号即可cat /proc/infolscpu pci123456#查看pci信息lscpi#查看sub信息lsusb#查看硬盘设备lsblk 编译 下载内核并解压到/usr/source/kernel目录下，并创建连接对其操作 使用make menuconfig进入图形界面设置内核模块 make编译、make modules_install、make install 123456#进行内核编译时建议使用screen运行，防止终端断开导致内核编译失败打开：screen拆除：ctrl+a，d列出：screen -ls连接：screen -r screen_id关闭：exit 配置文件红帽系列的内核编译配置文件一般在/boot/config-4.18.0-80.el8.x86_64文件，里面列出了当前内核编译时的一些选项。非红帽发行版可能在/proc/config.gz内有配置文件。 编译前需要将上述这个模板复制过来，然后使用make menuconfig在其基础上进行修改即可。 进行编译多线程编译：make -j 指定cpu核心数 只对内核某个模块进行编译：切换到/usr/src/kernel对应模块目录下，使用make file_name.ko进行编译，注意.ko的文件必须是一个已有的.c文件。最后将其放到/lib/modules/release-name/kernel/下的对应目录中即可 内核清理用于对执行过编译操作的内核源码树进行重新编译 123456#清理绝大多数文件，但保存configmake clean#清理所有文件make mrproper#相当于mrproper，额外清理patches和编辑器备份文件make distclean 模块安装1make modules_install","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"内核管理","slug":"内核管理","permalink":"http://yoursite.com/tags/%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86/"}],"author":"Frdqy"},{"title":"系统启动流程","slug":"系统启动流程","date":"2020-01-06T13:10:42.000Z","updated":"2020-01-06T13:13:04.263Z","comments":true,"path":"2020/01/06/系统启动流程/","link":"","permalink":"http://yoursite.com/2020/01/06/%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","excerpt":"POST带电自检，存储在ROM中，其中包括BIOS。","text":"POST带电自检，存储在ROM中，其中包括BIOS。 BOOT按次序查找各引导设备，第一个有引导程序的设备即为本次启动要用到的设备，引导程序叫做bootloader。在linux中叫做grub2。他主要是提供一个菜单，允许用户选择要启动的系统或不同的内核版本，把其装载到RAM中解压并展开，之后把系统执行权限移交给内核。 由于MBR的bootloader只允许446字节，远不够bootloader的编写。因此grub分成三段，第一段就位于bootloader中；第二段位于mbr之后的扇区中，用于让第一段的程序能够识别grub真正程序所在的文件系统；第三段位于/boot/grub目录下，提供真正能编辑的界面。配置文件在/boot/grub/grub.conf中。 这里提一个注意点，就是grub是如何识别不同设备的，也就是说grub是如何找到/boot/grub/下的grub配置文件的。这里分两种情况讨论。 第一种情况是boot单独分区，那么访问grub的配置文件时就不需要通过根文件系统来访问，即不需要/boot/grub/grub.conf来访问，而是通过grub的root命令将根设定为boot分区即可，这样访问就通过/grub/grub.conf即可。这种情形通常出现在根文件系统比较复杂或需要LVM支持，而boot只能放在基本磁盘上分区，因此将boot单独分区即可。 第二种情况是将boot放在/下，不进行单独分区，这样就需要通过根文件系统来访问，即/boot/grub/grub.conf，这样根文件系统就不能做成LVM形式，只能是基本磁盘分区。 分区命名12hd(@,@)#第一个@表示磁盘编号，第二个@表示分区编号，从0开始编号 第二阶段 提供菜单，并提供交互式接口 e：编辑模式 c：命令模式，交互式接口 123456help：显示帮助信息root (hd@,@)：把指定磁盘分区设定为根设备find (hd@,@)/path：查找指定磁盘上的文件，如果有的话会自动补齐kernel /path：指明内核程序的位置用于本次内核启动initrd /path：指明内核的额外帮助文件即ramdisk，版本号要匹配boot：引导启动内核 加载用户选择的内核或操作系统，允许传递特定参数，允许隐藏菜单 为菜单设置密码提供保护措施 配置文件grub2的配置文件在/boot/grub2/grub.cfg文件中，他依次调用/etc/grub.d目录下的配置文件来执行，还有一个配置文件在/etc/default/grub文件中。 1234567891011121314#修改启动等待时间需要修改/etc/default/grub文件中的GRUB_TIMEOUT选项#为grub加密，即需要密码才能修改grub启动以及编辑参数在/etc/grub.d/00_header 文件末尾添加如下内容set superusers='admin'password admin frdqy#设置加密的密码，使用grub2-mkpasswd-pbkdf2[root@localhost default]@ grub2-mkpasswd-pbkdf2 Enter password: Reenter password: PBKDF2 hash of your password is grub.pbkdf2.sha512.10000.9C469331A01C52D45794B9C812DEEA6D35DC876677D5552AE4AB7DA775C6FAAF495237DCB6E093F48CAFB42F259C4F0E15BE21AE1B146663B25135D605051795.08CEB5DDF92884E1239FBCF5C003BABCBD4FE11B73DF1557ECE31D028927F05AD013F5138B5E85A84A1E29EF51480837B878E5868D0E55F9C97B8D86CB9662F8再按照上文加入password字段即可 登录模式登录模式主要主要有rescue、emergency、shell引导 rescue模式只要在commandline配置末尾加s即可，类似单用户模式，ctrl+x启动 emergency则直接将上面s替换为emergency即可，ctrl+x启动 实例忘记root密码12345首先，在内核一行后加“rd.break console=tty0”，然后ctrl+x启动其次，挂载文件系统：mount -o remount /sysroot/之后，切换根目录到sysroot：chroot /sysroot/最后使用passwd修改root密码即可#注意：可能有时需要在根下创建autorelabel，用于标记selinux环境 MBR引导丢失123即前446字节丢失需要挂载一个镜像来排错，用iso即可进入rescue后切换至源系统的根，然后找到启动分区(例如sda)，最后grub2-install /dev/sda即可 配置文件丢失1需要使用rpm的--force强制覆盖安装内核，之后再安装grub2到启动分区即可 KERNELCentos5自身初始化探测可识别到的所有硬件设备、加载硬件驱动程序(可能此时会借助于ramdisk加载驱动)、以只读方式挂载根文件系统、运行用户空间第一个应用程序/sbin/init。 注意：init它的配置文件在centos6中存放在/etc/init/目录中，他会读取/etc/init.d/*.conf配置文件；而在centos7中，配置文件在/etc/systemd/system中和/usr/lib/systemd/system目录中 运行级别为了系统的运行或维护等目的而设定的机制，包括0~6七个级别，默认一般为3或5级别。定义在/etc/inittab中。 1234567#级别切换init 数字#级别查看，第一个表示上次级别，第二个是当前级别runlevel N 5#也可以查看级别who -r 0：关机模式，shutdown 1：单用户模式，root用户，无需认证；维护模式 2：多用户模式，会启动网络功能，但不启动NFS；维护模式 3：多用户模式，完全功能模式；文本界面，正常模式 4：预留级别，目前无特别使用目的，但习惯以同3级别功能使用 5：多用户模式，完全功能模式，图形界面，有图像接口 6：重启模式，reboot 初始化脚本12#/etc/rc.d/sysinit，系统初始化脚本任务：设计主机名、设置欢迎信息、激活udev和selinux、挂载/etc/fstab所有文件系统、检测根文件系统、以读写方式重新挂载根文件系统、设置系统时钟、根据/etc/sysctl.conf文件设置内核参数、激活lvm和软raid设备、激活各swap设备、加载额外设备的驱动程序、清理一些多余文件 配置文件Centos5中init的配置文件，即所有运行脚本存放在/etc/init.d/目录中。 1234567891011121314151617181920212223#每行定义一个action与之对应的processid:runlevel:action:processid：一个任务的标识符runlevels：在哪些级别启动此任务，为空表示所有级别action：在什么条件下启动此任务 wait：等待切换至此任务执行级别时执行一次 respawn：此任务终止时就会重新启动一次 initdefault：设定默认允许级别，process此时被省略 sysinit：设定系统初始化方式，一般为指定/etc/rc.d/rc.sysinit脚本process：具体任务#管控每个服务脚本在各级别下的启动或关闭状态chkconfig [option] name --list：查看服务状态 --add：添加一个脚本 --del：删除一个脚本 --level LEVELs &#123;on|off|reset&#125;：修改级别，默认为2345 #/etc/rc.d/rc @在这个文件中放了不同运行级别所需要的不同服务连接，他们都是连接至/etc/init.d/目录内的服务，其中命名都以K或S开头加数字加服务名 K**：需要停止的服务，数字越小越先关闭 S**：需要开启的服务，数字越小越先开启注意这里有一个独特的脚本叫做rc.local，他是最后执行的脚本，当用户想每次开机执行一条命令时即可编辑此脚本，在里面直接加命令即可，不需要单独添加服务。 总结由/sbin/init脚本执行。 流程为：设置默认运行级别、运行系统初始化脚本(/etc/rc.d/sysinit)、关闭对应级别下需要停止的服务、启动对应级别下需要开启的服务(/etc/rc.d/rc @)、设置登录终端。 Centos6本质和Centos5仍然时一样的，只不过由于启动进程被换成了upstart(依然是/sbin/init)，其描述文件发生了变化。即配置文件都是/etc/init/*.conf结尾的配置文件，而/etc/inittab仅用于定义默认运行级别。其语法为upstart语法，但由于centos7以后就不用该语法，且centos7已经缓存systemd来启动了，因此此处不做过多介绍。 Centos7init程序：systemd 特性系统引导时实现服务并行启动；按需激活进程；系统状态快照；基于依赖关系定义服务控制逻辑 基于socket的激活机制：socket与程序分离 基于bus的激活机制：总线有对某个接口的请求时，激活该接口 基于device的激活机制：自动激活、挂载设备 基于path的激活机制：监控某一路径，可以对特定行为进行响应 系统快照：保存unit当前状态信息于持久存储设备中 向后兼容sysv init脚本：/etc/init.d/的脚本仍可以执行 新概念unit：所有的系统资源都称作unit。它统一了资源配置格式，而使用文件后缀名来区别不同类型的文件及服务。 配置文件：/usr/lib/systemd/system/*、/etc/systemd/system unit常见类型service unit：文件扩展名为.service，用于定义系统服务 target unit：文件扩展名为.target，用于模拟实现运行级别，由于Centos7上没有运行级别概念，但是为了兼容6，就定义了target来模拟不同的级别 123#获取当前用户级别[root@localhost init.d]# systemctl get-default graphical.target device unit：文件扩展名为.device，用于定义内核识别的设备 mount unit：文件扩展名为.mount，用于定义文件系统挂载点 socket unit：文件扩展名为.socket，用于进程间通信 snapshot unit：文件扩展名为.snapshot，管理系统快照 swap unit：文件扩展名为.swap，用于标识swap设备 automount unit：文件扩展名为.automount，文件系统自动挂载设备 path unit：文件扩展名为.path用于定义文件系统中的文件和目录 systemctl命令管理系统服务主要靠service类型的unit文件来实现控制 12345678910111213141516171819systemctl [option] COMMAND [NAME...] start：启动服务 stop：停止服务 restart：重启服务 status：显示状态 try-restart：条件式重启 reload-or-restart：重载或重启服务 reload-or-try-restart：重载或条件重启服务 daemon-reload：重读unit文件 is-adtive：查看是否激活 list-units：列出所有已激活的服务 --type/-t：指明类型 --all：显示所有选项 enable：设置服务开机自启 disable：设置服务禁止开机自启 is-enable：查询服务是否能开机自启 mask：禁止某服务设置为开机自启 unmask：取消禁止某服务开机自启 list-dependencies：查看服务的依赖关系 管理target 级别 含义 0 runlevel0.target；poweroff.target 1 runlevel1.tartget；rescue.target 2 runlevel2.tartget；multi-user.target 3 runlevel3.tartget；multi-user.target 4 runlevel4.tartget；multi-user.target 5 runlevel5.tartget；graphical.target 6 runlevel6.tartget；reboot.target 123456789101112131415#级别切换systemctl isolate NAME.target#查看级别systemctl list-units -t target#获取默认运行级别systemctl get-default#修改默认运行级别#修改运行级别实质是修改/etc/systemd/system/default.target的符号链接实现的#且定义在不同级别运行的服务也会在/etc/systemd/system/下对应的目录中创建符号链接，他们实际是/usr/lib/systemd/system/下对应unit的符号链接systemctl set-default NAME.target#切换紧急救援模式systemctl rescue#切换至紧急模式，不会装载额外系统驱动或者多余设置#拿Centos6来说，rescue模式还会执行sysinit初始化脚本，而emergency不会执行systemctl emergency 其他命令12345678910#关机systemctl halt；systemctl poweroff#重启systemctl reboot#挂起(睡眠)systemctl suspend#快照systemctl hibernate#快照并挂起(睡眠)systemctl hybird-sleep unit文件格式由三部分组成[unit]、[service]、[install] [unit]：定义与unit类型无关的信息。如描述信息和依赖关系 [service]：定义与特定类型相关的专用选项，各种类型均不一样 [install]：定义由enable和disable实现服务启动关闭时用到的选项 unit段常用选项description：描述信息 after：定义启动次序，表示当前unit晚于哪些unit requires：指明依赖到的其他unit，即依赖关系，要求比wants强，即必须全部启动 wants：指明依赖到的其他unit，即依赖关系，但即使不启动，本服务自身也能启动 conflicts：定义units之间的依赖关系 service段常用选项type：定义影响execstart及相关参数的功能的unit进程启动类型 类型有：simple：默认类型，表示为主进程 ​ forking：表示进程会生成一个主进程，自身会退出 ​ oneshot：一次性进程 ​ dbus：后续进程在主进程得到dbus后才能启动 ​ notify：后续进程在主进程发送notify后才能启动 ​ idle：类似于simple execstart：指明启动unit要运行的命令或脚本 execstop：停止unit要运行的命令或脚本 restart：进程意外退出后重启的命令或脚本 environmentfile：环境配置文件，在execstart前读取，为其提供变量 install段常用选项alias：当前程序别名 requiredby：被哪些unit所依赖，强依赖 wantedby：被那些unit所依赖，弱依赖 注意当修改或新建unit文件时，要通知systemd重载此配置文件 1systemctl daemon-reload","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"启动流程","slug":"启动流程","permalink":"http://yoursite.com/tags/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"name":"systemd","slug":"systemd","permalink":"http://yoursite.com/tags/systemd/"},{"name":"init","slug":"init","permalink":"http://yoursite.com/tags/init/"}],"author":"Frdqy"},{"title":"系统安装自动化","slug":"系统安装自动化","date":"2020-01-06T13:09:57.000Z","updated":"2020-01-22T12:14:33.166Z","comments":true,"path":"2020/01/06/系统安装自动化/","link":"","permalink":"http://yoursite.com/2020/01/06/%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E8%87%AA%E5%8A%A8%E5%8C%96/","excerpt":"总览电脑启动时，首先bootloader加载kernel，然后为了防止kernel不能识别硬盘，kernel首先使用ramdisk在内存中模拟一个根文件系统，这就不需要读取真正的磁盘，而且这个模拟文件系统有操作系统安装时需要的各种程序。之后，启动anaconda程序来完成系统安装，这个程序处在待安装系统的某个程序包下即可装载运行。","text":"总览电脑启动时，首先bootloader加载kernel，然后为了防止kernel不能识别硬盘，kernel首先使用ramdisk在内存中模拟一个根文件系统，这就不需要读取真正的磁盘，而且这个模拟文件系统有操作系统安装时需要的各种程序。之后，启动anaconda程序来完成系统安装，这个程序处在待安装系统的某个程序包下即可装载运行。 安装过程首先加载安装镜像中的boot.cat文件 其次执行isolinux/isolinux.bin，他的配置文件为同目录下的/isolinux.cfg 等待用户选择对应安装的内核，每个菜单项加载不同的内核，也在/isolinux/vmlinuz下，并且通过append向内核传递参数。 最后装载img根文件系统(即)，并启动anaconda。注意，后续的anaconda及其安装用到的程序包可以来自光盘及镜像自带的仓库，也可以手动指定仓库(http,ftp等)，手动指定时需要在boot命令(引导界面按ESC)下输入linux method即可。 安装引导选项引导选项可以将必要的直接添加在/isolinux/isolinux.cfg的对应条目下，就不需要手动输入了 1234567891011121314151617181920boot： text：文本安装方式 method：手动指定安装方式 与网络相关的引导选项： ip&#x3D;IPADDR netmask&#x3D;MASK gateway&#x3D;GW dns&#x3D;DNS_SERVER 远程访问功能： vnc vncpassword&#x3D;&#39;password&#39; 启动紧急救援： rescue 装载额外驱动程序： dd 指明kickstart的位置 ks&#x3D;cdrom:&#x2F;path ks&#x3D;http:&#x2F;&#x2F;host:port&#x2F;path ks&#x3D;ftp:&#x2F;&#x2F;host:post&#x2F;path ks&#x3D;https:&#x2F;&#x2F;host:port&#x2F;path 配置文件anaconda除了基本的交互式配置外，还支持通过读取配置文件中事先定义好的配置项自动完成配置；配置文件遵循特定的语法格式，此文件即为kickstart文件，该文件如果是系统第一次安装且需要自定义的话一般放在服务器上，因为放在光盘内的话不能编辑，然后安装时从服务器读取即可。 安装好的系统后配置文件在家目录下，为anaconda-ks.cfg。 文件格式命令段指定各种安装前配置选项，如键盘类型。由必备命令，可选命令组成。 必备命令authconfig：认证方式配置 bootloader：定义bootload安装位置 keyboard：设置键盘类型 lang：语言类型 part：分区布局 rootpw：管理员密码； 12#生成密码方式使用opensslopenssl passwd -1 -salt `openssl rand -hex 4` clearpart：清空磁盘分区 volgroup：创建卷组 logvol：创建逻辑卷 timezone：设置时区 其他命令install or upgrade：安装或升级 text：安装界面类型，text为tui，默认为gui network：配置网络接口 repo：指明仓库 url：指明仓库，优先级高于repo firewall：防火墙 selinux：SELinux 123456#关闭firewallsystemctl stop firewalld.servicesystemctl disable firewalld.service#关闭selinux编辑/etc/sysconfig/selinux文件，修改SELINUX值，不等于enforcing即可另外可以通过getenforce查看，如果是1或者是enforcing则使用setenforce 0设置即可 程序包段指明要安装的程序包以及包组，也包括不安装的程序包。以%packages开头，%end结尾 @group_name表示包组 package表示单个程序包 -package表示不安装程序包，但是为了解决依赖可能自动安装 脚本段%pre：安装前shell脚本 %post：安装后shell脚本 生成工具system-config-kickstart图形界面来配置kickstart配置文件 123456789#安装yum install system-config-kickstart#启动system-config-kickstart#检查语法错误ksvalidator#将isolinux目录复制到一个新的目录下，为myboot，然后把kickstart配置文件放在与目录同级位置#创建光盘镜像mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V \"Centos\" -c isolinux/boot.cat -b isolinux/isolinux.bin -o /root/boot.iso myboot/","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"自动化","slug":"自动化","permalink":"http://yoursite.com/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"anaconda","slug":"anaconda","permalink":"http://yoursite.com/tags/anaconda/"},{"name":"kickstart","slug":"kickstart","permalink":"http://yoursite.com/tags/kickstart/"}],"author":"Frdqy"},{"title":"进程管理","slug":"进程管理","date":"2020-01-05T05:44:15.000Z","updated":"2020-01-05T05:45:17.711Z","comments":true,"path":"2020/01/05/进程管理/","link":"","permalink":"http://yoursite.com/2020/01/05/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"pstree显示进程树信息","text":"pstree显示进程树信息 12345678#显示的一部分[root@localhost 1]# pstreesystemd─┬─ModemManager───2*[&#123;ModemManager&#125;] ├─NetworkManager───2*[&#123;NetworkManager&#125;] ├─VGAuthService ├─2*[abrt-dump-journ] ├─abrtd───2*[&#123;abrtd&#125;] ├─accounts-daemon───2*[&#123;accounts-daemon&#125;] ps显示当前进程运行的状态快照。内核通过/proc/将内核信息输出给用户。其中具体/proc/PID文件中的文件都是内核输出的参数，文件内容即是当前的内核对应数据。 1234567891011121314151617181920212223242526272829303132333435363738#ps选项有三种风格，注意区分ps [option] a：所有与终端相关的进程 x：所有与终端无关的进程 u：以用户为中心组织进程状态信息显示 -e：显示所有进程 -f：完整格式 -H：以层级结构显示进程相关信息 -o/o field1,field2...：自定义显示字段，后面加字段名即可#常用fieldpid、ni、pri、psr、pcpu、stat、comm、tty、ppid、rtprioni：nice值，范围-20~19，越小优先级越高priority：优先级rtprio：实时优先级#常用组合：ps aux[root@localhost 1]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANVSZ：虚拟内存集RSS：常驻内存集STAT： R：运行态 S：可终端睡眠 D：不可中断睡眠 T：停止态 Z：僵死态，自己没资源了，等待父进程回收 +：前台进程 l：多线程进程 N：低优先级进程 &lt;：高优先进程 s：会话引领者 #常用组合：ps -ef/F[root@localhost 1]# ps -eFUID PID PPID C SZ RSS PSR STIME TTY TIME CMDPPID：父进程idC：cpu占用百分比PSR：占用哪个cpuSTIME：进程开始时间 pgrep/pkill根据进程的名字或其他属性来查询进程或向进程发送信号。 123456pgrep/pkill [option] pattern -u/U uid：显示指定用户进程 -t tty：与指定终端相关的进程 -l：显示进程名 -a：显示完整格式进程名 -P pid：显示此进程的子进程 pidof根据进程名取指定进程的进程号 12[root@localhost 1]# pidof systemd8331 8324 1292 1274 1 top动态显示进程信息 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@localhost 1]# toptop - 04:41:07 up 8:28, 1 user, load average: 0.09, 0.05, 0.01Tasks: 261 total, 1 running, 260 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni, 99.9 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stMiB Mem : 798.1 total, 85.0 free, 467.6 used, 245.5 buff/cacheMiB Swap: 2048.0 total, 1759.0 free, 289.0 used. 172.5 avail MemPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND -d @：指定显示时间间隔 -b：以批次方式显示 -n @：显示多少批次#第一行；也可以用uptime显示当前时间；运行时间；登录当前系统的用户数；平均负载(过去1分钟、5分钟、15分钟的平均队列长度，即等待cpu进程数)#第一行一共运行进程数；运行数、睡眠数、停止数、僵死数#第三行cpu占用百分比 us：用户空间百分比 sy：内核空间百分比 ni：用于nice值调整占用的cpu百分比 id：空闲百分比 wa：等待io完成所消耗cpu时间百分比 hi：处理硬件中断占用cpu百分比 si：处理软件中断占用cpu百分比 st：被虚拟化程序占用的cpu百分比#第四行物理空间占用情况：总空间；空闲空间；已使用空间；用于缓存和缓冲的内存空间#第五行交换分区占用情况：总空间；空闲空间；已使用空间；用于缓存和缓冲的内存空间#第六行SHR：共享内存空间；其他与ps显示意义一样#内部命令P：以占据CPU百分比显示M：以占据内存百分比显示T：以累计占用CPU时间排序l：显示/隐藏第一行信息t：显示/隐藏第二行信息m：显示隐藏第三行信息s：修改显示时间间隔k：终止指定进程1：显示全部cpu htop改进版的top 12345678910111213141516#安装#安装epel库dnf install epel-release -ydnf install htop htop [option] -d @：指定延迟时间 -s colume：以指定字段进行排序 -u UserName：仅显示指定user的进程u：选择指定用户进程H：显示/隐藏用户线程K：显示隐藏内核线程l：跟踪一个进程的操作s：跟踪一个进程的系统调用t：以层级关系显示各进程状态a：选定进程运行在指定cpu上 vmstat管理虚拟内存信息 12345678910111213141516171819202122232425262728293031vmstat [option] [delay [count]] delay：多久刷新一次 count：刷新多少次 -s：显示内存统计数据[root@localhost ~]# vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st procs： r：等待运行进程的个数 b：处于不可中断睡眠的进程个数memory： swpd：交换内存使用情况，若使用则说明内存不足 free：空闲的物理内存总量 buffer：用于buffer的内存总量 cache：用于cache内存总量swap： si：数据进入swap的速率(kb&#x2F;s) so：数据离开swap的速率(kb&#x2F;s)io： bi：从块设备读入数据到系统的速度(kb&#x2F;s) bo：保存数据到块设备的速度(kb&#x2F;s)system： in：中断速率 cs：进程上下文切换速率cpu： us：用户空间占用百分比 sy：系统占用百分比 id：空闲时间占用百分比 wa：等待时间百分比 st：被虚拟化偷走的时间 pmap显示进程内存映射，实际是通过查看/proc下对应进程的maps文件 12pmap [option] pid -x：显示详细格式信息 dstat生成系统资源统计数据，几乎包括上述所有功能 1234567891011121314151617181920dstat [option] [delay[count]] delay：多久刷新一次 count：刷新多少次 -c：查看cpu信息 -d：查看disk信息 -m：查看内存信息 -g：查看内存页交换信息 -n：显示网络信息 -r：显示io统计数据 -p：统计进程相关数据 -s：统计swap数据 --tcp：显示tcp相关信息 --udp：显示udp相关信息 --raw：显示裸套接字信息 --socket：显示所有套接字信息 --ipc：显示进程间交换信息 --top-cpu：显示最占用cpu的信息 --top-io：显示最占用io的信息 --top-mem：显示最占用内存的信息 --top-lantency：显示延迟最大的进程信息 kill终止一个进程，本质是向进程发送一个命令。 1234567891011kill [option] pid -l：列出可用信号 -s @：发送指定信号 % @：终止指定id的作业(jobs)常用信号 SIGHUP：不重启读配置文件 SIGINT：终止正在运行的进程，相当于Ctrl+c SIGTERM：默认信号，终止正在运行的进程(关闭进程相关后再杀死) SIGKILL：杀死正在执行的进程(不管进程在干什么直接杀死，可能会损坏文件) SIGCONT：后天进程继续执行 SIGSTOP：将进程送到后台 killall根据进程名杀死进程，用于关闭一整个服务 1killall [SIGNAL] PRRC_NAME fg/bg/jobs/nohup12345678#把指定作业调往前台fg jobs_num#把作业送往后台bg jobs_num#查询作业jobs#将指定作业剥离与中断关系在后台运行nohup COMMAND/FIEL &amp; 进程优先级调整可通过nice值调整的优先级范围：100-139，分别对应于-20~19。nice值越低优先级越高 进程启动时，其nice值默认为0，其优先级是120。 12345678910#仅root可以调低nice值nice [option] [COMMAND] -n NICE：以指定nice值启动#调整nicerenice [option] pid -n NICE：调整nice值 #查看nice和优先级ps axo pid,ni,priority,comm","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"http://yoursite.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}],"author":"Frdqy"},{"title":"Linux网络属性配置","slug":"Linux网络属性配置","date":"2020-01-04T12:03:23.000Z","updated":"2020-01-05T05:47:41.022Z","comments":true,"path":"2020/01/04/Linux网络属性配置/","link":"","permalink":"http://yoursite.com/2020/01/04/Linux%E7%BD%91%E7%BB%9C%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE/","excerpt":"ifcfg系列ifconfig接口及地址查看和管理","text":"ifcfg系列ifconfig接口及地址查看和管理 1234567ifconfig [interface] -a：显示所有接口，包括非激活状态ifconfig INTERFACE [aftype] option | address...#启用网卡,其中大写的需要替换成具体接口名以及ip地址、子网掩码等信息ifconfig INTERFACE_NAME IP/MASK [up]ifconfig INTERFACE_NAME netmask NETMASK route路由查看和管理 查看12route [option] -n：直接显示数字信息，不进行主机名解析，效率比较高 添加123456route add [-net|-host] target [netmask Nm] [gw GW] [dev]#实例#添加条目，经由192.168.10.1访问10.10.10.0网络route add -net 10.10.10.0/8 gw 192.168.10.1#添加默认网关route add -net 0.0.0.0/0.0.0.0 gw 192.168.10.1 删除123456route del [-net|-host] target [gw GW] [dev]#实例#删除上面创建的条目route del -net 10.10.10.0/8 gw 192.168.10.1#删除默认网关route del default netstat网络连接、路由表、接口信息等网络信息查看 1234567891011121314151617#显示路由表netstat -rn -r：路由表 -n：数字格式#显示网络连接netstat [option] -t：tcp相关连接 -u：UDP相关连接 -w：raw socket相关连接 -l：处于监听状态的连接 -a：所有状态 -n：以数字格式显示 -e：扩展格式 -p：显示相关进程pid -i：显示接口信息#常用组合 -tan、-uan、-tnl、-unl、-tnlp ifup/ifdown通过读取/etc/sysconfig/network-scripts/下网卡的配置文件进行网卡的开启和禁用 hostnamectl配置主机名 1234hostnamectl status：显示当前主机名设定 set-hostname NAME：设定主机名，永久有效#centos6中需要修改/etc/sysconfig/network来修改主机名才能永久有效 DNS配置1234#在配置文件/etc/resolov.conf中修改即可，最多可以同时添加3个#nameserver为关键字，后面ip地址只能以数字形式，不能使用域名nameserver 192.168.163.2#注意/etc/hosts优先于dns配置文件，如果本地有host，那么host内的设置优先 iproute2系列ip查看和管理路由、设备、策略路由以及隧道等信息，主要用来逐渐取代ifcfg系列。 1234567891011121314151617181920212223242526272829303132333435ip [option] OBJECT &#123;COMMAND|help&#125; link：网络设备配置 show/list：显示设备的属性 set：设置设备的属性 dev NAME：指明要管理的设备 up/down：启用和关闭设备 multicast on/off：启用关闭多播 name NAME：重命名网络接口 mtu NUMBER：设置MTU大小，默认1500 netns NAME：ns为命名空间，用于将指定接口移到某个netns中，常用于构建虚拟网络 help：显示简要帮助 netns：管理网络命名空间 add NAME：增加一个网络命名空间 del NAME：删除一个网络命名空间 list：列出所有的netns exec NAME COMMAND：在netns中执行COMMAND命令 addr：管理网络接口的ip地址 add IP dev INTERFACE：指定接口增加IP地址 label NAME：为指定接口添加接口别名。用于解决ifconig命令不显示多个地址的问题 broadcast ADDRESS：广播地址，一般自动获得 scope SCOPE_VALUE：指定接口作用范围 global：全局可用 link：接口可用 host：仅本机可用 delete IP dev INTERFACE：删除指定设备的地址 show：显示地址信息 flush dev INTERFACE：清空指定接口地址 route：路由管理 add 目标网络/掩码长度 via GW dev 设备 [src]：添加路由 change：同上 repalce：同上 delete 网络：删除到指定网络的路由 show：显示路由信息 get 目标网络：获取某单个路由信息 flush：清空路由信息 ss用来取代netstat的命令 1234567891011121314151617181920ss [option] [filter] -t：tcp相关连接 -u：UDP相关连接 -w：raw socket相关连接 -l：处于监听状态的连接 -a：所有状态 -n：以数字格式显示 -e：扩展格式 -p：显示相关进程pid -i：显示接口信息 -m：显示内存用量 -o：显示计时器信息 [fileter] state [TCP-STATE] [EXPRESSION]#实例#过滤出目标端口和源端口均为22的信息ss -tan '( dport = :22 or sport = :22 )'#过滤出TCP状态为ESTABLISHED的连接ss -tan state ESTABLISHED#常见TCP状态：LISTEN,ESTABLISHED,FIN_WAIT_1,FIN_WAIT_@,SYN_SENT,SYN_RECV,CLOSED 配置文件ip上述命令修改的信息都是临时有效，若想重启后仍然有效需要修改配置文件。配置文件一般放在/etc/sysconfig/network-scripts/目录下。 参数 含义 DEVICE 此配置文件的设备名 ONBOOT 开机时是否激活 UUID 设备唯一标识 IPV6INIT 是否初始化IPV6 BOOTPROTO 激活此接口时使用什么协议配置接口属性，常用dhcp、static TYPE 接口类型 DNS1 定义第一DNS服务器指向 DNS2 定义备用DNS服务器指向 DOMAIN DNS搜索域 GATEWAY 网关 IPADDR ip地址，静态是要填写 NETMASIK/PREFIX 以长度方式指明子网掩码 USERCTL 是否允许普通用户控制此设备 PEERDNS 是否允许dhcp的dns指向覆盖本地的dns NM_CONTROLLED 是否使用nm工具 12345#centos6service SERVICE_NAME &#123;start|stop|statues|restart&#125;#centos7/8systemctl &#123;start|stop|statues|restart&#125; SERVICE_NAMEnmcli SERVICE_NAME &#123;start|stop|statues|restart&#125; route配置文件放在/etc/sysconfig/network-scripts/route-INTERFACE，有两种配置方式，不可混用。 每行一个路由条目 1TARGET via GW 每三行一个路由条目 123ADDRESS#&#x3D;TARGETNETMASK#&#x3D;MASKGATEWAY#&#x3D;NEXTHOP 其他命令ping通过icmp协议报文进行网络探测。可用于DDOS攻击(需要大量主机) 1234ping [option] destination -c：指明ping包个数 -w @：ping命令超时时长 -W @：一次ping中等待对方响应 hping3进阶版ping，可设置选项更多，DDOS更快了 12345#安装时需要epel源hping3 [option] ip --fast：每秒发10次 --faster：更快 --flood：更快，且不会显示ping过程 traceroute用于追踪主机间路由信息，即跟踪当前主机到目标主机之间经过的路由信息。 ftp文件传输协议相关命令 12345678910匿名登录：anonymoushelp：命令帮助get：下载一个文件mget：下载多个文件put：上传一个文件mput：上传多个文件delete：删除一个文件mdelete：删除多个文件bye：结束ftp连接#注意：在ftp模式下执行命令前加！则表示在本地主机上执行 lftp取代ftp的命令工具 12345678910lftp [option] ip -u usre,passwd：以指定用户名和密码登录,若要匿名访问则不输入该选项即可help：命令帮助get：下载一个文件mget：下载多个文件put：上传一个文件mput：上传多个文件rm：删除一个文件mrm：删除多个文件bye：结束ftp连接 wget下载网络资源 12345#不能下载目录，只能下载文件wget [option] url -b：在后台下载(脚本中可能使用) -q：静默模式 -O file：指明下载位置","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"网络配置","slug":"网络配置","permalink":"http://yoursite.com/tags/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"}],"author":"Frdqy"},{"title":"IF常见检测选项补充","slug":"IF常见检测选项补充","date":"2020-01-03T11:39:30.000Z","updated":"2020-01-03T11:45:54.526Z","comments":true,"path":"2020/01/03/IF常见检测选项补充/","link":"","permalink":"http://yoursite.com/2020/01/03/IF%E5%B8%B8%E8%A7%81%E6%A3%80%E6%B5%8B%E9%80%89%E9%A1%B9%E8%A1%A5%E5%85%85/","excerpt":"常用选项","text":"常用选项 123456789101112131415161718192021222324[ -f \"somefile\" ] ：判断是否是一个文件[ -x \"/bin/ls\" ] ：判断/bin/ls是否存在并有可执行权限[ -n \"$var\" ] ：判断$var变量是否有值[ \"$a\" = \"$b\" ] ：判断$a和$b是否相等-r file 用户可读为真-w file 用户可写为真-x file 用户可执行为真-f file 文件为正规文件为真-d file 文件为目录为真-c file 文件为字符特殊文件为真-b file 文件为块特殊文件为真-s file 文件大小非0时为真-t file 当文件描述符(默认为1)指定的设备为终端时为真含条件选择的shell脚本 对于不含变量的任务简单shell脚本一般能胜任。但在执行一些决策任务时，就需要包含if/then的条件判断了。shell脚本编程支持此类运算，包括比较运算、判断文件是否存在等。基本的if条件命令选项有： - eq —比较两个参数是否相等（例如，if [ 2 –eq 5 ]）-ne —比较两个参数是否不相等-lt —参数1是否小于参数2-le —参数1是否小于等于参数2-gt —参数1是否大于参数2-ge —参数1是否大于等于参数2-f — 检查某文件是否存在（例如，if [ -f \"filename\" ]）-d — 检查目录是否存在几乎所有的判断都可以用这些比较运算符实现。脚本中常用-f命令选项在执行某一文件之前检查它是否存在。 其他选项123456789101112131415161718192021222324252627282930313233343536373839404142434445[-a file] 如果file存在则为真[-b file] 如果file存在且是一个块特殊文件则为真[-c file] 如果file存在且是一个字特殊文件则为真[-d file] 如果file文件存在且是一个目录则为真-d前的!是逻辑非例如：if [ ! -d $lcd_path/$par_date ]表示后面的那个目录不存在，则执行后面的then操作[-e file] 如果file文件存在则为真[-f file] 如果file存在且是一个普通文件则为真[-g file] 如果file存在且已经设置了SGID则为真（SUID 是 Set User ID, SGID 是 Set Group ID的意思）[-h file] 如果file存在且是一个符号连接则为真[-k file] 如果file存在且已经设置粘制位则为真当一个目录被设置为\"粘制位\"(用chmod a+t),则该目录下的文件只能由一、超级管理员删除二、该目录的所有者删除三、该文件的所有者删除也就是说,即便该目录是任何人都可以写,但也只有文件的属主才可以删除文件。具体例子如下：#ls -dl /tmpdrwxrwxrwt 4 root root .........注意other位置的t，这便是粘连位。[-p file] 如果file存在且是一个名字管道（F如果O）则为真管道是linux里面进程间通信的一种方式，其他的还有像信号（signal）、信号量、消息队列、共享内存、套接字（socket）等。[-r file] 如果file存在且是可读的则为真[-s file] 如果file存在且大小不为0则为真[-t FD] 如果文件描述符FD打开且指向一个终端则为真[-u file] 如果file存在且设置了SUID（set userID）则为真[-w file] 如果file存在且是可写的则为真[-x file] 如果file存在且是可执行的则为真[-O file] 如果file存在且属有效用户ID则为真[-G file] 如果file存在且属有效用户组则为真[-L file] 如果file存在且是一个符号连接则为真[-N file] 如果file存在and has been mod如果ied since it was last read则为真[-S file] 如果file存在且是一个套接字则为真[file1 –nt file2] 如果file1 has been changed more recently than file2或者file1 exists and file2 does not则为真[file1 –ot file2] 如果file1比file2要老，或者file2存在且file1不存在则为真[file1 –ef file2] 如果file1和file2指向相同的设备和节点号则为真[-o optionname] 如果shell选项“optionname”开启则为真[-z string] “string”的长度为零则为真[-n string] or [string] “string”的长度为非零non-zero则为真[sting1==string2] 如果2个字符串相同。“=”may be used instead of “==”for strict posix compliance则为真[string1!=string2] 如果字符串不相等则为真[string1&lt;string2] 如果“string1”sorts before“string2”lexicographically in the current locale则为真[arg1 OP arg2] “OP”is one of –eq,-ne,-lt,-le,-gt or –ge.These arithmetic binary oprators return true if “arg1”is equal to,not equal to,less than,less than or equal to,greater than,or greater than or equal to“agr2”,respectively.“arg1”and “agr2”are integers.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"IF选项","slug":"IF选项","permalink":"http://yoursite.com/tags/IF%E9%80%89%E9%A1%B9/"}],"author":"Frdqy"},{"title":"Linux程序包管理","slug":"Linux程序包管理","date":"2020-01-03T11:38:49.000Z","updated":"2020-01-04T12:17:27.874Z","comments":true,"path":"2020/01/03/Linux程序包管理/","link":"","permalink":"http://yoursite.com/2020/01/03/Linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86/","excerpt":"概念将源代码编译后变成目标二进制格式，然后需要将二进制程序和其库文件、配置文件、帮助文件等打包形成一个或多个方便用户使用管理的包，这个包叫做程序包，实现这个过程的工具叫做程序包管理器。他可以帮助用户实现程序的安装、升级、卸载、查询、校验的等。","text":"概念将源代码编译后变成目标二进制格式，然后需要将二进制程序和其库文件、配置文件、帮助文件等打包形成一个或多个方便用户使用管理的包，这个包叫做程序包，实现这个过程的工具叫做程序包管理器。他可以帮助用户实现程序的安装、升级、卸载、查询、校验的等。 包管理器组成格式 程序包的组成清单。每个程序包单独实现。包括文件清单、安装或卸载脚本 数据库。整个系统维护一个数据库，存放各个包的名称版本、依赖关系、功能说明、文件路径和校验码等，数据库存放在/var/lib/rpm下，每个文件都存放不同侧重点的信息。 dpkg待补充 rpm1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950rpm [option] package -i：安装 -h：hash marks输出进度条，每个'#'表示2%进度 --test：只检测不安装，通常检测依赖 --replacepkgs：重新安装 --nosignature：不检查签名，即不检查来源合法性 --nodigest：不检查包完整性信息 -U：升级或安装 -h：hash marks输出进度条，每个'#'表示2%进度 --oldpackage：程序包降级 --force：强制升级 -e：卸载 --allmatches：卸载所有匹配到的指定程序包各版本 --test：只测试卸载，检测依赖 -q：查询 #rpm &#123;-q|--query&#125; [select-options] [query-options] [select options] package_name：查询指定的程序包是否安装及其版本 -a：查询所有已安装包 -f file：查询指定的文件由哪个程序包安装生成 -p package：对未安装的程序包查询 --whatprovides capability：查询指定capability由哪个包提供 --whatrequiers capability：查询指定capability被哪个包依赖 [query-options] --changelog：查询rpm包的changelog -l：列出程序包安装生成的所有文件 -i：查询程序包相关的信息，版本号、大小等 -c：查询指定程序包的配置文件 -d：查询指定程序包文档 --provides：列出指定程序包的所有capability -R：查询指定程序包的依赖关系 --scripts：查询程序包自带的脚本 -V：校验 #校验位含义 S file Size differs M Mode differs (includes permissions and file type) 5 digest (formerly MD5 sum) differs D Device major/minor number mismatch L readLink(2) path mismatch U User ownership differs G Group ownership differs T mTime differs P caPabilities differ -v：详细信息 -K：不安装直接检验程序合法性与完整性 --nosignature：不检查签名，即不检查来源合法性 --nodigest：不检查包完整性信息 #注意：不要对内核做升级操作，直接安装，支持多内核共存#程序包原配置文件被改动过，那么安装新版本时不会覆盖，而是将新的配置文件重命名后提供 包命名格式name-version-release.arch.rpm version：major.minor.release release.arch：rpm包的发行号 拆包由于程序打包后并不是所有功能都被用户所需要，因此引进拆包的概念。拆包后包分为主包和支包。 主包：name-version-release.arch.rpm 支包：name-function-version-release.arch.rpm ​ function：devel，utils，libs等各种开发或者插件包 依赖关系每个rpm包之间可能存在安装A就要先安装B这种情况，这叫做依赖关系。 12#查询指定程序包的依赖关系rpm -qr package 前端工具用来自动解决依赖关系。rhel系列上rpm包前端工具为yum、dnf。centos8中dnf已取代yum，不过大体命令使用格式没变，下文均使用习惯的yum来表示dnf。 仓库yum的仓库就是yum repository，它存储了大量的rpm包以及包的相关源数据，通常放置于特定目录下repodata 1234567891011121314151617#仓库定义#&#123;A|B&#125;其中A为默认选项[repositoryid]name=some name for repo#baseurl指向的是一堆url，可以是包含repodata的文件夹baseurl=url://pathenable=&#123;1|0&#125;#该仓库是否启用gpgcheck=&#123;1|0&#125;#是否启用校验gpgkey=url#指明gpg的密钥文件mirrorlist=url#镜像url文件enablegroups=&#123;1|0&#125;#是否使用组批量管理程序包failovermethod=&#123;roundrobin|priority&#125;#多个仓库的选用顺序定义#创建repo，即在指定目录下创建仓库#执行后会在指定目录下创建repodata目录，里面存放了有关各个rpm的信息#其中repmod.xml存放了各个文件的校验码，用于检查上述文件是否合法，不合法则丢弃cachecreaterepo 目录 配置文件 /etc/yum.conf：为所有仓库提供公共配置 /etc/yum.repos.d/*.repo：为仓库的指向提供配置 12345#repo文件中的变量$releasever：当前OS的发型版的主版本号$arch：平台$basearch：基础平台$YUM0-9：自定义变量 yum命令1234567891011121314151617181920212223242526272829yum [option] &lt;commands&gt; [args...] repolist &#123;all|enable|disable&#125;：显示仓库列表 list &#123;available|installed|updates&#125;：显示程序包 install package：安装指定包，可以指定具体版本 reinstall package：重新安装 downgrade package：降级 update package：升级指定程序包 check-update：检查可用升级 remove|erase package：卸载程序包，依赖也会被卸载 info package：显示指定package详细信息 provides|whatprovides feature：查看指定特性由哪个程序包提供 clean &#123;package|all|plugins...&#125;：清理本地缓存 makecache：生成缓存 search string：根据关键字模糊搜索程序包名和summary信息 deplist package：显示指定包的依赖关系 history：查看安装、卸载等信息 groupinstall group：安装包组 groupupdate group：更新包组 grouplist：查询所有包组信息 groupinfo group：查询指定包组信息 groupremove group：删除包组 #命令行选项 --nogpgcheck：禁止进行gpgcheck -y：自动回答yes -q：静默模式 --disablerepo=repoidglob：临时禁用指定的repo --enablerepo=repoidglob：临时启用指定的repo --noplugins：禁用所有插件 安装脚本rpm包可以自带安装脚本，主要分为四类： preinstall：安装之前执行的脚本，用%pre定义，用–nopre取消 postinstall：安装之后执行的脚本，用%post定义，用–nopost取消 preuninstall：卸载真正执行前执行的脚本，用%preun定义，用–nopreun取消 postuninstall：卸载完成后执行的脚本，用%postun定义，用–nopostun取消 完整性验证数字签名的含义是指制作者首先用单向加密算法对数据进行加密并得到特征码，然后使用自己的私钥对特征码进行加密，这样别人只能使用制作者的公钥才能对文件解密，然后再使用相同的单向加密算法计算特征码，相同则文件没有问题。 12345#获取并导入信任的包制作者密钥，centos发行版的密钥通常保存在/etc/pki/rpm-gpg/目录下rpm --import /etc/pki/rpm-gpg/#不安装直接检查完整性与合法性rpm -K package 数据库重建rpm数据库放在/var/lib/rpm/下，其中存放各个包的信息。 1234#使用rpmdb命令，本身还是rpmrpm &#123;--initdb|--rebuilddb&#125; [-v] [--dbpath DIRECTORY] [--root DIRECTORY] --initdb：初始化数据库，若没有数据库则创建一个新的 --rebuilddb：重新构建数据库，构建后的数据库没有rpm事务文件，即__db.001等文件 程序包编译安装形如testname-version-release.src.rpm的包成为源程序包，需要使用rpmbuild命令制作成二进制格式的rpm包后再进行安装。 组织格式源代码一般由多个文件组成，且文件中的代码之间很有可能存在跨文件的依赖关系。因此需要使用make来管理源代码的编译。 编译安装步骤 ./configure 通过选项传递参数，指定启用特性、安装路径等；执行时会参考用户指定的Makefile.in文件生成makefile 检查各指定功能依赖到的外部环境 一般由autoconf系列命令根据开发者的需要生成configure脚本；由automake系列命令根据用户需要生成Makefile.in文件(一般源代码文件都会提供) 1234#configure脚本，一般可以指定安装位置、指定启用的特性 --help：获取帮助 --prefix=path：指明默认安装位置，默认为/usr/local/ --sysconfdir=path：指明配置文件安装位置 make 根据makefile文件构建应用程序 make install 导出二进制程序至PATH环境变量中。即编辑文件/etc/profile.d/name.sh添加export PATH=$PATH:/yourpath 导出库文件路径。即编辑/etc/ld.so.conf.d/name.conf，添加新的库文件所在目录至此文件中。之后使用ldconfig命令让系统重新生成缓存 导出头文件。可以导出整个目录的符号链接到/usr/include/目录下即可。 导出帮助手册。编辑/etc/man.conf，添加一条MANPATH路径即可。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"rpm","slug":"rpm","permalink":"http://yoursite.com/tags/rpm/"},{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"},{"name":"dnf","slug":"dnf","permalink":"http://yoursite.com/tags/dnf/"}],"author":"Frdqy"},{"title":"任务计划crontab","slug":"任务计划crontab","date":"2020-01-02T14:21:35.000Z","updated":"2020-01-02T14:26:20.789Z","comments":true,"path":"2020/01/02/任务计划crontab/","link":"","permalink":"http://yoursite.com/2020/01/02/%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92crontab/","excerpt":"概念用于设定系统定时处理某件事情的功能，例如设定数据库定时备份等。","text":"概念用于设定系统定时处理某件事情的功能，例如设定数据库定时备份等。 工具at、batch、crontab 其中at和batch是在未来的某个时间点执行一次任务，crontab是周期性的运行某任务 上述命令的执行结果会通过邮件发送给用户。这里说的邮件是本机邮件，不是互联网邮件。 at在未来某个时间点执行一次某个任务 1234567891011at [option] time -l：查看已有的任务 -f file：从file中读取作业内容，不用交互输入 -d #：删除指明作业号的作业 -c #：查看指定作业号的具体内容 -q QUEUE：指明任务执行队列，默认队列为a#运行结果以邮件方式发给提交作业的用户#时间格式为：HH:MM[YYYY-mm-dd]#模糊时间表示：noon、midnight、teatime、tomorrow#相对时间表示：now+#mins/hours/days/weeks crontab实现周期性执行某任务。需要服务程序来监控，该服务为cronle，提供了crond守护进程及相关辅助工具 12345678#注意：如果拒绝接收邮件可以用command &gt; /dev/null，还会接收错误输出#若使用command &amp;&gt; /dev/null则连错误输出也过滤掉，不推荐crontab [option] -e：编辑任务；可用于删除单个任务 -l：列出所有任务 -r：移除所有任务；即删除/var/spool/cron/下的用户文件 -i：交互式 -u user：root用户用于管理其他用户的任务，与其他命令组合使用 系统cron任务主要用于实现系统自身的维护，编辑时直接手动编辑配置文件/etc/crontab 1234567891011121314151617#cat /etc/crontab#注意：每一行定义一个周期任务；命令建议使用绝对路径；执行结果发送给MAILTO指定的用户；共7个字段[root@localhost ~]# cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 用户cron任务使用命令crontab编辑任务 12345678910111213141516171819#确保crond运行systemctl status crond.service#定义于/var/spool/cron/username中，只能用命令crontab修改，且只有6个字段(无用户名)#注意：每一行定义一个周期任务；命令建议使用绝对路径；结果发给定义文件的用户SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * command to be executed 注意 *表示“每…执行一次”； 在时间点上使用逗号分隔的多个值可以表示多个时间实现离散取值 在时间点上使用#-#表示连续时间取值； 可以在指定时间上定义步长*/#，#就是步长，且步长需要能整除时间； 最小单位为分钟，不能完成秒级任务(可以通过脚本每分钟循环实现) 实例 3 * * * *：每小时执行一次；每小时的第3分钟执行 3 4 * * 5：每周执行一次；每周5的4点3分执行 5 6 7 * *：每月执行一次；每月的7号的6点5分执行 7 8 9 10 *：每年执行一次；每年10月9号8点7分执行 9 8 * * 3,7：每周3和周日执行一次 0 8,20 * * 3,7：每周3和周日的8点和20点执行一次，注意前面的min位必须指定，否则每分钟都执行 0 9-18 * * 1-5：周1到周5的9点到18点每小时执行一次 */5 * * * *：每5分钟执行一次 本地电子邮件服务smtpsimple mail transmission protocol，简单邮件投递服务，只能发邮件不能收邮件 pop3post office protocol，邮局协议，用于接收邮件 mail命令1234mail [-s 'SUBJECT'] 用户 &lt; 邮件正文#邮件正文一般用输入重定向即可#注意，初次实验可能对面没有收到，因为配置文件/etc/postfix/main.cf文件中的inet_interfaces = all一开始没有设置成all而是localhost，修改后即可正常发送。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"定时任务","slug":"定时任务","permalink":"http://yoursite.com/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"}],"author":"Frdqy"},{"title":"压缩与归档","slug":"压缩与归档","date":"2020-01-02T14:20:58.000Z","updated":"2020-01-05T05:48:16.831Z","comments":true,"path":"2020/01/02/压缩与归档/","link":"","permalink":"http://yoursite.com/2020/01/02/%E5%8E%8B%E7%BC%A9%E4%B8%8E%E5%BD%92%E6%A1%A3/","excerpt":"目的CPU时间换磁盘空间","text":"目的CPU时间换磁盘空间 压缩工具compress/uncompress .z gzip/gunzip .gz bzip2/bunzip2 .bz2 xz/unxz .xz 上述工具不支持压缩目录，要压缩目录需要先归档。 gzip123456789#压缩文件并删除源文件gzip [option] file -d：解压缩，相当于gunzip -#：指定压缩比，默认6，数字越大压缩比越大(1-9) -c：将压缩结果输出至标准输出例如：gzip -c file &gt; file.gz#解压缩文件，结尾必须是.gz结尾gunzip [option] file.gz#不解压直接查看压缩文件zcat file.gz bzip2123456bizip2 [option] file -d：解压缩，相当于bunzip -#：指定压缩比，默认为6，数字越大压缩比越大(1-9) -k：保留源文件#不解压直接查看压缩文件bzcat file.bz xz/unxz123456xz [option] file -d：解压缩 -#：指定压缩比，默认为6，数字越大压缩比越大(1-9) -k：保留源文件#不解压直接查看压缩文件xzcat file.xz 归档工具用于将目录内所有文件都归档成一个文件再指行压缩 tar12345678910111213141516171819202122tar [option] file -c：创建归档 -x：展开归档 -t：查看归档文件列表，不展开归档 -f path：指明要归档的文件目录 -C path：指明归档文件展开到何处 -z：使用gizp2压缩/解压缩 -j：使用bzip2压缩/解压缩 -J：使用xz压缩/解压缩 -v：显示压缩详细信息 -A：新增文件到已压缩文件中 #常用搭配#使用gzip压缩和解压缩目录文件tar zcvf 保存文件.tar.gz ./test/tar zxvf 保存文件.tar.gz ./test/#使用bzip2压缩和解压缩目录文件tar jcvf 保存文件.tar.bz ./test/tar jxvf 保存文件.tar.bz ./test/#使用xz压缩和解压缩目录文件tar Jcvf 保存文件.tar.xz ./test/tar Jxvf 保存文件.tar.xz ./test/","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"tar","slug":"tar","permalink":"http://yoursite.com/tags/tar/"},{"name":"压缩","slug":"压缩","permalink":"http://yoursite.com/tags/%E5%8E%8B%E7%BC%A9/"}],"author":"Frdqy"},{"title":"磁盘管理与文件系统","slug":"磁盘管理与文件系统","date":"2020-01-02T14:20:26.000Z","updated":"2020-01-02T14:25:47.253Z","comments":true,"path":"2020/01/02/磁盘管理与文件系统/","link":"","permalink":"http://yoursite.com/2020/01/02/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","excerpt":"设备类型块随机访问，数据交换单位是块 字符线性访问，数据交换单位是字符","text":"设备类型块随机访问，数据交换单位是块 字符线性访问，数据交换单位是字符 设备文件关联至设备的驱动程序；设备的访问入口 命名12/dev/sd[a-z]##其中\"#\"表示任意数字 设备号 major：主设备号，区分设备类型，用于标明设备所需要的驱动程序 minor：次设备号，区分同种设备类型下的不同设备，是特定设备的访问路口 mknod命令123#用于创建块或字符设备mknod [OPTION]... NAME TYPE [MAJOR MINOR] -m MODE:创建后的设备文件的访问权限 引用方式 设备文件名 卷标 UUID 磁盘分区MBR主引导记录，处于0号扇区(每个扇区512B)。 组成部分 446B：bootloader程序，是引导启动操作系统的程序 64B：分区表，每16B标识一个分区，一共只能有4个分区，其中第四个分区使用拓展分区即可超过4个分区的限制 2B：MBR区域的有效性标识，一般为55AA GPT待补充 fdisk命令12345678910111213#用于管理磁盘分区fdisk [options] device#fdisk /dev/dev_name后将进入交互式管理接口#交互常用命令 n:创建新分区 d:删除已有分区 t:修改分区类型 l:查看已有id w:保存修改到磁盘 q:不保存直接退出 m:查看帮助信息 p:显示现有分区信息 注意：在已经分区且已经挂载其中某个分区的磁盘上创建新的分区，内核可能在创建完成后无法直接识别，使用以下命令解决 12345678#查看内核分区cat /proc/partitions#通知内核强制重读磁盘分区CentOS 5：partprobe [device]CentOS 6/7： partx -a [device] kpartx -af [device] 文件系统格式化低级格式化分区之前进行，主要划分磁道 高级格式化分区之后对分区进行，主要是创建文件系统 元数据元数据主要是文件的属性例如大小、权限、时间戳、数据块指针等信息的存放区域(不包括文件名)，一般一个文件的元数据叫做一个inode(index node)索引节点，在创建操作系统时就已经分配了一段区域作为元数据的存储区域。另外，元数据区域包括一个位图，用于标识inode节点的分配情况。 123456789101112131415#文件前的编号即为inode编号[root@localhost ~]# ls -i 34214878 anaconda-ks.cfg 34214891 initial-setup-ks.cfg#stat命令查看具体文件的inode信息[root@localhost ~]# stat ./anaconda-ks.cfg File: ./anaconda-ks.cfg Size: 1467 Blocks: 8 IO Block: 4096 regular fileDevice: fd00h/64768d Inode: 34214878 Links: 1Access: (0600/-rw-------) Uid: ( 0/ root) Gid: ( 0/ root)Context: system_u:object_r:admin_home_t:s0Access: 2019-12-23 08:02:55.976905697 -0500Modify: 2019-12-23 07:16:53.042026882 -0500Change: 2019-12-23 07:16:53.042026882 -0500 Birth: - 目录目录本身也是文件，他所在的块存贮的是他的一级目录下的文件名和对于的inode映射。因此在每次查找路径时都会先查找/的inode，然后查找/的块，从/的块中的映射查找需要的文件再依次查找下去，直到找到目标文件。 12345#free查看内存看出cache占用，里面存储的就包含路径的缓存，用于加快查找映射[root@localhost ~]# free total used free shared buff/cache availableMem: 817272 522836 91996 1804 202440 140784Swap: 2097148 216064 1881084 VFS虚拟文件系统，是一个中间层，用于将各种文件系统的差异性屏蔽而向上层统一输出一个接口。 Linux文件系统：ext2~4、xfs、btrfs等 网络文件系统：nfs、cifs等 集群文件系统：gfs2、ocfs2等 内核级分布式文件系统：ceph等 伪文件系统：proc、sysfs、tmpfs等 交换文件系统：swap等 用户空间分布式文件系统：mogiles、moosefs等 管理工具创建文件系统工具mkfs：它包括一系列指令，如mkfs.ext2、mkfs.ext3、mkfs.xfs等 12345678910#ext系列专用管理工具mke2fs [option] device -t &#123;ext2|3|4&#125;：指明文件系统类型 -b &#123;1024|2048|4096&#125;：指明文件系统的块大小 -L LABLE：指明卷标 -j：创建有日志的文件系统 -i #：指明inode的比率，即每多少字节创建一个inode -N #：直接指明要给此文件系统创建的inode数量 -O [^]feature：以指定的特性创建文件系统(或取消某种特性) -m #：指定预留空间百分比，直接根数字即可 检测及修复文件系统工具fsck：它包括一系列指令，如fsck.ext2、fsck.ext3、fsck.xfs等 12345678910#e2fsck用于检查ext系列文件系统e2fsck [option] device -y：对所有问题自动回复yes -f：即使文件系统clean也要强制检测 #fsck用于通用的linux文件系统检查fsck -t type：指明文件系统类型 -a：无须交互而自动修复所有错误 -r：交互式修复(推荐) 查看管理属性工具dumpe2fs、tune2fs、blkid、e2label 1234567891011121314151617181920212223#e2label用于查看与设置ext系列的卷标e2label devicee2label device LABEL#blkid打印块属性blkid [option] device -L LABEL；根据LABEL定位设备 -U UUID：根据UUID定位设备 #tune2fs用于调整ext系列系统中可调整的参数，例如卷标和系统类型等tune2fs [option] device -l：查看超级块信息 -j：将ext2升级为ext3 -L LABEL：修改卷标 -m #：修改预留空间百分比，直接跟数字即可 -O [^]feature：开启或关闭某种特性 -o [^]mount_option：开启或关闭某种默认挂载选项，常用设置acl #dumpe2fs用于显示文件系统属性信息，包括每个块组和超级块信息dumpe2fs [option] device#修改ext系列文件系统的大小，主要用于扩展lv后扩展文件系统使用resize2fs lvname 日志主要是解决当写文件发生错误导致系统重启后恢复哪些文件而设置的机制。在磁盘上会单独分一块日志区，写文件时先写在日志区，然后再写回文件系统中。虽然会有性能损失，但是利大于弊。 文件操作删除文件将此文件指向的所有数据块标记为未使用状态并将此文件的inode标记为未使用，即只修改inode位图和数据块位图即可，因此速度很快。 移动文件当处于同一文件系统时，移动文件仅仅是改变其路径。即将当前目录的条目移到另一目录即可，文件本身并不做改变。 当处于不同文件系统时，移动文件相当于复制数据至目标文件并删除源文件，因此比较慢。 链接文件硬链接指向同一inode的不同路径 其中目录不支持硬链接；硬链接不能跨文件系统；创建硬链接会增加inode引用计数；硬链接大小相同 1234567891011121314151617181920212223#硬链接inode相同[root@localhost ~]# ls -i34214878 anaconda-ks.cfg 34214891 initial-setup-ks.cfg34214878 anaconda-ks.cfg_bak 34214894 test#第二列的“1”就是引用计数[root@localhost ~]# ls -ltotal 8-rw-------. 1 root root 1467 Dec 23 07:16 anaconda-ks.cfg-rw-r--r--. 1 root root 1622 Dec 23 08:03 initial-setup-ks.cfg#创建一个硬链接，可以看到引用计数加1#删除一个硬链接不影响另一个[root@localhost ~]# ln anaconda-ks.cfg anaconda-ks.cfg_bak[root@localhost ~]# ls -ltotal 12-rw-------. 2 root root 1467 Dec 23 07:16 anaconda-ks.cfg-rw-------. 2 root root 1467 Dec 23 07:16 anaconda-ks.cfg_bak-rw-r--r--. 1 root root 1622 Dec 23 08:03 initial-setup-ks.cfg#不能链接目录[root@localhost ~]# ln test test_1ln: test: hard link not allowed for directory 符号链接inode数据保存的指针区域保存的不是指向磁盘块的指针，而是指向那个真正文件的路径 其中，符号链接和文件是两个独立的文件，他们有各自的inode；可以对目录进行符号链接，且可以跨文件系统；删除符号链接不影响源文件，但是删除源文件影响符号链接；符号链接大小为路径字符串长度。 符号链接本身权限是777，因为用户对符号链接的访问本质还是要看源文件的权限。 123456789101112131415161718#可以看到符号链接的文件inode与硬链接和源文件不同#且源文件和符号链接的引用计数也不同，源文件引用计数不变[root@localhost ~]# ln -s anaconda-ks.cfg anaconda-ks.cfg_symbolic[root@localhost ~]# ls -litotal 1234214878 -rw-------. 2 root root 1467 Dec 23 07:16 anaconda-ks.cfg34214878 -rw-------. 2 root root 1467 Dec 23 07:16 anaconda-ks.cfg_bak34214895 lrwxrwxrwx. 1 root root 15 Jan 1 06:15 anaconda-ks.cfg_symbolic -&gt; anaconda-ks.cfg34214891 -rw-r--r--. 1 root root 1622 Dec 23 08:03 initial-setup-ks.cfg34214894 drwxr-xr-x. 2 root root 6 Jan 1 06:09 test#可以对目录进行符号链接[root@localhost ~]# ln -s test test_symbolic[root@localhost ~]# ls -li test*34214899 lrwxrwxrwx. 1 root root 4 Jan 1 06:17 test_symbolic -&gt; testtest:total 0 swap交换分区Linux上的交换分区必须使用独立的文件系统，且文件系统的system_ID必须为82 创建swap分区123mkswap [option] device -L：指明卷标 -f：强制创建 启用swap12swapon [option] device -a：启用定义在/etc/fstab文件中的所有swap设备 禁用swap1swapoff device 挂载根文件系统以外的其他文件系统想要被访问就必须先关联到根文件系统上的某个目录来实现，这个关联操作称为“挂载”，挂载目录成为”挂载点“，即用于另一个文件系统的访问入口。 此外，挂载点必须实现存在；应该使用不会被或未被其他进程使用的目录；挂载点下原有的文件会被隐藏 mount使用1234567891011121314151617181920212223242526272829303132333435#mount实现挂载mount [-fnrsvw] [-t fstype] [-o options] device dir -a：自动挂载 -r：只读挂载 -w：读写挂载 -n：默认情况下，挂载卸载会同步更新到/etc/mtab中，该选项用于禁止该功能 -t：指明挂载文件系统类型，可省略，默认通过blkid识别 -L LABEL：挂载时以卷标的方式指明设备 -U UUID：挂载时以UUID方式指明设 -o options挂载选项 sync/async：同步/异步操作 atime/noatime：文件在被访问时是否更新其访问时间戳，不启用更好 diratime/nodiratime：同上，对目录操作 remount：重新挂载，不用卸载再挂载 acl：支持使用facl ro：只读类似-r rw：读写类似-w dev/nodev：此设备上是否允许创建设备文件 exec/noexec：是否允许运行此设备上的程序文件 auto/noauto：是否允许自动挂载 user/nouser：是否允许普通用户挂载 suid/nosuid：是否允许suid和sgid特殊权限生效 defaults：rw, suid, dev, exec, auto, nouser, and async --bind 源目录 目标目录：实现目录的绑定，用作某目录临时入口 #查看当前已挂载设备mountcat /etc/mtabcat /proc/mounts#挂载光盘mount -r /dev/cdrom mount_point#挂载本地回环设备(iso等映像)mount -o loop 回环设备 mount_point umount使用123456789#umount实现卸载umount [-dflnrv] &#123;directory|device&#125;#正在被访问时无法卸载,查看被谁访问使用lsof mount_pointfuser -v mount_point#终止所有访问挂载点的进程fuser -km mount_point fstab用于定义开机自动挂载的目录。其每行定义一个要挂载的文件系统及其相关属性 属性从左自右分别为：挂载设备、挂载点、文件系统类型、挂载选项、转储频率、自检次序 挂载设备：LAEBL、UUID、伪文件系统均可 挂载选项：defaults表示默认选项，若自定义多个选项，则每个选项之间使用”，“分隔 转储频率：0表示不备份；1表示每天备份、2表示每隔一天备份 自检次序：0表示不自检；1表示首先自检，通常为根文件系统；2.3.4….依次自检 其余命令df12345#显示文件系统使用情况df [option] -l：仅显示本地文件的相关信息 -h：以人可读的形式显示，即单位换算 -i：显示inode使用状态 du1234#显示文件使用情况而非文件系统du [option] file -h：以人可读的形式显示，即单位换算 -s：显示目录下所有文件的大小总和 dd1234567891011121314#底层的复制工具#表示从path1复制文件到path2dd if=/path1 of=/path2 bs=#：表示复制单元大小 count=#：表示复制多少个bs #备份MBRdd if=/dev/sda of=/tmp/mbr.bck bs=512 count=1#破坏MBR的bootloaderdd if=/dev/zero of=/dev/sda bs=256 count=1#特殊设备/dev/null/dev/zero","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"http://yoursite.com/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}],"author":"Frdqy"},{"title":"LVM2","slug":"LVM2","date":"2020-01-02T14:19:49.000Z","updated":"2020-01-03T11:43:14.672Z","comments":true,"path":"2020/01/02/LVM2/","link":"","permalink":"http://yoursite.com/2020/01/02/LVM2/","excerpt":"概念Logical Volume Manager，逻辑卷管理器。在硬盘之上创建一个逻辑层用于管理硬盘分区系统。主要用于实现文件系统的动态增加与减少，类似于btrfs的动态扩展和收缩。","text":"概念Logical Volume Manager，逻辑卷管理器。在硬盘之上创建一个逻辑层用于管理硬盘分区系统。主要用于实现文件系统的动态增加与减少，类似于btrfs的动态扩展和收缩。 术语PVphysical volume 在物理层面组成的磁盘卷，是在硬件磁盘分区基础上加上了lVM相关的管理参数，可以理解为对硬盘的划分，与分区类似。PV可以是一个磁盘也可以是一个分区。 VGvolume group 将多个PV组合而成抽象出的一个逻辑卷组，用以对外提供PE(physical extend)，即PV在逻辑上组合成VG后再经过逻辑划分成PE来使用。 PEphysical extend 在VG里划分的对外提供的块，一般为M单位大小。 LVlogical volume 由多个PE组成的逻辑卷，对LV可以进行挂载和建立文件系统操作。此时可以通过增加或删除PE实现文件系统的动态增加与减少。 管理工具PV管理工具123456#简要pv信息显示pvs#显示pv详细信息pvdisplay device#创建pv。新创建的pv没有加入VG，所以不知道PE大小pvcreate device VG管理工具123456789101112#简要vg信息显示vgs#显示vg详细信息vgdisplay#创建vg，其中device必须是已被创建的pvvgcreate [option] vgname device#扩展vg，device必须是已创建的pvvgextend vgname device#缩减vg，device必须是已创建的pv，且删除前要使用pvmove移走pv中的数据到同一vg的其他pv上vgreduce vgname device#删除vgvgremove vgname LV管理工具123456789101112131415161718#简要lv信息显示lvs#显示lv详细信息lvdisplay#创建lvlvcreate [option] lvname vgname -L：指明卷大小 -n：指明卷名称#扩展逻辑卷#注意：修改逻辑卷后要修改文件系统大小resize2fs lvnamelvextend [option] lvnam -L：指明目标大小#缩减逻辑卷#注意：缩减逻辑卷前要先卸载逻辑卷，然后做文件系统强制检测修复fsck -f lvname，之后修改文件系统大小resize2fs lvname 大小，最后再挂载即可lvreduce [option] lvname -L：指明目标大小#逻辑卷删除lvremove lvname 快照快照是LVM提供对lv上文件系统做备份的一个功能。快照也是一个或多个逻辑卷区域，只是文件类型与正常文件不同而已。快照使用写时复制，本质是一个指向要备份数据的inode的硬链接，当没有数据改变时快照和目标数据相同。当目标数据发生变化时，会把要修改的文件先拷贝到快照区域，然后再修改需要修改的目标文件，这样快照里保存的就是未修改前的文件了，这方便备份与还原。 1234567#创建快照#-p r：指明只读lvcreate -L 大小 -p r -s snapshot_name original_lv_name#利用lvconvert合并快照与源数据#注意：合并前源数据和快照都需要卸载才可以合并，且合并结束后会自动删除快照lvconvert --merge original_lv_name","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"lvm","slug":"lvm","permalink":"http://yoursite.com/tags/lvm/"}],"author":"Frdqy"},{"title":"RAID","slug":"RAID","date":"2020-01-02T14:19:14.000Z","updated":"2020-01-03T11:45:30.396Z","comments":true,"path":"2020/01/02/RAID/","link":"","permalink":"http://yoursite.com/2020/01/02/RAID/","excerpt":"概念Redundant Arrays Of Independent Disks，独立磁盘冗余阵列","text":"概念Redundant Arrays Of Independent Disks，独立磁盘冗余阵列 级别RAID-0概念条带卷(stripe) 将要存储的数据分块然后并行存储到RAID的不同的磁盘下叫做条带。 特点 读、写性能提升 可用空间：N*min(S1,S2…) 无容错能力 最小磁盘数：2,2+ RAID-1概念镜像卷(mirror) 将要存储的数据分块然后在RAID的每个磁盘上都存储一份，即镜像。 特点 读性能提升，写性能下降 可用空间：1*min(S1,S2…) 有冗余能力 最小磁盘数：2,2+ RAID-5概念使用异或校验的形式且校验码依次存储在每个磁盘上，即每个磁盘轮流当校验码，目前主要以左对称为主 特点 读写性能提升 可用空间：(N-1)*min(S1,S2…) 用冗余能力，最多坏一块 最小磁盘数：3,3+ RAID-6概念在RAID-5基础上增加一块校验盘 特点 读写性能提升 可用空间：(N-2)*min(S1,S2…) 有冗余能力，最多坏2块 最少磁盘数：4,4+ RAID-10概念先两两做成RAID-1再做成RAID-0。存储时先按RAID-0条带后再镜像存储到RAID-1中。 特点 读写性能提升 可用空间：N*(S1,S2…)/2 有冗余能力，每组镜像最多只能坏一块 RAID-01概念先两两做成RAID-0再做成RAID-1。存储时先按RAID-1镜像后再条带到RAID-0中。 特点 读写性能提升 可用空间：N*(S1,S2…)/2 有冗余能力，每组镜像最多只能坏一块 JBODJust a Bunch Of Disks 功能：将多块磁盘空间合并一个大的连续空间使用，可用空间一般为磁盘容量总和","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"raid","slug":"raid","permalink":"http://yoursite.com/tags/raid/"}],"author":"Frdqy"},{"title":"文件特殊权限","slug":"文件特殊权限","date":"2020-01-01T11:23:25.000Z","updated":"2020-01-01T11:55:55.319Z","comments":true,"path":"2020/01/01/文件特殊权限/","link":"","permalink":"http://yoursite.com/2020/01/01/%E6%96%87%E4%BB%B6%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90/","excerpt":"文件特殊权限SUID、SGID、STICKY","text":"文件特殊权限SUID、SGID、STICKY 安全上下文 进程以某用户的身份运行：进程是发起此进程用户的代理，因此以此用户的身份和权限完成所有操作 权限匹配模型： 判断进程的属主是否为被访问文件的属主 ，如果是则使用属主权限访问，否则进入2 判断进程的属主是否属于被访问文件的属组，如果是就使用属组权限，否则进入3 应用other模型 SUID默认情况下用户发起的进程其属主是其发起者。而设置SUID的进程执行时，其属主为进程自己的属主。 1234567891011121314151617181920#/etc/shadow无访问权限[frdqy@localhost ~]$ ls -l /etc/shadow----------. 1 root root 1434 Dec 31 22:26 /etc/shadow#以frdqy身份无法访问/etc/shadow，因为此时以使用cat的发起者权限来访问/etc/shadow，即other[frdqy@localhost ~]$ cat /etc/shadowcat: /etc/shadow: Permission denied#此时cat并没有设置SUID权限[frdqy@localhost ~]$ ls -l /bin/cat-rwxr-xr-x. 1 root root 51856 May 11 2019 /bin/cat#用root给cat设置SUID权限后[root@localhost frdqy]# chmod u+s /bin/cat[root@localhost frdqy]# ls -l /bin/cat-rwsr-xr-x. 1 root root 51856 May 11 2019 /bin/cat#frdqy用户即可用cat查看/etc/shadow内容，因为此时cat进程使用的是其属主root权限，而不是进程的发起者[frdqy@localhost ~]$ cat /etc/shadowroot:$6$RsZ/8mPpOXX17jO8$yeL/BOfROjigWhsFEEwvF6ZDe3ldr/FJX9vvQFtzJCIWZngO5RhjLVRRgAeSg13ymfLWELIyl5R.sTBbGtP390::0:99999:7::: 注意： 如果进程属主原本有执行权限，那么加了SUID后就变成s；如果进程属主原本没有执行权限，那么加SUID后就变成S。 SGID通常对目录设置，这样其他用户在该目录下创建文件时，文件的属组全都是目录的属组，主要为了方便同组用户的修改。 1chmod g+|g- /dir STICKY用于解决某一目录下每个用户都可以删除同组其他用户的文件问题，在该目录上设置STICKY后用户只能新建和删除自己的文件，不能删除同组其他用户的文件。 12chmod o+t|o-t /dir#/tmp和/var/tmp默认具有STICKY权限 FACLfacl是文件的额外赋权机制，在原来的ugo之外，另一层让普通用户能控制赋权给另外的用户或组的赋权机制 getfacl1234getfacl fileuser:USERNAME:MODEgroup:GROUPNAME:MODE#若username为空则为属主的权限，若groupname为空则为默认属组的权限 setfacl1234567#赋权给用户setfacl -m u:USERNAME:MODE file#赋权给组setfacl -m g:GROUPNAME:MODE file#撤销赋权setfacl -x u:USERNAME:MODE filesetfacl -x g:GROUPNAME:MODE file 访问控制顺序首先，检查进程属主与被访问文件属主是否相同，相同则使用属主权限；否则检查被访问文件是否定义关于该用户的访问控制链表(facl)，有则应用该访问链表权限；否则检查此进程的属主是否是被访问文件的属组，是则应用属组访问权限，否则检查访问控制链表是否有该用属组的定义，若有则应用该属组权限。最后还不匹配就按other访问。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"权限","slug":"权限","permalink":"http://yoursite.com/tags/%E6%9D%83%E9%99%90/"}],"author":"Frdqy"},{"title":"Shell编程之（七）：脚本实战","slug":"Shell编程之（七）：脚本实战","date":"2019-12-31T08:27:45.000Z","updated":"2019-12-31T08:28:45.979Z","comments":true,"path":"2019/12/31/Shell编程之（七）：脚本实战/","link":"","permalink":"http://yoursite.com/2019/12/31/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E8%84%9A%E6%9C%AC%E5%AE%9E%E6%88%98/","excerpt":"脚本需求 实现一个脚本工具，该脚本提供类似supervisor功能 一键查看所有进程运行状态 按分组查看进程运行状态","text":"脚本需求 实现一个脚本工具，该脚本提供类似supervisor功能 一键查看所有进程运行状态 按分组查看进程运行状态 拆分脚本功能app_statuesfunction get_all_process123456789101112#返回进程名称列表字符串# define variablesHOME_DIR=\"/home/frdqy/shell/day_06/\"CONFIG_FILE=\"process.cfg\"function get_all_process&#123; for g in `get_all_group`; do P_LIST=`sed -n '/\\['$g'/,/^\\[/p' $HOME_DIR/$CONFIG_FILE | egrep -v \"(^$|^\\[)\"` echo $P_LIST done&#125; function get_all_group1234567891011121314#返回进程租列表字符串# define variablesHOME_DIR=\"/home/frdqy/shell/day_06/\"CONFIG_FILE=\"process.cfg\"function get_all_group&#123; if [ ! -e $HOME_DIR/$CONFIG_FILE ];then echo \"$CONFIG_FILE is not exit.\" exit 1 else G_LIST=`sed -n '/\\[GROUP_LIST\\]/,/\\[/p' $HOME_DIR/$CONFIG_FILE | egrep -v \"(^$|^\\[)\"` echo $G_LIST fi&#125; function get_process_pid_by_name12345678910#参数为进程pid根据进程名称查pidfunction get_process_pid_by_name&#123; if [ $# -ne 1 ];then return 1 else pids=`ps -ef | grep $1 | grep -v grep |grep -v $0 | awk '&#123;print $2&#125;'` echo $pids fi&#125; function get_process_info_by_pid1234567891011121314#参数为pid，根据pid查询进程状#详细信息包括：运行状态，PID，MEM信息，CPU信息，时间信息#此处不能根据进程名查，会有很多无关信息function get_process_info_by_pid&#123; if [ `ps -ef | awk -v pid=$1 \"$2==pid&#123;print &#125;\" | wc -l` -eq 1 ];then proc_statues=\"RUNNING\" else proc_statues=\"STOPED\" fi pro_cpu=`ps aux | awk -v pid=$1 \"$2==pid&#123;print $3&#125;\"` pro_mem=`ps aux | awk -v pid=$1 \"$2==pid&#123;print $4&#125;\"` pro_stat_time=`ps -p $1 -o lstart | grep -v STARTED`&#125; function is_group_in_config1234567891011121314#参数为group，判断group是否在config中# define variablesHOME_DIR=\"/home/frdqy/shell/day_06/\"CONFIG_FILE=\"process.cfg\"function is_group_in_config&#123; for gn in `get_all_group`; do if [ \"$gn\" == \"$1\" ];then return fi done return 1&#125; function get_all_process_group1234567891011#参数为group，根据group获取processfunction get_all_process_group&#123; is_group_in_config $1 if [ $? -eq 0 ];then p_list=`sed -n \"/\\[$1/,/\\[/p\" $HOME_DIR/$CONFIG_FILE | egrep \"(^$|^#|^\\[)\"` echo $p_list else echo \"GroupName $1 is not in process.cfg\" fi&#125; function get_group_by_process12345678910111213#根据进程获取组名，参数为processfunction get_group_by_process&#123; for gn in `get_all_group` do for pn in `get_all_process_group $gn` do if [ \"$pn\" == \"$1\" ];then echo $gn fi done done&#125; function format_print12345678910111213#接收两个参数，第一个为process，第二个为groupfunction format_print&#123; ps -ef | grep $1 | grep -v grep | grep -v $this_pid &amp;&gt; /dev/null if [ $? -eq 0 ];then pids=`get_process_pid_by_name $1` for pid in $pids do get_process_info_by_pid $pid awk -v p_name=$1 -v g_name=$2 -v p_status=$pro_stat_time -v p_cpu=$pro_cpu -v p_mem=$pro_mem -v p_start_time=$pro_stat_time 'BEGIN&#123;printf \"%-10s%-10s%-5s%-5s%-5s%-5s%-15s\\n\",p_name,g_name,p_status,p_cpu,p_mem,p_start_time&#125;' done fi &#125; function is_process_in_config123456789101112#参数为process#坑点：此处一开始将return1写在循环里导致直接跳出function is_process_in_config&#123; for pn in `get_all_process` do if [ \"$pn\" == \"$1\" ];then return fi done return 1&#125; 主函数流程 无参数 列出配置文件中所有经常的运行信息 -g GroupName 列出GroupName组内的所有进程 process_name1 列出指定进程的运行信息 代码实现1234567891011121314151617181920212223242526if [ $# -gt 0 ];then if [ \"$1\" == \"-g\" ];then shift for gn in $@; do for pn in `get_all_process_group $gn` do is_process_in_config $pn &amp;&amp; format_print $pn $gn done done else for pn in $@ do gn=`get_group_by_process $pn` is_process_in_config $pn &amp;&amp; format_print $pn $gn done fielse for pn in `get_all_process` do gn=`get_group_by_process $pn` #echo `is_process_in_config $pn` is_process_in_config $pn &amp;&amp; format_print $pn $gn donefi 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#!/bin/bash## Func:Get process statues in process.cfg# define variablesHOME_DIR=\"/home/frdqy/shell/day_06/\"CONFIG_FILE=\"process.cfg\"this_pid=$$function get_all_group&#123; G_LIST=`sed -n '/\\[GROUP_LIST\\]/,/\\[/p' $HOME_DIR/$CONFIG_FILE| egrep -v \"(^$|^\\[)\"` echo $G_LIST&#125;function get_all_process&#123; for g in `get_all_group`; do P_LIST=`sed -n '/\\['$g'/,/^\\[/p' $HOME_DIR/$CONFIG_FILE | egrep -v \"(^$|^\\[)\"` echo $P_LIST done&#125;function get_process_pid_by_name&#123; if [ $# -ne 1 ];then return 1 else pids=`ps -ef | grep $1 | grep -v grep |grep -v $this_pid | awk '&#123;print $2&#125;'` echo $pids fi&#125;function get_process_info_by_pid&#123; if [ `ps -ef | awk -v pid=$1 '$2==pid&#123;print&#125;' | wc -l` -eq 1 ];then proc_statues=\"RUNNING\" else proc_statues=\"STOPED\" fi pro_cpu=`ps aux | awk -v pid=$1 '$2==pid&#123;print $3&#125;'` pro_mem=`ps aux | awk -v pid=$1 '$2==pid&#123;print $4&#125;'` pro_stat_time=`ps -p $1 -o lstart | grep -v STARTED`&#125;function is_group_in_config&#123; for gn in `get_all_group`; do if [ \"$gn\" == \"$1\" ];then return fi done return 1&#125;function get_all_process_group&#123; is_group_in_config $1 if [ $? -eq 0 ];then p_list=`sed -n \"/\\[$1/,/\\[/p\" $HOME_DIR/$CONFIG_FILE | egrep -v \"(^$|^#|^\\[)\"` echo $p_list else echo \"GroupName $1 is not in process.cfg\" fi&#125;function get_group_by_process&#123; for gn in `get_all_group` do for pn in `get_all_process_group $gn` do if [ \"$pn\" == \"$1\" ];then echo $gn fi done done&#125;function format_print&#123; ps -ef | grep $1 | grep -v grep | grep -v $this_pid &amp;&gt; /dev/null if [ $? -eq 0 ];then pids=`get_process_pid_by_name $1` for pid in $pids do get_process_info_by_pid $pid awk -v p_name=$1 -v g_name=$2 -v p_id=$pid -v p_status=$proc_statues -v p_cpu=$pro_cpu -v p_mem=$pro_mem -v p_start_time=\"$pro_stat_time\" 'BEGIN&#123;printf \"%-20s%-15s%-15s%-15s%-15s%-15s%-15s\\n\",p_name,g_name,p_id,p_status,p_cpu,p_mem,p_start_time&#125;' done else awk -v p_name=$1 -v g_name=$2 'BEGIN&#123;printf \"%-20s%-15s%-15s%-15s%-15s%-15s%-15s\\n\",p_name,g_name,\"NULL\",\"NULL\",\"NULL\",\"NULL\",\"NULL\"&#125;' fi &#125;function is_process_in_config&#123; for pn in `get_all_process` do if [ \"$pn\" == \"$1\" ];then return fi done return 1&#125;if [ $# -gt 0 ];then if [ \"$1\" == \"-g\" ];then shift for gn in $@; do for pn in `get_all_process_group $gn` do is_process_in_config $pn &amp;&amp; format_print $pn $gn done done else for pn in $@ do gn=`get_group_by_process $pn` is_process_in_config $pn &amp;&amp; format_print $pn $gn done fielse for pn in `get_all_process` do gn=`get_group_by_process $pn` #echo `is_process_in_config $pn` is_process_in_config $pn &amp;&amp; format_print $pn $gn donefi 小结至此，shell编程的专项学习告一段落，下面的练习都将在学习其他知识时进行巩固。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}],"author":"Frdqy"},{"title":"Shell编程之（六）：mysql","slug":"Shell编程之（六）：mysql","date":"2019-12-30T07:54:12.000Z","updated":"2019-12-30T07:57:06.178Z","comments":true,"path":"2019/12/30/Shell编程之（六）：mysql/","link":"","permalink":"http://yoursite.com/2019/12/30/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9Amysql/","excerpt":"安装mariadb1sudo apt-get install mariadb-server","text":"安装mariadb1sudo apt-get install mariadb-server 测试实例建表脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758--student.sql--create tables--student tablescreate table &#96;student&#96;( &#96;s_id&#96; varchar(20), &#96;s_name&#96; varchar(20) not null default &#39;&#39;, &#96;s_birth&#96; varchar(20)not null default &#39;&#39;, &#96;s_sex&#96; varchar(20) not null default &#39;&#39;, primary key(&#96;s_id&#96;));--course tablescreate table &#96;course&#96;( &#96;c_id&#96; varchar(20), &#96;c_name&#96; varchar(20)not null default &#39;&#39;, &#96;t_id&#96; varchar(20) not null, primary key(&#96;c_id&#96;));--teacher tablecreate table &#96;teacher&#96;( &#96;t_id&#96; varchar(20), &#96;t_name&#96; varchar(20)not null default &#39;&#39;, primary key(&#96;t_id&#96;));--score tablecreate table &#96;score&#96;( &#96;s_id&#96; varchar(20), &#96;c_id&#96; varchar(20), &#96;s_score&#96; int(3), primary key(&#96;s_id&#96;,&#96;c_id&#96;));--insert student tableinsert into student values(&#39;1001&#39;,&#39;zhaolei&#39;,&#39;1990-1001-1001&#39;,&#39;male&#39;);insert into student values(&#39;1002&#39;,&#39;lihang&#39;,&#39;1990-12-21&#39;,&#39;male&#39;);insert into student values(&#39;1003&#39;,&#39;yanwen&#39;,&#39;1990-1005-20&#39;,&#39;male&#39;);insert into student values(&#39;1004&#39;,&#39;hongfei&#39;,&#39;1990-1008-1006&#39;,&#39;male&#39;);insert into student values(&#39;1005&#39;,&#39;ligang&#39;,&#39;1991-12-1001&#39;,&#39;female&#39;);insert into student values(&#39;1006&#39;,&#39;zhousheng&#39;,&#39;1992-1003-1001&#39;,&#39;female&#39;);insert into student values(&#39;1007&#39;,&#39;wangjun&#39;,&#39;1989-1007-1001&#39;,&#39;female&#39;);insert into student values(&#39;1008&#39;,&#39;zhoufei&#39;,&#39;1990-1001-20&#39;,&#39;female&#39;);--insert course tableinsert into teacher values(&#39;1001&#39;,&#39;aidisheng&#39;);insert into teacher values(&#39;1002&#39;,&#39;aiyinsitan&#39;);insert into teacher values(&#39;1003&#39;,&#39;qiansanqiang&#39;);--insert score tableinsert into score values(&#39;1001&#39;,&#39;1001&#39;,80);insert into score values(&#39;1001&#39;,&#39;1002&#39;,90);insert into score values(&#39;1001&#39;,&#39;1003&#39;,99);insert into score values(&#39;1002&#39;,&#39;1001&#39;,70);insert into score values(&#39;1002&#39;,&#39;1002&#39;,60);insert into score values(&#39;1002&#39;,&#39;1003&#39;,80);insert into score values(&#39;1003&#39;,&#39;1001&#39;,80);insert into score values(&#39;1003&#39;,&#39;1002&#39;,80);insert into score values(&#39;1003&#39;,&#39;1003&#39;,50);insert into score values(&#39;1004&#39;,&#39;1001&#39;,20);insert into score values(&#39;1004&#39;,&#39;1002&#39;,30); 建数据库1create database school; 导入数据1mysql school &lt; student.sql 授权用户1234--授予dbuser用户在所有网段都可以对school数据库进行操作，密码为123456grant all on school.* to dbuser@&#39;%&#39; identified by &#39;123456&#39;grant all on school.* to dbuser@&#39;localhost&#39; identified by &#39;123456&#39;--&#39;%&#39;表示所有主机都可以访问 使用授权用户登录12--u和p与参数间可以省略mysql -udbuser -p123456 -h localhost mysql命令参数 命令 含义 -u 用户名 -p 用户密码 -h 服务器ip地址 -D 链接的数数据库 -N 不输出列信息 -B 使用tab键代替默认交互分隔符 -e 执行sql语句 -E 垂直输出 -H 以HTML格式输出 -X 以XML格式输出 注意 -B用来不显示周围一圈分隔符时建议放在选项最后，在-e之前。 查询实例 写一个脚本，该脚本可以接收一个参数，参数为需要执行的sql语句 123#!/bin/bash#mysql -u dbuser -p123456 -D school -e \"$1\" 查询mysql任意表的数据，并将查询到的结果保存到HTML文件中 123#!/bin/bash#mysql -u dbuser -p123456 -D school -H -e \"$1\" &gt; $2 查询mysql任意表的数据，并将查询到的结果保存到XML文件中 123#!/bin/bash#mysql -u dbuser -p123456 -D school -X -e \"$1\" &gt; $2 导入实例需求一处理文本中的数据，将文本中的数据插入mysql ​ 1010 jerry 1991-12-13 male ​ 1011 mike 1991-12-13 female ​ 1012 tracy 1991-12-13 male ​ 1013 kobe 1991-12-13 female ​ 1014 allen 1991-12-13 male ​ 1015 curry 1991-12-13 male ​ 1016 tom 1991-12-13 female 123456789101112#!/bin/bash#user=\"dbuser\"passwd=\"123456\"database=\"school\"mysql_conn=\"mysql -u\"$user\" -p\"$passwd\"\"cat data.txt | while read id name birth sexdo $mysql_conn -D $database -e \"insert into student1 values('$id','$name','$birth','$sex')\"done 需求二同上，但是分隔符变了 ​ 1010|jerry|1991-12-13|male ​ 1011|mike|1991-12-13|female ​ 1012|tracy|1991-12-13|male ​ 1013|kobe|1991-12-13|female ​ 1014|allen|1991-12-13|male ​ 1015|curry|1991-12-13|male ​ 1016|tom|1991-12-13|female 123456789101112131415#!/bin/bash#user=\"dbuser\"passwd=\"123456\"database=\"school\"#mysql_conn=\"mysql -u\"$user\" -p\"$passwd\"\"#输入分隔符指定IFS=\"|\"cat data2.txt | while read id name birth sexdo mysql -u \"dbuser\" -p\"$passwd\" -D $database -e \"insert into student2 values('$id','$name','$birth','$sex')\"done 注意需求二有一个坑，在于注释的sql语句那样写在变量里会提示找不到命令，可能时管道符号冲突问题，shll真不规范！！ mysqldump备份语法格式1mysqldump [OPTIONS] database [tables] 命令参数 命令 含义 -u 用户名 -p 密码 -h 服务器IP地址 -d 等价于–no-data，只导出表结构 -t 等价于–no-create-info，只导出数据，不导出建表语句 -A 等价于–all-databases -B 等价于–databases，导出一个或多个数据库 需求将school中的score备份，并且将备份数据通过ftp传输到xxx.xxx.xxx.xxx的/data/backup目录下 补充知识 open xxx.xxx.xxx.xxx：用于打开远端连接 user 用户名 密码：用于登录 -i：不交互 -n：自动登录 -v：显示详细信息 &lt;&lt; EOF：表示下面将输入长命令，直到遇到EOF结束，且EOF最后一行必须顶格写 12345678910111213141516171819202122232425262728#!/bin/bash#db_user=\"dbuser\"db_passwd=\"123456\"ftp_user=\"ftp_user\"ftp_passwd=\"redhat\"ftp_host=\"192.168.184.3\"dst_dir=\"/data/backup\"time_date=\"`date +%Y%m%d%H%M%S`\"file_name=\"school_score_$&#123;time_date&#125;.sql\"function auto_ftp&#123; ftp -niv &lt;&lt; EOF open $ftp_host user $ftp_user $ftp_passwd cd $dst_dir put $1 byeEOF&#125;mysqldump -u\"$db_user\" -p\"$db_passwd\" school score &gt; ./$file_name &amp;&amp; auto_ftp ./$file_name","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}],"author":"Frdqy"},{"title":"Shell编程之（五）：awk","slug":"Shell编程之（五）：awk","date":"2019-12-29T13:09:12.000Z","updated":"2019-12-30T07:58:27.704Z","comments":true,"path":"2019/12/29/Shell编程之（五）：awk/","link":"","permalink":"http://yoursite.com/2019/12/29/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9Aawk/","excerpt":"简介awk是一个文本处理工具，通常用于处理数据并生成结果报告。 语法格式12awk 'BEGIN&#123;&#125;pattern&#123;commands&#125;END&#123;&#125;' file_namestdout | awk 'BEGIN&#123;&#125;pattern&#123;commands&#125;END&#123;&#125;'","text":"简介awk是一个文本处理工具，通常用于处理数据并生成结果报告。 语法格式12awk 'BEGIN&#123;&#125;pattern&#123;commands&#125;END&#123;&#125;' file_namestdout | awk 'BEGIN&#123;&#125;pattern&#123;commands&#125;END&#123;&#125;' 语法格式说明 语法格式 解释 BEGIN{} 正式处理数据之前执行 pattern 匹配模式 {commands} 处理命令，可能多行 END{} 处理完所有匹配数据后执行 内置变量对照表 内置变量 含义 $0 整行内容 $1-$n 当前行的第1-n个字段 NF(Number Field) 当前行的字段个数 NR(Number Row) 当前行行号，从1开始 FNR(File Number Row) 多文件每个文件行号单独计数，从0开始 FS(Field Separator) 输入字段分隔符，默认空格或tab RS(Row Separator) 输入行分隔符，默认回车换行 OFS(Output Field Separator) 输出字段分隔符，默认空格 ORS(Output Row Separator) 输出行分隔符，默认回车换行 FILENAME 当前输入的文件名字 ARGC 命令行参数个数 ARGV 命令行参数数组 printf详解printf格式说明符 格式符 含义 %s 打印字符串 %d 打印十进制数 %f 打印浮点数 %x 打印十六进制数 %o 打印八进制数 %e 打印数字科学计数法形式 %c 打印单个字符的ASCII printf修饰符 修饰符 含义 - 左对齐 + 右对齐 # 八进制加0，十六进制加0x 格式符实例 以字符串格式打印/etc/passwd中的第7个字段，以”:”作为分隔符 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;printf \"%s\\n\",$7&#125;' /etc/passwd 以10进制格式打印/etc/passwd中的第3个字段，以”:”作为分隔符 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;printf \"%d\\n\",$3&#125;' /etc/passwd 以浮点数进制格式打印/etc/passwd中的第3个字段，以”:”作为分隔符，小数点保留2位 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;printf \"%0.2f\\n\",$3&#125;' /etc/passwd 以16进制格式打印/etc/passwd中的第3个字段，以”:”作为分隔符 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;printf \"%#x\\n\",$3&#125;' /etc/passwd 以8进制格式打印/etc/passwd中的第3个字段，以”:”作为分隔符 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;printf \"%#o\\n\",$3&#125;' /etc/passwd 以科学技术格式打印/etc/passwd中的第3个字段，以”:”作为分隔符 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;printf \"%e\\n\",$3&#125;' /etc/passwd 模式匹配语法格式 语法格式 含义 /RegExp/ 按正则匹配 关系运算 按关系匹配 正则实例 匹配/etc/passwd文件行中包含有root字符串的所有行 1awk 'BEGIN&#123;FS=\":\"&#125;/root/&#123;printf \"%s\\n\",$0&#125;' /etc/passwd 匹配/etc/passwd文件行中以frdqy开头的所有行 1awk 'BEGIN&#123;FS=\":\"&#125;/^frdqy/&#123;printf \"%s\\n\",$0&#125;' /etc/passwd 关系实例 以:为分隔符，匹配/etc/passwd文件中第3个字段小于50的所有行信息 1awk 'BEGIN&#123;FS=\":\"&#125;$3&lt;50&#123;printf \"%d\\n\",$3&#125;' /etc/passwd 以:为分隔符，匹配/etc/passwd文件中第3个字段大于50的所有行信息 1awk 'BEGIN&#123;FS=\":\"&#125;$3&gt;50&#123;printf \"%d\\n\",$3&#125;' /etc/passwd 以:为分隔符，匹配/etc/passwd文件中第7个字段为/bin/bash的所有行信息 1awk 'BEGIN&#123;FS=\":\"&#125;$7==\"/bin/bash\"&#123;printf \"%s\\n\",$7&#125;' /etc/passwd 以:为分隔符，匹配/etc/passwd文件中第7个字段不为/bin/bash的所有行信息 1awk 'BEGIN&#123;FS=\":\"&#125;$7!=\"/bin/bash\"&#123;printf \"%s\\n\",$7&#125;' /etc/passwd 以:为分隔符，匹配/etc/passwd文件中第3个字段包含3个以上数字的所有行信息 12awk 'BEGIN&#123;FS=\":\"&#125;$3~/[0-9]&#123;3,&#125;/&#123;printf \"%s\\n\",$0&#125;' /etc/passwd#~表示匹配正则，!~表示不匹配正则 布尔实例 以:为分隔符，匹配/etc/passwd文件中包含root或frdqy的所有 1awk 'BEGIN&#123;FS=\":\"&#125;$1==\"root\" || $1==\"frdqy\"&#123;printf \"%s\\n\",$0&#125;' /etc/passwd 以:为分隔符，匹配/etc/passwd文件中第3个字段小于50并且第4个字段大于50的所有行 1awk 'BEGIN&#123;FS=\":\"&#125;$3&lt;50 &amp;&amp; $4&gt;50&#123;printf \"%s\\n\",$0&#125;' /etc/passwd 动作算术运算符 运算符 含义 + 加 - 减 * 乘 除 / % 模 ^或** 乘方 ++x 返回变量x之前+1 x++ 返回变量x之后+1 x+=y x=x+y 算数实例 使用awk计算/etc/services中空白行的数量 1awk '/^$/&#123;sum++&#125;END&#123;printf \"%d\\n\",sum&#125;' /etc/services 计算下列每个同学的平均分数，将其打印在最后一列后 Allen,80,90,96,98 Mike,93,98,92,91 Zhang,78,76,87,92 Jerry,86,89,68,92 Li,78,88,98,100 1awk 'BEGIN&#123;FS=\",\"&#125;&#123;sum=$2+$3+$4+$5;avg=sum/(NF-1);printf \"%-8s%-8d%-8d%-8d%-8d%-0.2f\\n\",$1,$2,$3,$4,$5,avg&#125;' ./student.txt 条件语句123456if(条件表达式) 动作1else if(条件表达式) 动作2else 动作3 条件实例 以:为分隔符，只打印/etc/passwd中第3个字段的数值在50-100范围内的行信息 1awk 'BEGIN&#123;FS=\":\"&#125;&#123;if($3&lt;=100&amp;&amp;$3&gt;=50)print $0&#125;' /etc/passwd 计算下列每个学生的平均分数，并且只打印平均分大于90的学生姓名和分数信息 Allen,80,90,96,98 Mike,93,98,92,91 Zhang,78,76,87,92 Jerry,86,89,68,92 Li,78,88,98,100 12345678910111213#过长，写在scripts.awk中BEGIN&#123; FS=\",\" &#125;&#123; sum=$2+$3+$4+$5; avg=sum/(NF-1); if(avg&gt;90) printf \"%-8s%-8d%-8d%-8d%-8d%-0.2f\\n\",$1,$2,$3,$4,$5,avg&#125;#用-f选项调用awk -f ./scripts.awk ./student.txt 循环语句-while12while(条件表达式) 动作 循环语句-do while123do 动作while(条件表达式) 循环语句-for12for(初始化计数器;测试计数器;计数器变更) 动作 循环实例 计算1+2+…+100的和，使用while、do while、for三种实现 1234567891011121314151617181920212223242526272829#whileBEGIN&#123; while(i&lt;=100) &#123; sum+=i; i++; &#125; print sum&#125;#do-whileBEGIN&#123; i=0; do &#123; i++ sum+=i &#125;while(i&lt;100) print sum&#125;#forBEGIN&#123; for(i=0;i&lt;=100;i++) &#123; sum+=i; &#125; print sum&#125; 字符串函数 函数名 解释 函数返回值 length 计算字符串长度 整数长度值 index(str1,str2) 在str1中找str2位置 返回索引，从1开始 tolower(str) 转换为小写 转换后的字符串 toupper(str) 转换为大写 转换后的字符串 substr(str,m,n) 从str的m个字符开始，截取n位 截取后的子串 match(str,RE) 在str中按RE查找 返回索引 split(str,arr,fs) 按fs切割字符串，结果存arr中 切割后的子串个数 sub(RE,repStr,str) 在str中找符合RE的子串，将其换为repStr，换一个 替换个数 gsub(RE,repStr,str) 在str中找符合RE的子串，将其换为repStr，换所有 替换个数 字符串处理实例 以:为分隔符，返回/etc/passwd中每行每个字段的长度 1234567891011121314151617BEGIN&#123; FS=\":\" &#125;&#123; for(i=1;i&lt;=NF;i++) &#123; if(i!=NF) &#123; printf \"%d:\",length($i) &#125; if(i==NF) &#123; printf \"%d\",length($i) printf \"\\n\" &#125; &#125;&#125; 搜索字符串”I have a dream”中出现”ea”字符串的位置 1234567891011#indexBEGIN&#123; i=index(\"I have a dream\",\"ea\") print i&#125;#match,可见match功能包含了indexBEGIN&#123; i=index(\"I have a dream\",\"ea\") print i&#125; 将字符串”Hadoop is a bigdata Framework”全部转换为小写 1234BEGIN&#123; str=tolower(\"Hadoop is a bigdata Framework\") print str&#125; 将字符串”Hadoop is a bigdata Framework”全部转换为大写 1234BEGIN&#123; str=toupper(\"Hadoop is a bigdata Framework\") print str&#125; 将字符串”Hadoop Kafka Spark Storm HDFS YARN Zookeeper”分割保存到数组arr中 12345678910BEGIN&#123; str=\"Hadoop Kafka Spark Storm HDFS YARN Zookeeper\" len=split(str,arr,\" \") i=1 while(i&lt;=len) &#123; print arr[i] i++ &#125;&#125; 搜素字符串”Transaction 2345 Start:Select * from master”第一个数字出现的位置 12345BEGIN&#123; str=\"Transaction 2345 Start:Select * from master\" i=match(str,\"[0-9]\") print i&#125; 截取字符串”Transaction start”的子串，截取条件从第4个字符开始，截取5位 12345BEGIN&#123; str=\"Transaction start\" str1=substr(str,4,5) print str1&#125; 替换字符串”Transaction 243 Start,Event ID:9002”中第一个匹配到数字串替换为$符号 12345BEGIN&#123; str=\"Transaction 243 Start,Event ID:9002\" sub(\"[0-9]+\",\"$\",str) print str&#125; 替换字符串”Transaction 243 Start,Event ID:9002”中所有匹配到数字串替换为$符号 12345BEGIN&#123; str=\"Transaction 243 Start,Event ID:9002\" gsub(\"[0-9]+\",\"$\",str) print str&#125; 选项 选项 解释 -v 参数传递 -f 指定脚本文件 -F 指定分隔符 -V 查看awk版本号 注意1234567#在使用参数传递时，引用变量建议全部使用\"\"，否则如果引用的字符串内出现空格则会报错。num=20var=\"Hello World\"#下面命令会报错，原因在于var变量字符串包含空格awk -v num2=$num -v var1=$var 'BEGIN&#123;print num2,var1&#125;'#遇到上述问题需要将引用用\"\"包含起来awk -v \"num2=$num\" -v \"var1=$var\" 'BEGIN&#123;print num2,var1&#125;' 数组shell中数组的用法1234567#定义,各元素用空格或tab分隔array=(\"Allen\" \"Mike\" \"Messi\")#遍历for a in $&#123;array[@]&#125;do echo $adone 命令 含义 echo ${array[2]} 打印元素 echo ${ #array[@]} 打印元素个数 echo ${ #array[3]} 打印元素长度 array[3]=”Li” 数组元素赋值 unset array[2];unset array 删除元素 echo ${array[@]:1:3} 分片访问 ${array[@]/e/E} 替换第一个e为E ${array[@]//e/E} 替换所有的e为E awk中数组的用法既可以数字作为数组下标也可以字符串作为数组下标 12345678910111213141516#检测数组第i+1下标是否存在if i in array#删除某个数组元素delete array[i]#删除整个数组delete array#for循环语法格式1for(初始化; 布尔表达式; 更新) &#123;//代码语句&#125; #for循环语法格式2for(变量 in 数组) &#123;//代码语句&#125; 数组实例 统计主机上所有的TCP连接状态数，按照每个TCP状态分类 1netstat -an | grep tcp | awk '&#123;array[$6]++&#125;END&#123;for(a in array) print a,array[a]&#125;' 计算横向数据总和，计算纵向数据总和 allen 80 90 87 91 mike 78 86 93 96 Kobe 66 92 82 78 Jerry 98 74 66 54 Wang 87 21 100 43 1234567891011121314151617BEGIN&#123; printf \"%-10s%-10s%-10s%-10s%-10s%-10s\\n\",\"Name\",\"Yuwen\",\"Math\",\"English\",\"Physical\",\"total\"&#125;&#123; total=$2+$3+$4+$5 sum+=total i=2 while(i&lt;=NF) &#123; array[i]+=$i i++ &#125; printf \"%-10s%-10d%-10d%-10d%-10d%-10d\\n\",$1,$2,$3,$4,$5,total&#125;END&#123; printf \"%-10s%-10d%-10d%-10d%-10d%-10d\\n\",\"sum_c\",array[2],array[3],array[4],array[5],sum&#125; 实战演练模拟脚本123456789101112131415161718192021222324#!/bin/bash#数据生成脚本，模拟大型数据function create_random&#123; min=$1 max=$(($2-$min+1)) num=`date +%s%N` echo $(($num%$max+$min))&#125;INDEX=1while truedo for user in allen mike jerry tracy han lilei do COUNT=$RANDOM NUM1=`create_random 1 $COUNT` NUM2=`expr $COUNT - $NUM1` echo \"`date '+%Y-%m-%d %H:%M:%S'` $INDEX Batches: user $user insert $COUNT records into database:product table:detal, insert $NUM1 records successfully,failed $NUM2 records\" &gt;&gt; ./db.log.`date +%Y%m%d` INDEX=`expr $INDEX + 1` donedone 需求及解决方案 统计每个人分别插入多少条record进数据库 1234567&#123; array[$6]+=$8&#125;END&#123; for (i in array) printf \"%-10s%-10d\\n\",i,array[i]&#125; 统计每个人分别插入成功多少record，失败多少record 12345678910&#123; array[$6]+=$14 array1[$6]+=$17&#125;END&#123; for (i in array) printf \"%-10s %-10d successed!\\n\",i,array[i] for (j in array1) printf \"%-10s %-10d Failed!\\n\",j,array[j]&#125; 将1和2结合起来一起输出 1234567891011121314BEGIN&#123; printf \"%-20s%-20s%-20s%-20s\\n\",\"Name\",\"Sum\",\"Successed\",\"Failed\"&#125;&#123; array[$6]+=$8 array1[$6]+=$14 array2[$6]+=$17&#125;END&#123; for (i in array) &#123; printf \"%-20s%-20d%-20d%-20d\\n\",i,array[i],array1[i],array2[i] &#125;&#125; 在3结尾加上统计全部插入记录、失败记录数、成功记录数 123456789101112131415161718BEGIN&#123; printf \"%-20s%-20s%-20s%-20s\\n\",\"Name\",\"Sum\",\"Successed\",\"Failed\"&#125;&#123; array[$6]+=$8 array1[$6]+=$14 array2[$6]+=$17&#125;END&#123; for (i in array) &#123; total_sum+=array[i] total_successed+=array1[i] total_failed+=array2[i] printf \"%-20s%-20d%-20d%-20d\\n\",i,array[i],array1[i],array2[i] &#125; printf \"%-20s%-20d%-20d%-20d\\n\",\"total\",total_sum,total_successed,total_failed&#125; 查找丢失数据的现象(成功+失败不等于插入的记录数) 1234&#123; if($8!=$14+$17) print $0&#125;","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"awk","slug":"awk","permalink":"http://yoursite.com/tags/awk/"}],"author":"Frdqy"},{"title":"Shell编程之（四）：sed","slug":"Shell编程之（四）：sed","date":"2019-12-28T12:48:41.000Z","updated":"2020-01-03T11:35:41.973Z","comments":true,"path":"2019/12/28/Shell编程之（四）：sed/","link":"","permalink":"http://yoursite.com/2019/12/28/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9Ased/","excerpt":"基础介绍sed(Stream Editor)，流编辑器。对标准输出或文件逐行进行处理(修改、删除、打印等)。","text":"基础介绍sed(Stream Editor)，流编辑器。对标准输出或文件逐行进行处理(修改、删除、打印等)。 pattern space模式空间，每一个被pattern所匹配到的行都放到pattern space中等待进一步处理 hold space保持空间，内存中另一块可以存放sed匹配行的空间，可以使操作更灵活。但主要是用来炫技，实际很少使用。 语法格式123sed [option] \"pattern command\" file #对文件逐行操作stdout | sed [option] \"pattern command\" #对标注输出逐行操作#sed用parttern来匹配每一行，如果某一行符合pattern模式被匹配到，就用command对那一行进行执行 sed选项 选项 含义 -n 只打印模式匹配行(静默模式) -e 直接在命令行进行sed编辑,默认选项;适用于多个匹配模式和命令 -f 编辑动作保存在文件中，指定文件执行 -r 支持扩展正则表达式 -i 直接修改文件内容 pattern用法 匹配模式 含义 10command 匹配到第10行 10,20command 匹配从第10行开始，到第20行结束 10,+5command 匹配从第10行开始，到第16行结束 /pattern1/command 匹配到pattern1的行 /pattern1/,/pattern2/command 匹配到pattern1开始，pattern2结束的行 10,/pattern1/command 匹配从第10行开始，到匹配到pattern1的行结束 /pattern1/,10command 匹配到pattern1的行开始到第10行结束 1~2command 步长为2：从第一行开始每两行执行一次 编辑命令对照表查询 编辑命令 含义 p 打印 增加 编辑命令 含义 a 往后追加 i 往前追加 r 外部文件读入，行后追加 w 匹配行写入外部文件 删除 编辑命令 含义 d 删除 修改 编辑命令 含义 s/old/new 将行内第一个old替换为new s/old/new/g 将行内全部的old替换为new s/old/new/2g 将行内从第两个old开始到最后所有的old替换为new s/old/new/ig 将行内old全部替换为new，忽略大小写 其他 编辑命令 含义 = 显示行号 n 覆盖读取下一行 N 追加读取下一行 h 把模式空间的内容覆盖至保持空间 H 把模式空间的内容追加至保持空间 g 把保持空间的内容覆盖至模式空间 G 把保持空间的内容追加至模式空间 x 把模式空间与保持空间内容互换 ！ 条件取反，例如！1表示除了第一行 后向引用12345&amp; #引用匹配的整个串\\1 #引用匹配的第一个分组，需要&quot;()&quot;将待匹配括起来#例如： sed &#39;s&#x2F;\\(l..e\\)&#x2F;\\1r&#x2F;g&#39; #表示将以l开头e结尾的四字串替换为结尾加e#注意：&amp;只能匹配整个串，而\\1可以匹配一部分串，更加灵活 注意事项当写脚本时使用sed匹配模式中包含变量时，要用双引号将整个匹配模式括起来。也可以对引用变量使用单引号单独括起来，效果一样。 查询实例 打印/etc/passwd中第20行内容 1sed -n '20p' /etc/passwd 打印/etc/passwd中从第8行开始，到第15行结束的内容 1sed -n '8,15p' /etc/passwd 打印/etc/passwd中从第8行开始，然后+5行结束的内容 1sed -n '8,+5p' /etc/passwd 打印/etc/passwd中开头匹配frdqy字符串的内容 1sed -n '/^frdqy/p' /etc/passwd 打印/etc/passwd中开头为root的行开始，到开头为frdqy的行结束的内容 1sed -n '/^root/,/^frdqy/p' /etc/passwd 打印/etc/passwd中第8行开始，到含有/sbin/nologin的内容的行结束的内容 1sed -n '8,/\\/sbin\\/nologin/p' /etc/passwd 打印/etc/passwd中第一个包含/bin/bash内容的行开始，到第五行结束的内容 1sed -n '/\\/bin\\/bash/,5p' /etc/passwd 删除实例 删除/etc/passwd中的第15行 1sed -i '15d' /etc/passwd 删除/etc/passwd中的第8行到第14行的所有内容 1sed -i '8,14d' /etc/passwd 删除/etc/passwd中的不能登录的用户(/sbin/nologin) 1sed -i '/\\/sbin\\/nologin/d' /etc/passwd 删除/etc/passwd中以mail开头的行，到以backup开头的行的所有内容 1sed -i '/^mail/,/^backup/d' /etc/passwd 删除/etc/passwd中第一个不能登录的用户，到第13行的所有内容 1sed -i '/\\/sbin\\/nologin/,13d' /etc/passwd 删除/etc/passwd中第5行到以ftp开头的所有行的内容 1sed -i '5,/^ftp/d' /etc/passwd 删除/etc/passwd中以backup开头的行到最后行的所有内容 1sed -i '/^backup/,$d' /etc/passwd 删除配置文件的注释行和空行 1234sed -i '/^#/d;/^$/d'#只能删除#在开头的注释，例如代码内部注释就删不了。sed -i '/^[:blank:]*#/d' ./nginx#只删除代码内部的注释 在配置文件中所有不以#开头的行前面添加*符号，注意：以#开头的行不添加 12sed -i 's/^[^#]/\\*&amp;/g' ./nginx#中括号外的^表示行首，中括号内的^表示取反，即不取中括号内的值。 修改实例 修改/etc/passwd中第1行中第一个root为ROOT 1sed -i '1s/root/ROOT/' /etc/passwd 修改/etc/passwd中第5行到第10行中所有的/sbin/nologin为/bin/bash 1sed -i '5,10/\\/sbin\\/nologin/\\/bin\\/bash/g' /etc/passwd 修改/etc/passwd中匹配到/sbin/nologin的行，将匹配到行中的login改为大写LOGIN 1sed -i 's/\\(\\/sbin\\/no\\)login/\\1LOGIN/g' /etc/passwd 修改/etc/passwd从匹配到以root开头的行，到匹配到行中包括mail的所有行，将bin改为dqy 1sed -i '/^root/,/mail/s/bin/dqy/g' /etc/passwd 修改/etc/passwd从匹配到以root开头的行，到第15行中所有行的nologin修改为frdqy 1sed -i '/^root/,15s/nologin/frdqy/g' /etc/passwd 修改/etc/passwd从第15行开始，到匹配到以frdqy开头的所有行的bin修改为BIN 1sed -i '15,/^frdqy/s/bin/BIN/g' /etc/passwd 追加实例 在/etc/passwd文件第10行后面追加”Add Line Behind” 1sed -i '10a Add Line Behind' /etc/passwd 在/etc/passwd文件第10行到第20行，每行后面追加”Test Line Behind” 1sed -i '10,20a Test Line Behind' /etc/passwd 在/etc/passwd文件匹配到/bin/bash的行后追加”Insert Line For /bin/bash Behind” 1sed -i '/\\/bin\\/bash/a Insert Line For /bin/bash Behind' /etc/passwd 在/etc/passwd文件匹配到以gdm开头的行，在匹配行前面追加”Add Line Before” 1sed -i '/^gdm/i Add Line Before' /etc/passwd 在/etc/passwd文件每一行前面都追加”Insert Line Before Every Line” 1sed -i 'i Insert Line Before Every Line' /etc/passwd 将/etc/fstab文件内容追加到/etc/passwd文件第 20行后 1sed -i '20r /etc/fstab' /etc/passwd 将/etc/inittab文件内容追加到/etc/passwd文件匹配/sbin/nologin行后 1sed -i '/\\/sbin\\/nologin/r /etc/inittab' /etc/passwd 将/etc/vconsole.conf文件内容追加到/etc/passwd文件匹配以sync开头到18行的所有行后 1sed -i '/^sync/,18r /etc/vconsole.conf' /etc/passwd 将/etc/passwd文件匹配到/bin/bash的行追加到/tmp/sed.txt中 1sed -i '/\\/bin\\/bash/w /tmp/sed.txt' /etc/passwd 将/etc/passwd文件从第10行开始到匹配到frdqy开头的所有行追加到/tmp/sed_1.txt中 1sed -i '10,/^frdqy/w /tmp/sed_1.txt' /etc/passwd","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"sed","slug":"sed","permalink":"http://yoursite.com/tags/sed/"}],"author":"Frdqy"},{"title":"正则知识补充","slug":"正则知识补充","date":"2019-12-27T14:19:00.000Z","updated":"2019-12-28T00:46:28.925Z","comments":true,"path":"2019/12/27/正则知识补充/","link":"","permalink":"http://yoursite.com/2019/12/27/%E6%AD%A3%E5%88%99%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/","excerpt":"123456^ #行首$ #行尾\\&lt; #词首\\&gt; #词尾\\b #单词边界\\B #单词非边界","text":"123456^ #行首$ #行尾\\&lt; #词首\\&gt; #词尾\\b #单词边界\\B #单词非边界 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# #表示前面的字符连续出现任意次，包括0次。. #表示任意单个字符。.* #表示任意长度的任意字符，与通配符中的*的意思相同。\\? #表示匹配其前面的字符0或1次\\+ #表示匹配其前面的字符至少1次，或者连续多次，连续次数上不封顶。\\&#123;n\\&#125; #表示前面的字符连续出现n次，将会被匹配到。\\&#123;x,y\\&#125; #表示之前的字符至少连续出现x次，最多连续出现y次，都能被匹配到，换句话说，只要之前的字符连续出现的次数在x与y之间，即可被匹配到。\\&#123;,n\\&#125; #表示之前的字符连续出现至多n次，最少0次，都会陪匹配到。\\&#123;n,\\&#125; #表示之前的字符连续出现至少n次，才会被匹配到.. #表示匹配任意单个字符S* #表示匹配前面的字符任意次，包括0次[ ] #表示匹配指定范围内的任意单个字符[^ ] #表示匹配指定范围外的任意单个字符 [[:alpha:]] #表示任意大小写字母[[:lower:]] #表示任意小写字母[[:upper:]] #表示任意大写字母[[:digit:]] #表示0到9之间的任意单个数字（包括0和9）[[:alnum:]] #表示任意数字或字母[[:space:]] #表示任意空白字符，包括&quot;空格&quot;、&quot;tab键&quot;等。[[:punct:]] #表示任意标点符号 [0-9]与[[:digit:]]等效[a-z]与[[:lower:]]等效[A-Z]与[[:upper:]]等效[a-zA-Z]与[[:alpha:]]等效[a-zA-Z0-9]与[[:alnum:]]等效 [^0-9]与[^[:digit:]]等效[^a-z]与[^[:lower:]]等效[^A-Z]与[^[:upper:]]等效[^a-zA-Z]与[^[:alpha:]]等效[^a-zA-Z0-9]与[^[:alnum:]]等效 #简短格式并非所有正则表达式解析器都可以识别\\d #表示任意单个0到9的数字\\D #表示任意单个非数字字符\\t #表示匹配单个横向制表符（相当于一个tab键）\\s #表示匹配单个空白字符，包括&quot;空格&quot;，&quot;tab制表符&quot;等\\S #表示匹配单个非空白字符\\(\\) #表示分组，且可以嵌套\\(ab\\) #表示将ab作为一个整体处理\\1 #表示引用整个表达式中第一个分组中的正则表达式\\2 #表示引用整个表达式中第二个分组中的正则表达式#若分组嵌套，以左括号为基准判断是第几个分组","categories":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/categories/%E6%AD%A3%E5%88%99/"}],"tags":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/tags/%E6%AD%A3%E5%88%99/"}],"author":"Frdqy"},{"title":"Shell编程之（三）：常用查找工具","slug":"Shell编程之（三）：常用查找工具","date":"2019-12-27T14:16:02.000Z","updated":"2019-12-30T07:58:04.759Z","comments":true,"path":"2019/12/27/Shell编程之（三）：常用查找工具/","link":"","permalink":"http://yoursite.com/2019/12/27/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/","excerpt":"find命令： 语法格式：find [路径] [选项] [操作] 选项： -name(大小写敏感) -iname(忽略大小写) -perm -prune(排除某些目录，通常与path一起使用) 如：find . -path ./test -prune -o -type f(-o表示或者) -user -group -mtime -n | +n -nogroup(无效组) -nouser(无效用户) -newer file1 ! file2 -type -size -n | +n -mindepth n -maxdepth n","text":"find命令： 语法格式：find [路径] [选项] [操作] 选项： -name(大小写敏感) -iname(忽略大小写) -perm -prune(排除某些目录，通常与path一起使用) 如：find . -path ./test -prune -o -type f(-o表示或者) -user -group -mtime -n | +n -nogroup(无效组) -nouser(无效用户) -newer file1 ! file2 -type -size -n | +n -mindepth n -maxdepth n 操作： -print(默认) -ok(与exec相似，会给用户提示) -exec 删除etc下conf结尾的文件 find ./etc -name &apos;*.conf&apos; -exec rm -rf {} \\; 复制 find ./etc -size +1M -exec cp {} ./test/ \\; 删除/var/log下以.log结尾的7天以前的文件 find /var/log -name &apos;*.log&apos; -mtime +7 -exec rm -rf {} \\; 搜素etc下以conf结尾的且大于10k的文件，复制到root/conf目录下 find /etc/ -name &apos;*.conf&apos; -size +10k -exec cp {} /root/conf/ \\; locate locate在数据库文件中查找，而find在整个磁盘中查找 由系统定时任务负责更新数据库 find默认全部匹配，locate默认部分匹配 updatedb命令： 更新/var/lib/mlocate/mlocate.db 配置文件为：/etc/updatedb.conf whereis -b查找二进制文件 -m查找帮助文件 -s查找源代码文件 which 查找二进制文件(查用于查找程序绝对路径) grep 形式一：grep [option] [pattern] [file1,file2...] 形式二：command | grep [option] [pattern] 参数： -v 不显示匹配行 -i 忽略大小写 -n 显示行号 -r 递归搜索(当前目录下搜索所有文件) -E 支持扩展正则 -F 不按正则 -c 输出匹配行的数量 -w 匹配整个单词 -x 匹配整行 -l 只列出匹配的文件名 逻辑运算：123-a #与-o #或-not|! #非","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"find","slug":"find","permalink":"http://yoursite.com/tags/find/"},{"name":"grep","slug":"grep","permalink":"http://yoursite.com/tags/grep/"}],"author":"Frdqy"},{"title":"Shell编程之（二）：函数的使用","slug":"Shell编程之（二）：函数的使用","date":"2019-12-27T14:15:17.000Z","updated":"2020-01-06T07:39:51.424Z","comments":true,"path":"2019/12/27/Shell编程之（二）：函数的使用/","link":"","permalink":"http://yoursite.com/2019/12/27/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"函数命名格式12345678910111213name() &#123; command1 command2 &#125;function name &#123; command1 command2 &#125;#调用函数时直接用函数名调用即可，像一条shell命令一样#函数内部参数使用$1,$2...$n#调用函数例子：function_name $1 $2 函数传参12345function name&#123; echo $1 #第一个参数 echo $2 #第二个参数&#125; 函数调用1name zhangsan lisi 函数返回值 返回0：成功返回1~255：失败 echo返回单一字符串或数据列表 echo $$：返回脚本执行的进程pid，用于解决脚本自身名字包含所要管 理的服务引起冲突的情况。守护进程(daemon)：通过脚本判断某个服务是否正常，不正常就启动 netstat -tnlp：查看网络状态 全局变量与局部变量的定义 不做特殊说明，shell中变量都是全局变量(不建议在大型脚本中使用全 局变量) 定义变量时使用local关键字函数内外若存在同名变量，则函数内部变量覆盖外部变量 库函数：用于封装常用函数，后缀通常以.lib结尾。引用库函数时，用. base_function即可，推荐用绝对路径(点后有一个 空格) 文件包含12345678#!/bin/bash# author:菜鸟教程# url:www.runoob.com#注意.和文件名中间有空格. file_name#或者source file_name while循环只强调一个while循环的特殊用法，即依次读取文件的行 123456#格式while read linedo 循环体done &lt; /path/file#上述可以实现一次读取file中的每一行并赋值给line变量 case选择123456789101112case $var inpar1) 分支1 ;;part2) 分支2 ;;...#上述都不匹配则匹配此选项*) 分支nesac","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}],"author":"Frdqy"},{"title":"Shell编程之（一）：变量的用法","slug":"Shell编程之（一）：变量的用法","date":"2019-12-27T14:13:36.000Z","updated":"2020-01-28T03:14:46.935Z","comments":true,"path":"2019/12/27/Shell编程之（一）：变量的用法/","link":"","permalink":"http://yoursite.com/2019/12/27/Shell%E7%BC%96%E7%A8%8B%E4%B9%8B%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%8F%98%E9%87%8F%E7%9A%84%E7%94%A8%E6%B3%95/","excerpt":"","text":"定义范围12345#显示1到100的数echo &#123;1..100&#125;#表示从1到10，步长为2seq 1 2 10 计算字符串长度1$&#123;#String&#125; 1expr length \"$String\" 获取子串在字符串中的索引位置1expr index $String $subString #切片,字符查找，返回第一个 计算子串长度1expr match $String subString 抽取子串12345$&#123;string:position:length&#125;#从position取length个$&#123;String:position&#125; #从String中的position开始$&#123;String: -position&#125; #从右往左(注意空格)$&#123;String:(position)&#125; #从左往右$expr substr $String $position $length #与二类似 变量替换：1234567891011$&#123;变量名#正则&#125; #从开头匹配最短删除$&#123;变量名##正则&#125; #从开头匹配最长删除$&#123;变量名%正则&#125; #从尾部匹配最短删除$&#123;变量名%%正则&#125; #从尾部匹配最长删除$&#123;变量名/旧字符串/新字符串&#125; #第一个字符串替换$&#123;变量名//旧字符串/新字符串&#125; #全部字符串替换#注意：使用expr索引计数从1开始，使用$&#123;&#125;索引计数从0开始#设置默认值$&#123;NAME:-tom&#125; #若NAME没有值，其值为tom$&#123;NAME:+tom&#125; #若NAME有值，则将其值改为tom 命令替换12``$() 数学运算12$[a+b]$((a+b)) #注意与命令替换区分 有类型变量1234567891011declare -r #声明变量为只读类型declare -i #声明变量为整型declare -f #在脚本中显示定义的函数和内容declare -F #在脚本中显示定义的函数declare -a #声明数组arr=(\"jones\" \"mike\" \"kobe\" \"jordan\") #以空格分隔echo $&#123;arr[@]&#125; #获取整个数组echo $&#123;#arr[@]&#125; #获取整个数组长度echo $&#123;#arr[i]&#125; #获取某个数组元素长度declare -x #声明环境变量#取消某个设置只需要“-”改为“+”即可 expr语法格式1234567expr $num1 operator $num2#操作符对照表(注意转义)num1 | num2 num1 #不为空且非0，返回num1；否则返回num2num1 &amp; num2 num1 #不为空且非0，返回num1；否则返回0#判断整数expr $num + 1 #如果执行成功则为整数(成功返回1) bc进行浮点数计算123echo \"23 + 5\" | bcecho \"23.15 + 4.3\" | bcecho \"scale=4;23.5/3.5\" | bc let自增12#let后变量不需要$引用，一般直接++即可let i++","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}],"author":"Frdqy"},{"title":"Hello World","slug":"hello-world","date":"2019-12-27T05:38:00.000Z","updated":"2019-12-27T15:36:33.873Z","comments":true,"path":"2019/12/27/hello-world/","link":"","permalink":"http://yoursite.com/2019/12/27/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StratCreate a new post","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StratCreate a new post 1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}